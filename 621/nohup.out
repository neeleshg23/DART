===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.1988238462 - test_loss: 0.3401560605
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.1121748031 - test_loss: 0.3879721695
Early Stop Left: 4
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0975863241 - test_loss: 0.3806926476
Early Stop Left: 3
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0899352960 - test_loss: 0.4318989817
Early Stop Left: 2
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0841825442 - test_loss: 0.4207445487
Early Stop Left: 1
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0796499291 - test_loss: 0.4358746318
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 33%|███▎      | 12/36 [00:00<00:00, 114.09it/s] 67%|██████▋   | 24/36 [00:00<00:00, 114.85it/s]100%|██████████| 36/36 [00:00<00:00, 117.48it/s]
Best micro threshold=0.178061, fscore=0.638
p,r,f1: 0.6185993423257832 0.6580561563129241 0.6377180154594063
throttleing by fixed threshold: 0.5
p,r,f1: 0.7747247590513663 0.5001817808934298 0.6078927318096975
{'model': 'vitt',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.17806099355220795,
                 'p': 0.6185993423257832,
                 'r': 0.6580561563129241,
                 'f1': 0.6377180154594063},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.7747247590513663,
                 'r': 0.5001817808934298,
                 'f1': 0.6078927318096975}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5073171479 - test_loss: 0.5761813803
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3841226285 - test_loss: 0.4704384580
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.3323922598 - test_loss: 0.4176744098
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3074420416 - test_loss: 0.3861280936
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2952250819 - test_loss: 0.3674279137
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2897619023 - test_loss: 0.3570958376
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2874548833 - test_loss: 0.3526351717
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2857263028 - test_loss: 0.3515883742
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2820259543 - test_loss: 0.3526231042
Early Stop Left: 4
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2787829253 - test_loss: 0.3516606225
Early Stop Left: 3
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2770595628 - test_loss: 0.3508762171
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2760938273 - test_loss: 0.3506090119
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2754206545 - test_loss: 0.3500048179
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2748492420 - test_loss: 0.3504673301
Early Stop Left: 4
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2742624874 - test_loss: 0.3517281405
Early Stop Left: 3
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2736297754 - test_loss: 0.3516185010
Early Stop Left: 2
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2729344151 - test_loss: 0.3503850069
Early Stop Left: 1
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2721899948 - test_loss: 0.3506461763
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 53%|█████▎    | 19/36 [00:00<00:00, 183.38it/s]100%|██████████| 36/36 [00:00<00:00, 188.47it/s]
Best micro threshold=0.348144, fscore=0.538
p,r,f1: 0.7234605213449188 0.4284435826683571 0.5381733021077284
throttleing by fixed threshold: 0.5
p,r,f1: 0.8952409674889921 0.3459010739055858 0.4989997949159322
{'model': 'vit',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.348143607378006,
                 'p': 0.7234605213449188,
                 'r': 0.4284435826683571,
                 'f1': 0.5381733021077284},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8952409674889921,
                 'r': 0.3459010739055858,
                 'f1': 0.4989997949159322}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6003910248 - test_loss: 0.5747667021
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.4463629300 - test_loss: 0.4673256295
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.3765417974 - test_loss: 0.4133702674
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3392360087 - test_loss: 0.3812879556
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3184672211 - test_loss: 0.3618379020
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3073827456 - test_loss: 0.3499736761
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3015710048 - test_loss: 0.3439190288
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2973149476 - test_loss: 0.3421351347
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2917294061 - test_loss: 0.3433184955
Early Stop Left: 4
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2870491103 - test_loss: 0.3422577108
Early Stop Left: 3
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2844719586 - test_loss: 0.3419093589
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2829886866 - test_loss: 0.3412151370
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2819277593 - test_loss: 0.3411049636
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2810127834 - test_loss: 0.3424725698
Early Stop Left: 4
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2800598272 - test_loss: 0.3430470137
Early Stop Left: 3
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2789715692 - test_loss: 0.3437067709
Early Stop Left: 2
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2776479113 - test_loss: 0.3426444978
Early Stop Left: 1
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2759761574 - test_loss: 0.3429216378
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 56%|█████▌    | 20/36 [00:00<00:00, 195.05it/s]100%|██████████| 36/36 [00:00<00:00, 195.34it/s]
Best micro threshold=0.334953, fscore=0.539
p,r,f1: 0.7422222947955406 0.42372893206055634 0.5394754996283664
throttleing by fixed threshold: 0.5
p,r,f1: 0.8959041381183785 0.34587543813856364 0.4990760715132419
{'model': 'vit',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3349533975124359,
                 'p': 0.7422222947955406,
                 'r': 0.42372893206055634,
                 'f1': 0.5394754996283664},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8959041381183785,
                 'r': 0.34587543813856364,
                 'f1': 0.4990760715132419}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5693875790 - test_loss: 0.5751813187
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.4257281124 - test_loss: 0.4681654208
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.3620682301 - test_loss: 0.4144544750
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3291064105 - test_loss: 0.3823688568
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3114542731 - test_loss: 0.3628446120
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3025245634 - test_loss: 0.3511898261
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2981137461 - test_loss: 0.3455365698
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2947573517 - test_loss: 0.3442069896
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2899747998 - test_loss: 0.3450937635
Early Stop Left: 4
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2860207813 - test_loss: 0.3440848564
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2838909090 - test_loss: 0.3436319489
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2826640772 - test_loss: 0.3431966545
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2817818034 - test_loss: 0.3430084528
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2810232267 - test_loss: 0.3441868689
Early Stop Left: 4
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2802431160 - test_loss: 0.3450695607
Early Stop Left: 3
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2793735088 - test_loss: 0.3456277069
Early Stop Left: 2
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2783483292 - test_loss: 0.3448221228
Early Stop Left: 1
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2771254678 - test_loss: 0.3452920318
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 47%|████▋     | 17/36 [00:00<00:00, 169.15it/s] 94%|█████████▍| 34/36 [00:00<00:00, 169.29it/s]100%|██████████| 36/36 [00:00<00:00, 171.49it/s]
Best micro threshold=0.341849, fscore=0.539
p,r,f1: 0.7479482525520224 0.42160116339771797 0.5392433173610749
throttleing by fixed threshold: 0.5
p,r,f1: 0.8957451050281827 0.3455468342158252 0.49870924884168755
{'model': 'vit',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.34184888005256653,
                 'p': 0.7479482525520224,
                 'r': 0.42160116339771797,
                 'f1': 0.5392433173610749},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8957451050281827,
                 'r': 0.3455468342158252,
                 'f1': 0.49870924884168755}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4048259274 - test_loss: 0.3453762854
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2968322475 - test_loss: 0.3333430249
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2752383155 - test_loss: 0.3431344421
Early Stop Left: 4
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2552379674 - test_loss: 0.3367798279
Early Stop Left: 3
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2374595527 - test_loss: 0.3214571451
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2219566809 - test_loss: 0.3240708593
Early Stop Left: 4
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2108165249 - test_loss: 0.3381845260
Early Stop Left: 3
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2031005724 - test_loss: 0.3459409691
Early Stop Left: 2
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.1971859490 - test_loss: 0.3519628371
Early Stop Left: 1
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.1922627555 - test_loss: 0.3512498492
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 47%|████▋     | 17/36 [00:00<00:00, 164.42it/s] 94%|█████████▍| 34/36 [00:00<00:00, 161.71it/s]100%|██████████| 36/36 [00:00<00:00, 161.85it/s]
Best micro threshold=0.162667, fscore=0.660
p,r,f1: 0.6520144017599114 0.6672477440525021 0.659543124230449
throttleing by fixed threshold: 0.5
p,r,f1: 0.8838710043588812 0.36293487582966666 0.5145750726936293
{'model': 'vit',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.16266706585884094,
                 'p': 0.6520144017599114,
                 'r': 0.6672477440525021,
                 'f1': 0.659543124230449},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8838710043588812,
                 'r': 0.36293487582966666,
                 'f1': 0.5145750726936293}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
/data/neelesh/DART_by_app/621/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 1.0000001
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.043, 0.0649
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00011, 5.36e-05
--- total mse / var(X): 0.0325
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00995, 0.00864
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00615, 0.00695
--- total mse / var(X): 0.0078
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00333, 0.00259
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00287, 0.00351
--- total mse / var(X): 0.00305
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00649, 0.00612
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0111, 0.0118
--- total mse / var(X): 0.00894
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00871, 0.00743
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.015, 0.0172
--- total mse / var(X): 0.0123
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0212, 0.0166
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0258, 0.0314
--- total mse / var(X): 0.024
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0129, 0.0156
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0341, 0.027
--- total mse / var(X): 0.0213
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0158, 0.0136
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0103, 0.0117
--- total mse / var(X): 0.0127
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0046, 0.00456
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00513, 0.00518
--- total mse / var(X): 0.00487
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0022, 0.00238
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00319, 0.00292
--- total mse / var(X): 0.00265
start table evaluation...
Elapsed time: 42.72756290435791 seconds
Cosine similarity between AMM and exact (Train): 0.7623104
Cosine similarity between AMM and exact (Test): 0.7151184
p,r,f1: 0.6519280287593544 0.6673386344992169 0.6595433245155293
p,r,f1: 0.35230551127243037 0.5953743754194943 0.4426677756406924
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6519280287593544, 0.6673386344992169, 0.6595433245155293],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9973446726799011,
                                      0.9910668730735779,
                                      0.9866148233413696,
                                      0.762310266494751],
               'cossim_layer_test': [0.9938636422157288,
                                     0.9910899996757507,
                                     0.9852676391601562,
                                     0.715118408203125],
               'cossim_amm_train': [0.9957454800605774,
                                    0.9959656596183777,
                                    0.9780676364898682,
                                    0.9771974086761475,
                                    0.9821146130561829,
                                    0.9572482109069824,
                                    0.9038869142532349,
                                    0.8695135712623596],
               'cossim_amm_test': [0.9904009699821472,
                                   0.9942097663879395,
                                   0.9759666919708252,
                                   0.9769449234008789,
                                   0.9829823970794678,
                                   0.9528855085372925,
                                   0.8916664719581604,
                                   0.8521609902381897],
               'f1': [0.35230551127243037,
                      0.5953743754194943,
                      0.4426677756406924],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999994
Manual and Torch results cosine similarity (Test): 1.0000001
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
/data/neelesh/DART_by_app/621/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0439, 0.0663
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00045, 0.00022
--- total mse / var(X): 0.0333
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:45,  1.06s/it]  2%|▏         | 2/100 [00:02<02:23,  1.46s/it]  3%|▎         | 3/100 [00:04<02:27,  1.52s/it]  4%|▍         | 4/100 [00:05<01:55,  1.20s/it]  5%|▌         | 5/100 [00:06<02:10,  1.37s/it]  6%|▌         | 6/100 [00:07<01:57,  1.25s/it]  7%|▋         | 7/100 [00:09<02:10,  1.41s/it]  8%|▊         | 8/100 [00:10<02:09,  1.41s/it]  9%|▉         | 9/100 [00:12<02:07,  1.41s/it] 10%|█         | 10/100 [00:13<02:13,  1.48s/it] 11%|█         | 11/100 [00:14<01:50,  1.24s/it] 12%|█▏        | 12/100 [00:16<02:00,  1.37s/it] 13%|█▎        | 13/100 [00:17<02:03,  1.42s/it] 14%|█▍        | 14/100 [00:19<02:12,  1.54s/it] 15%|█▌        | 15/100 [00:21<02:12,  1.56s/it] 16%|█▌        | 16/100 [00:22<01:51,  1.32s/it] 17%|█▋        | 17/100 [00:24<02:08,  1.55s/it] 18%|█▊        | 18/100 [00:25<02:02,  1.49s/it] 19%|█▉        | 19/100 [00:27<02:22,  1.76s/it] 20%|██        | 20/100 [00:28<02:01,  1.51s/it] 21%|██        | 21/100 [00:29<01:42,  1.29s/it] 22%|██▏       | 22/100 [00:31<01:51,  1.43s/it] 23%|██▎       | 23/100 [00:32<01:43,  1.35s/it] 24%|██▍       | 24/100 [00:34<02:07,  1.68s/it] 25%|██▌       | 25/100 [00:35<01:50,  1.48s/it] 26%|██▌       | 26/100 [00:36<01:34,  1.27s/it] 27%|██▋       | 27/100 [00:37<01:17,  1.06s/it] 28%|██▊       | 28/100 [00:37<01:07,  1.07it/s] 29%|██▉       | 29/100 [00:38<01:01,  1.16it/s] 30%|███       | 30/100 [00:39<00:53,  1.30it/s] 31%|███       | 31/100 [00:40<00:53,  1.29it/s] 32%|███▏      | 32/100 [00:40<00:49,  1.36it/s] 33%|███▎      | 33/100 [00:41<00:48,  1.38it/s] 34%|███▍      | 34/100 [00:42<00:46,  1.41it/s] 35%|███▌      | 35/100 [00:42<00:46,  1.41it/s] 36%|███▌      | 36/100 [00:43<00:48,  1.31it/s] 37%|███▋      | 37/100 [00:44<00:55,  1.13it/s] 38%|███▊      | 38/100 [00:45<00:56,  1.09it/s] 39%|███▉      | 39/100 [00:46<00:56,  1.07it/s] 40%|████      | 40/100 [00:47<00:57,  1.05it/s] 41%|████      | 41/100 [00:48<00:55,  1.07it/s] 42%|████▏     | 42/100 [00:49<00:49,  1.18it/s] 43%|████▎     | 43/100 [00:49<00:43,  1.31it/s] 44%|████▍     | 44/100 [00:50<00:41,  1.36it/s] 45%|████▌     | 45/100 [00:51<00:38,  1.43it/s] 46%|████▌     | 46/100 [00:51<00:38,  1.41it/s] 47%|████▋     | 47/100 [00:52<00:40,  1.32it/s] 48%|████▊     | 48/100 [00:53<00:42,  1.22it/s] 49%|████▉     | 49/100 [00:54<00:39,  1.31it/s] 50%|█████     | 50/100 [00:54<00:36,  1.38it/s] 51%|█████     | 51/100 [00:55<00:35,  1.37it/s] 52%|█████▏    | 52/100 [00:56<00:33,  1.42it/s] 53%|█████▎    | 53/100 [00:57<00:33,  1.42it/s] 54%|█████▍    | 54/100 [00:57<00:31,  1.48it/s] 55%|█████▌    | 55/100 [00:58<00:29,  1.51it/s] 56%|█████▌    | 56/100 [00:59<00:30,  1.43it/s] 57%|█████▋    | 57/100 [00:59<00:28,  1.50it/s] 58%|█████▊    | 58/100 [01:00<00:28,  1.50it/s] 59%|█████▉    | 59/100 [01:01<00:27,  1.47it/s] 60%|██████    | 60/100 [01:01<00:26,  1.52it/s] 61%|██████    | 61/100 [01:02<00:25,  1.51it/s] 62%|██████▏   | 62/100 [01:03<00:25,  1.47it/s] 63%|██████▎   | 63/100 [01:03<00:24,  1.50it/s] 64%|██████▍   | 64/100 [01:04<00:23,  1.54it/s] 65%|██████▌   | 65/100 [01:04<00:21,  1.62it/s] 66%|██████▌   | 66/100 [01:05<00:21,  1.58it/s] 67%|██████▋   | 67/100 [01:06<00:22,  1.49it/s] 68%|██████▊   | 68/100 [01:06<00:21,  1.48it/s] 69%|██████▉   | 69/100 [01:07<00:20,  1.49it/s] 70%|███████   | 70/100 [01:08<00:20,  1.49it/s] 71%|███████   | 71/100 [01:08<00:18,  1.57it/s] 72%|███████▏  | 72/100 [01:09<00:18,  1.49it/s] 73%|███████▎  | 73/100 [01:10<00:17,  1.51it/s] 74%|███████▍  | 74/100 [01:10<00:17,  1.50it/s] 75%|███████▌  | 75/100 [01:11<00:16,  1.52it/s] 76%|███████▌  | 76/100 [01:12<00:15,  1.53it/s] 77%|███████▋  | 77/100 [01:12<00:15,  1.51it/s] 78%|███████▊  | 78/100 [01:13<00:13,  1.58it/s] 79%|███████▉  | 79/100 [01:14<00:13,  1.58it/s] 80%|████████  | 80/100 [01:14<00:13,  1.52it/s] 81%|████████  | 81/100 [01:15<00:12,  1.51it/s] 82%|████████▏ | 82/100 [01:16<00:12,  1.47it/s] 83%|████████▎ | 83/100 [01:16<00:11,  1.43it/s] 84%|████████▍ | 84/100 [01:17<00:10,  1.51it/s] 85%|████████▌ | 85/100 [01:18<00:10,  1.50it/s] 86%|████████▌ | 86/100 [01:18<00:09,  1.46it/s] 87%|████████▋ | 87/100 [01:19<00:08,  1.52it/s] 88%|████████▊ | 88/100 [01:20<00:08,  1.48it/s] 89%|████████▉ | 89/100 [01:20<00:07,  1.48it/s] 90%|█████████ | 90/100 [01:21<00:06,  1.53it/s] 91%|█████████ | 91/100 [01:22<00:05,  1.53it/s] 92%|█████████▏| 92/100 [01:22<00:05,  1.50it/s] 93%|█████████▎| 93/100 [01:23<00:04,  1.46it/s] 94%|█████████▍| 94/100 [01:24<00:04,  1.48it/s] 95%|█████████▌| 95/100 [01:24<00:03,  1.51it/s] 96%|█████████▌| 96/100 [01:25<00:02,  1.51it/s] 97%|█████████▋| 97/100 [01:26<00:02,  1.49it/s] 98%|█████████▊| 98/100 [01:27<00:01,  1.42it/s] 99%|█████████▉| 99/100 [01:27<00:00,  1.42it/s]100%|██████████| 100/100 [01:28<00:00,  1.43it/s]100%|██████████| 100/100 [01:28<00:00,  1.13it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0105, 0.00913
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00655, 0.00741
--- total mse / var(X): 0.00827
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00298, 0.00231
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00275, 0.00336
--- total mse / var(X): 0.00283
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00616, 0.00581
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00718, 0.00758
--- total mse / var(X): 0.0067
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00898, 0.00801
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0171, 0.0189
--- total mse / var(X): 0.0135
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0227, 0.0178
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0241, 0.0293
--- total mse / var(X): 0.0235
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:22,  1.20it/s]  2%|▏         | 2/100 [00:00<00:41,  2.35it/s]  3%|▎         | 3/100 [00:01<00:32,  3.03it/s]  4%|▍         | 4/100 [00:01<00:30,  3.11it/s]  5%|▌         | 5/100 [00:01<00:23,  4.10it/s]  7%|▋         | 7/100 [00:01<00:16,  5.77it/s]  9%|▉         | 9/100 [00:02<00:14,  6.08it/s] 11%|█         | 11/100 [00:02<00:12,  6.94it/s] 13%|█▎        | 13/100 [00:02<00:10,  8.08it/s] 15%|█▌        | 15/100 [00:02<00:09,  9.07it/s] 16%|█▌        | 16/100 [00:02<00:09,  8.85it/s] 18%|█▊        | 18/100 [00:02<00:08,  9.60it/s] 19%|█▉        | 19/100 [00:03<00:10,  7.46it/s] 21%|██        | 21/100 [00:03<00:09,  8.02it/s] 23%|██▎       | 23/100 [00:03<00:09,  7.93it/s] 24%|██▍       | 24/100 [00:03<00:09,  7.62it/s] 25%|██▌       | 25/100 [00:03<00:09,  7.64it/s] 27%|██▋       | 27/100 [00:04<00:09,  7.85it/s] 28%|██▊       | 28/100 [00:04<00:09,  7.82it/s] 30%|███       | 30/100 [00:04<00:08,  8.67it/s] 32%|███▏      | 32/100 [00:04<00:07,  8.95it/s] 34%|███▍      | 34/100 [00:05<00:08,  8.00it/s] 36%|███▌      | 36/100 [00:05<00:07,  8.07it/s] 37%|███▋      | 37/100 [00:05<00:07,  8.37it/s] 39%|███▉      | 39/100 [00:05<00:06,  9.32it/s] 41%|████      | 41/100 [00:05<00:06,  9.79it/s] 43%|████▎     | 43/100 [00:05<00:05,  9.91it/s] 45%|████▌     | 45/100 [00:06<00:05,  9.41it/s] 46%|████▌     | 46/100 [00:06<00:06,  8.70it/s] 48%|████▊     | 48/100 [00:06<00:05,  9.78it/s] 49%|████▉     | 49/100 [00:06<00:05,  8.85it/s] 51%|█████     | 51/100 [00:06<00:05,  9.61it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.78it/s] 53%|█████▎    | 53/100 [00:07<00:05,  8.39it/s] 54%|█████▍    | 54/100 [00:07<00:05,  8.45it/s] 55%|█████▌    | 55/100 [00:07<00:05,  8.62it/s] 57%|█████▋    | 57/100 [00:07<00:04,  9.57it/s] 58%|█████▊    | 58/100 [00:07<00:04,  9.50it/s] 59%|█████▉    | 59/100 [00:07<00:04,  8.79it/s] 61%|██████    | 61/100 [00:07<00:04,  9.02it/s] 63%|██████▎   | 63/100 [00:08<00:03,  9.55it/s] 64%|██████▍   | 64/100 [00:08<00:03,  9.35it/s] 66%|██████▌   | 66/100 [00:08<00:03,  8.72it/s] 67%|██████▋   | 67/100 [00:08<00:03,  8.70it/s] 68%|██████▊   | 68/100 [00:08<00:03,  8.45it/s] 69%|██████▉   | 69/100 [00:08<00:03,  8.24it/s] 70%|███████   | 70/100 [00:09<00:03,  8.23it/s] 71%|███████   | 71/100 [00:09<00:03,  8.51it/s] 72%|███████▏  | 72/100 [00:09<00:03,  8.52it/s] 73%|███████▎  | 73/100 [00:09<00:03,  8.47it/s] 74%|███████▍  | 74/100 [00:09<00:03,  8.33it/s] 75%|███████▌  | 75/100 [00:09<00:03,  7.88it/s] 76%|███████▌  | 76/100 [00:09<00:02,  8.26it/s] 77%|███████▋  | 77/100 [00:09<00:03,  7.55it/s] 79%|███████▉  | 79/100 [00:10<00:02,  8.39it/s] 80%|████████  | 80/100 [00:10<00:02,  8.56it/s] 81%|████████  | 81/100 [00:10<00:02,  8.33it/s] 83%|████████▎ | 83/100 [00:10<00:01,  8.53it/s] 84%|████████▍ | 84/100 [00:10<00:01,  8.65it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.58it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.05it/s] 88%|████████▊ | 88/100 [00:11<00:01,  8.83it/s] 89%|████████▉ | 89/100 [00:11<00:01,  7.44it/s] 90%|█████████ | 90/100 [00:11<00:01,  7.94it/s] 91%|█████████ | 91/100 [00:11<00:01,  8.31it/s] 93%|█████████▎| 93/100 [00:11<00:00,  8.90it/s] 95%|█████████▌| 95/100 [00:11<00:00,  9.82it/s] 96%|█████████▌| 96/100 [00:12<00:00,  9.53it/s] 97%|█████████▋| 97/100 [00:12<00:00,  9.57it/s] 98%|█████████▊| 98/100 [00:12<00:00,  9.01it/s] 99%|█████████▉| 99/100 [00:12<00:00,  8.91it/s]100%|██████████| 100/100 [00:12<00:00,  9.14it/s]100%|██████████| 100/100 [00:12<00:00,  7.99it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0118, 0.0141
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0409, 0.0328
--- total mse / var(X): 0.0235
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  7.89it/s]  3%|▎         | 3/100 [00:00<00:08, 10.98it/s]  5%|▌         | 5/100 [00:00<00:06, 14.14it/s]  7%|▋         | 7/100 [00:00<00:06, 15.31it/s]  9%|▉         | 9/100 [00:00<00:05, 16.27it/s] 11%|█         | 11/100 [00:00<00:05, 16.70it/s] 14%|█▍        | 14/100 [00:00<00:04, 17.84it/s] 16%|█▌        | 16/100 [00:00<00:04, 18.07it/s] 18%|█▊        | 18/100 [00:01<00:04, 18.20it/s] 20%|██        | 20/100 [00:01<00:04, 17.95it/s] 23%|██▎       | 23/100 [00:01<00:03, 20.55it/s] 26%|██▌       | 26/100 [00:01<00:03, 18.66it/s] 29%|██▉       | 29/100 [00:01<00:03, 19.47it/s] 32%|███▏      | 32/100 [00:01<00:03, 18.45it/s] 34%|███▍      | 34/100 [00:01<00:03, 18.06it/s] 37%|███▋      | 37/100 [00:02<00:03, 19.41it/s] 39%|███▉      | 39/100 [00:02<00:03, 18.52it/s] 41%|████      | 41/100 [00:02<00:03, 18.70it/s] 44%|████▍     | 44/100 [00:02<00:02, 20.19it/s] 47%|████▋     | 47/100 [00:02<00:02, 18.88it/s] 50%|█████     | 50/100 [00:02<00:02, 20.21it/s] 53%|█████▎    | 53/100 [00:02<00:02, 18.78it/s] 56%|█████▌    | 56/100 [00:03<00:02, 20.42it/s] 59%|█████▉    | 59/100 [00:03<00:02, 19.40it/s] 61%|██████    | 61/100 [00:03<00:02, 18.28it/s] 63%|██████▎   | 63/100 [00:03<00:02, 17.51it/s] 65%|██████▌   | 65/100 [00:03<00:02, 16.92it/s] 68%|██████▊   | 68/100 [00:03<00:01, 18.56it/s] 70%|███████   | 70/100 [00:03<00:01, 16.98it/s] 73%|███████▎  | 73/100 [00:04<00:01, 18.11it/s] 75%|███████▌  | 75/100 [00:04<00:01, 16.47it/s] 77%|███████▋  | 77/100 [00:04<00:01, 16.38it/s] 80%|████████  | 80/100 [00:04<00:01, 15.42it/s] 82%|████████▏ | 82/100 [00:04<00:01, 15.67it/s] 85%|████████▌ | 85/100 [00:04<00:00, 18.42it/s] 88%|████████▊ | 88/100 [00:04<00:00, 19.61it/s] 91%|█████████ | 91/100 [00:05<00:00, 20.69it/s] 94%|█████████▍| 94/100 [00:05<00:00, 17.77it/s] 97%|█████████▋| 97/100 [00:05<00:00, 18.77it/s] 99%|█████████▉| 99/100 [00:05<00:00, 15.91it/s]100%|██████████| 100/100 [00:05<00:00, 17.72it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0178, 0.0153
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0119, 0.0136
--- total mse / var(X): 0.0144
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:31,  3.15it/s]  2%|▏         | 2/100 [00:00<00:19,  4.93it/s]  3%|▎         | 3/100 [00:00<00:19,  4.92it/s]  5%|▌         | 5/100 [00:00<00:12,  7.89it/s]  8%|▊         | 8/100 [00:00<00:07, 12.65it/s] 12%|█▏        | 12/100 [00:01<00:04, 18.25it/s] 16%|█▌        | 16/100 [00:01<00:03, 22.65it/s] 20%|██        | 20/100 [00:01<00:03, 26.07it/s] 24%|██▍       | 24/100 [00:01<00:02, 29.33it/s] 28%|██▊       | 28/100 [00:01<00:02, 31.74it/s] 32%|███▏      | 32/100 [00:01<00:02, 32.76it/s] 36%|███▌      | 36/100 [00:01<00:01, 33.83it/s] 40%|████      | 40/100 [00:01<00:01, 35.01it/s] 44%|████▍     | 44/100 [00:01<00:01, 36.14it/s] 48%|████▊     | 48/100 [00:02<00:01, 34.94it/s] 52%|█████▏    | 52/100 [00:02<00:01, 34.22it/s] 56%|█████▌    | 56/100 [00:02<00:01, 24.45it/s] 59%|█████▉    | 59/100 [00:02<00:02, 20.21it/s] 62%|██████▏   | 62/100 [00:02<00:02, 18.86it/s] 66%|██████▌   | 66/100 [00:02<00:01, 22.15it/s] 70%|███████   | 70/100 [00:03<00:01, 24.60it/s] 74%|███████▍  | 74/100 [00:03<00:00, 26.92it/s] 78%|███████▊  | 78/100 [00:03<00:00, 28.54it/s] 82%|████████▏ | 82/100 [00:03<00:00, 29.41it/s] 86%|████████▌ | 86/100 [00:03<00:00, 31.62it/s] 90%|█████████ | 90/100 [00:03<00:00, 32.73it/s] 94%|█████████▍| 94/100 [00:03<00:00, 33.81it/s] 98%|█████████▊| 98/100 [00:03<00:00, 33.13it/s]100%|██████████| 100/100 [00:03<00:00, 25.24it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00599, 0.00585
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00743, 0.0076
--- total mse / var(X): 0.00672
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:06, 14.18it/s]  4%|▍         | 4/100 [00:00<00:06, 15.68it/s]  7%|▋         | 7/100 [00:00<00:04, 20.18it/s] 10%|█         | 10/100 [00:00<00:04, 20.78it/s] 13%|█▎        | 13/100 [00:00<00:03, 22.05it/s] 16%|█▌        | 16/100 [00:00<00:03, 23.27it/s] 19%|█▉        | 19/100 [00:00<00:03, 23.59it/s] 22%|██▏       | 22/100 [00:01<00:03, 20.50it/s] 25%|██▌       | 25/100 [00:01<00:03, 19.10it/s] 27%|██▋       | 27/100 [00:01<00:04, 17.55it/s] 30%|███       | 30/100 [00:01<00:03, 18.84it/s] 33%|███▎      | 33/100 [00:01<00:03, 20.03it/s] 36%|███▌      | 36/100 [00:01<00:03, 16.32it/s] 38%|███▊      | 38/100 [00:02<00:04, 14.78it/s] 40%|████      | 40/100 [00:02<00:03, 15.76it/s] 43%|████▎     | 43/100 [00:02<00:03, 16.68it/s] 45%|████▌     | 45/100 [00:02<00:03, 15.21it/s] 47%|████▋     | 47/100 [00:02<00:03, 14.31it/s] 49%|████▉     | 49/100 [00:02<00:03, 14.72it/s] 53%|█████▎    | 53/100 [00:02<00:02, 19.94it/s] 57%|█████▋    | 57/100 [00:03<00:01, 23.69it/s] 62%|██████▏   | 62/100 [00:03<00:01, 28.99it/s] 66%|██████▌   | 66/100 [00:03<00:01, 30.52it/s] 70%|███████   | 70/100 [00:03<00:00, 32.79it/s] 75%|███████▌  | 75/100 [00:03<00:00, 34.71it/s] 80%|████████  | 80/100 [00:03<00:00, 35.63it/s] 84%|████████▍ | 84/100 [00:03<00:00, 35.88it/s] 89%|████████▉ | 89/100 [00:03<00:00, 39.46it/s] 94%|█████████▍| 94/100 [00:03<00:00, 36.95it/s] 99%|█████████▉| 99/100 [00:04<00:00, 37.75it/s]100%|██████████| 100/100 [00:04<00:00, 24.13it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0116, 0.0119
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0092, 0.00899
--- total mse / var(X): 0.0104
start table evaluation...
Elapsed time: 112.49710392951965 seconds
Cosine similarity between AMM and exact (Train): 0.8826385
Cosine similarity between AMM and exact (Test): 0.9427079
p,r,f1: 0.6519280287593544 0.6673386344992169 0.6595433245155293
p,r,f1: 0.5190787307050813 0.5693633939891118 0.5430595181068373
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6519280287593544, 0.6673386344992169, 0.6595433245155293],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9973746538162231,
                                      0.9932155609130859,
                                      0.9912945032119751,
                                      0.8826383948326111],
               'cossim_layer_test': [0.9941254258155823,
                                     0.992996871471405,
                                     0.9903738498687744,
                                     0.942707896232605],
               'cossim_amm_train': [0.9957939982414246,
                                    0.9956924319267273,
                                    0.981715977191925,
                                    0.9754041433334351,
                                    0.9866061210632324,
                                    0.9745765924453735,
                                    0.9493155479431152,
                                    0.947044849395752],
               'cossim_amm_test': [0.9908118844032288,
                                   0.9938502311706543,
                                   0.978793203830719,
                                   0.9748604893684387,
                                   0.9869038462638855,
                                   0.9758216142654419,
                                   0.9484756588935852,
                                   0.9718246459960938],
               'f1': [0.5190787307050813,
                      0.5693633939891118,
                      0.5430595181068373],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4860174861 - test_loss: 0.3861885808
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3181086506 - test_loss: 0.3447321107
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2990817649 - test_loss: 0.3365242887
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2927475401 - test_loss: 0.3266571172
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2771797879 - test_loss: 0.3330126281
Early Stop Left: 4
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2709229652 - test_loss: 0.3346268402
Early Stop Left: 3
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2671051739 - test_loss: 0.3411136005
Early Stop Left: 2
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2615440466 - test_loss: 0.3446919517
Early Stop Left: 1
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2483005787 - test_loss: 0.3369040175
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 36%|███▌      | 13/36 [00:00<00:00, 129.45it/s] 78%|███████▊  | 28/36 [00:00<00:00, 137.07it/s]100%|██████████| 36/36 [00:00<00:00, 136.18it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4040200234 - test_loss: 0.3451967736
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2892176338 - test_loss: 0.3361938033
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2621536254 - test_loss: 0.3452728999
Early Stop Left: 4
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2288625360 - test_loss: 0.3384518582
Early Stop Left: 3
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2135189211 - test_loss: 0.3534556511
Early Stop Left: 2
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2019742840 - test_loss: 0.3802720180
Early Stop Left: 1
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.1911024688 - test_loss: 0.3793682601
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/36 [00:00<?, ?it/s] 36%|███▌      | 13/36 [00:00<00:00, 128.00it/s] 72%|███████▏  | 26/36 [00:00<00:00, 127.44it/s]100%|██████████| 36/36 [00:00<00:00, 129.56it/s]
Best micro threshold=0.326858, fscore=0.563
p,r,f1: 0.6982611213767617 0.47203836975165936 0.5632849435452473
throttleing by fixed threshold: 0.5
p,r,f1: 0.8770125320917279 0.37576674248638975 0.5261136562381716
{'model': 'vit_large',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3268575072288513,
                 'p': 0.6982611213767617,
                 'r': 0.47203836975165936,
                 'f1': 0.5632849435452473},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8770125320917279,
                 'r': 0.37576674248638975,
                 'f1': 0.5261136562381716}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm

Best micro threshold=0.309507, fscore=0.573
p,r,f1: 0.6908614436637085 0.48966878589007384 0.5731209178183266
throttleing by fixed threshold: 0.5
p,r,f1: 0.8569655832311694 0.4007499627116116 0.5461154179621626
{'model': 'vit_min',
 'app': '621.wrf-s2.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3095068335533142,
                 'p': 0.6908614436637085,
                 'r': 0.48966878589007384,
                 'f1': 0.5731209178183266},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8569655832311694,
                 'r': 0.4007499627116116,
                 'f1': 0.5461154179621626}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999998
Manual and Torch results cosine similarity (Test): 1.0000001
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0753, 0.0753
--- total mse / var(X): 0.0753
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:32,  1.07it/s]  2%|▏         | 2/100 [00:01<01:31,  1.07it/s]  3%|▎         | 3/100 [00:02<01:34,  1.03it/s]  4%|▍         | 4/100 [00:04<01:40,  1.04s/it]  5%|▌         | 5/100 [00:04<01:33,  1.02it/s]  6%|▌         | 6/100 [00:05<01:26,  1.09it/s]  7%|▋         | 7/100 [00:06<01:21,  1.14it/s]  8%|▊         | 8/100 [00:07<01:20,  1.15it/s]  9%|▉         | 9/100 [00:08<01:19,  1.15it/s] 10%|█         | 10/100 [00:11<02:12,  1.47s/it] 11%|█         | 11/100 [00:12<02:08,  1.44s/it] 12%|█▏        | 12/100 [00:13<01:47,  1.22s/it] 13%|█▎        | 13/100 [00:13<01:34,  1.09s/it] 14%|█▍        | 14/100 [00:16<02:19,  1.62s/it] 15%|█▌        | 15/100 [00:18<02:13,  1.57s/it] 16%|█▌        | 16/100 [00:19<01:52,  1.34s/it] 17%|█▋        | 17/100 [00:19<01:35,  1.15s/it] 18%|█▊        | 18/100 [00:20<01:20,  1.02it/s] 19%|█▉        | 19/100 [00:22<01:51,  1.37s/it] 20%|██        | 20/100 [00:24<01:55,  1.44s/it] 21%|██        | 21/100 [00:25<01:42,  1.30s/it] 22%|██▏       | 22/100 [00:26<01:36,  1.24s/it] 23%|██▎       | 23/100 [00:28<01:51,  1.45s/it] 24%|██▍       | 24/100 [00:29<01:52,  1.48s/it] 25%|██▌       | 25/100 [00:31<01:45,  1.41s/it] 26%|██▌       | 26/100 [00:32<01:51,  1.51s/it] 27%|██▋       | 27/100 [00:34<01:51,  1.52s/it] 28%|██▊       | 28/100 [00:35<01:35,  1.32s/it] 29%|██▉       | 29/100 [00:35<01:18,  1.10s/it] 30%|███       | 30/100 [00:36<01:06,  1.06it/s] 31%|███       | 31/100 [00:38<01:20,  1.17s/it] 32%|███▏      | 32/100 [00:39<01:30,  1.34s/it] 33%|███▎      | 33/100 [00:41<01:29,  1.34s/it] 34%|███▍      | 34/100 [00:42<01:21,  1.23s/it] 35%|███▌      | 35/100 [00:42<01:12,  1.11s/it] 36%|███▌      | 36/100 [00:43<01:05,  1.03s/it] 37%|███▋      | 37/100 [00:46<01:36,  1.54s/it] 38%|███▊      | 38/100 [00:48<01:36,  1.55s/it] 39%|███▉      | 39/100 [00:48<01:20,  1.32s/it] 40%|████      | 40/100 [00:49<01:10,  1.18s/it] 41%|████      | 41/100 [00:50<01:09,  1.18s/it] 42%|████▏     | 42/100 [00:52<01:16,  1.32s/it] 43%|████▎     | 43/100 [00:53<01:16,  1.33s/it] 44%|████▍     | 44/100 [00:54<01:08,  1.22s/it] 45%|████▌     | 45/100 [00:57<01:36,  1.75s/it] 46%|████▌     | 46/100 [00:59<01:27,  1.63s/it] 47%|████▋     | 47/100 [00:59<01:13,  1.39s/it] 48%|████▊     | 48/100 [01:00<01:03,  1.23s/it] 49%|████▉     | 49/100 [01:01<00:59,  1.16s/it] 50%|█████     | 50/100 [01:03<01:11,  1.42s/it] 51%|█████     | 51/100 [01:05<01:10,  1.45s/it] 52%|█████▏    | 52/100 [01:06<01:05,  1.37s/it] 53%|█████▎    | 53/100 [01:08<01:18,  1.67s/it] 54%|█████▍    | 54/100 [01:10<01:12,  1.58s/it] 55%|█████▌    | 55/100 [01:11<01:02,  1.40s/it] 56%|█████▌    | 56/100 [01:12<00:57,  1.32s/it] 57%|█████▋    | 57/100 [01:13<01:00,  1.40s/it] 58%|█████▊    | 58/100 [01:15<00:59,  1.43s/it] 59%|█████▉    | 59/100 [01:16<00:52,  1.27s/it] 60%|██████    | 60/100 [01:17<00:44,  1.10s/it] 61%|██████    | 61/100 [01:18<00:41,  1.07s/it] 62%|██████▏   | 62/100 [01:18<00:38,  1.01s/it] 63%|██████▎   | 63/100 [01:21<00:55,  1.51s/it] 64%|██████▍   | 64/100 [01:22<00:50,  1.41s/it] 65%|██████▌   | 65/100 [01:23<00:41,  1.18s/it] 66%|██████▌   | 66/100 [01:24<00:36,  1.06s/it] 67%|██████▋   | 67/100 [01:24<00:30,  1.07it/s] 68%|██████▊   | 68/100 [01:25<00:27,  1.15it/s] 69%|██████▉   | 69/100 [01:26<00:28,  1.10it/s] 70%|███████   | 70/100 [01:29<00:42,  1.41s/it] 71%|███████   | 71/100 [01:30<00:37,  1.29s/it] 72%|███████▏  | 72/100 [01:31<00:32,  1.16s/it] 73%|███████▎  | 73/100 [01:32<00:31,  1.16s/it] 74%|███████▍  | 74/100 [01:33<00:28,  1.11s/it] 75%|███████▌  | 75/100 [01:35<00:35,  1.44s/it] 76%|███████▌  | 76/100 [01:36<00:32,  1.37s/it] 77%|███████▋  | 77/100 [01:37<00:29,  1.26s/it] 78%|███████▊  | 78/100 [01:39<00:33,  1.53s/it] 79%|███████▉  | 79/100 [01:40<00:29,  1.43s/it] 80%|████████  | 80/100 [01:41<00:23,  1.18s/it] 81%|████████  | 81/100 [01:42<00:20,  1.07s/it] 82%|████████▏ | 82/100 [01:44<00:25,  1.40s/it] 83%|████████▎ | 83/100 [01:45<00:21,  1.26s/it] 84%|████████▍ | 84/100 [01:46<00:17,  1.09s/it] 85%|████████▌ | 85/100 [01:46<00:14,  1.02it/s] 86%|████████▌ | 86/100 [01:47<00:12,  1.11it/s] 87%|████████▋ | 87/100 [01:48<00:12,  1.08it/s] 88%|████████▊ | 88/100 [01:49<00:11,  1.07it/s] 89%|████████▉ | 89/100 [01:51<00:12,  1.15s/it] 90%|█████████ | 90/100 [01:52<00:13,  1.32s/it] 91%|█████████ | 91/100 [01:53<00:10,  1.21s/it] 92%|█████████▏| 92/100 [01:54<00:09,  1.14s/it] 93%|█████████▎| 93/100 [01:56<00:09,  1.42s/it] 94%|█████████▍| 94/100 [01:58<00:08,  1.50s/it] 95%|█████████▌| 95/100 [01:59<00:06,  1.40s/it] 96%|█████████▌| 96/100 [02:01<00:06,  1.63s/it] 97%|█████████▋| 97/100 [02:02<00:04,  1.42s/it] 98%|█████████▊| 98/100 [02:03<00:02,  1.23s/it] 99%|█████████▉| 99/100 [02:04<00:01,  1.08s/it]100%|██████████| 100/100 [02:05<00:00,  1.11s/it]100%|██████████| 100/100 [02:05<00:00,  1.26s/it]