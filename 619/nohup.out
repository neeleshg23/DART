===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Traceback (most recent call last):
  File "src/train_kd.py", line 237, in <module>
    main()
  File "src/train_kd.py", line 215, in main
    curr_train_loader = torch.load(os.path.join(processed_dir, cluster_option, f"{app_name}.train_{i}.pt"))
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'processed/i/462.libquantum-s0.train_1.pt'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.1716676340 - test_loss: 0.3377211684
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.0419903944 - test_loss: 0.3963697587
Early Stop Left: 4
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0236268782 - test_loss: 0.4196388617
Early Stop Left: 3
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0146181532 - test_loss: 0.4544416597
Early Stop Left: 2
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0105178086 - test_loss: 0.4782374947
Early Stop Left: 1
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0098556970 - test_loss: 0.5037829788
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/80 [00:00<?, ?it/s] 15%|█▌        | 12/80 [00:00<00:00, 113.52it/s] 30%|███       | 24/80 [00:00<00:00, 115.23it/s] 45%|████▌     | 36/80 [00:00<00:00, 115.77it/s] 60%|██████    | 48/80 [00:00<00:00, 112.81it/s] 75%|███████▌  | 60/80 [00:00<00:00, 113.99it/s] 90%|█████████ | 72/80 [00:00<00:00, 114.69it/s]100%|██████████| 80/80 [00:00<00:00, 114.89it/s]
Best micro threshold=0.531031, fscore=0.737
p,r,f1: 0.9631336689580993 0.5963365776444984 0.7365986458695486
throttleing by fixed threshold: 0.5
p,r,f1: 0.9540330234595542 0.598469026067393 0.7355342488081649
{'model': 'vitt',
 'app': '619.lbm-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.5310307145118713,
                 'p': 0.9631336689580993,
                 'r': 0.5963365776444984,
                 'f1': 0.7365986458695486},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9540330234595542,
                 'r': 0.598469026067393,
                 'f1': 0.7355342488081649}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.1716676340 - test_loss: 0.3377211684
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.0419903944 - test_loss: 0.3963697587
Early Stop Left: 4
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0236268782 - test_loss: 0.4196388617
Early Stop Left: 3
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0146181532 - test_loss: 0.4544416597
Early Stop Left: 2
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0105178086 - test_loss: 0.4782374947
Early Stop Left: 1
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0098556970 - test_loss: 0.5037829788
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:00<00:34,  2.26it/s] 16%|█▋        | 13/80 [00:00<00:02, 30.75it/s] 31%|███▏      | 25/80 [00:00<00:01, 53.44it/s] 46%|████▋     | 37/80 [00:00<00:00, 70.44it/s] 61%|██████▏   | 49/80 [00:00<00:00, 83.44it/s] 76%|███████▋  | 61/80 [00:00<00:00, 92.93it/s] 91%|█████████▏| 73/80 [00:01<00:00, 99.85it/s]100%|██████████| 80/80 [00:01<00:00, 71.57it/s]
Best micro threshold=0.531031, fscore=0.737
p,r,f1: 0.9631336689580993 0.5963365776444984 0.7365986458695486
throttleing by fixed threshold: 0.5
p,r,f1: 0.9540330234595542 0.598469026067393 0.7355342488081649
{'model': 'vitt',
 'app': '619.lbm-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.5310307145118713,
                 'p': 0.9631336689580993,
                 'r': 0.5963365776444984,
                 'f1': 0.7365986458695486},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9540330234595542,
                 'r': 0.598469026067393,
                 'f1': 0.7355342488081649}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000005
Manual and Torch results cosine similarity (Test): 1.0000001
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
/data/neelesh/DART_by_app/619/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0772, 0.117
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000126, 6.17e-05
--- total mse / var(X): 0.0583
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:58,  1.68it/s]  2%|▏         | 2/100 [00:01<00:59,  1.65it/s]  3%|▎         | 3/100 [00:01<01:00,  1.60it/s]  4%|▍         | 4/100 [00:02<00:58,  1.64it/s]  5%|▌         | 5/100 [00:03<00:58,  1.63it/s]  6%|▌         | 6/100 [00:03<00:56,  1.66it/s]  7%|▋         | 7/100 [00:04<00:53,  1.73it/s]  8%|▊         | 8/100 [00:04<00:52,  1.75it/s]  9%|▉         | 9/100 [00:05<00:51,  1.76it/s] 10%|█         | 10/100 [00:05<00:51,  1.74it/s] 11%|█         | 11/100 [00:06<00:51,  1.72it/s] 12%|█▏        | 12/100 [00:07<00:50,  1.75it/s] 13%|█▎        | 13/100 [00:07<00:49,  1.76it/s] 14%|█▍        | 14/100 [00:08<00:49,  1.74it/s] 15%|█▌        | 15/100 [00:08<00:47,  1.78it/s] 16%|█▌        | 16/100 [00:09<00:47,  1.77it/s] 17%|█▋        | 17/100 [00:09<00:46,  1.79it/s] 18%|█▊        | 18/100 [00:10<00:47,  1.73it/s] 19%|█▉        | 19/100 [00:11<00:48,  1.68it/s] 20%|██        | 20/100 [00:11<00:48,  1.67it/s] 21%|██        | 21/100 [00:12<00:46,  1.72it/s] 22%|██▏       | 22/100 [00:12<00:43,  1.78it/s] 23%|██▎       | 23/100 [00:13<00:43,  1.76it/s] 24%|██▍       | 24/100 [00:14<00:46,  1.64it/s] 25%|██▌       | 25/100 [00:14<00:45,  1.65it/s] 26%|██▌       | 26/100 [00:15<00:45,  1.62it/s] 27%|██▋       | 27/100 [00:15<00:44,  1.65it/s] 28%|██▊       | 28/100 [00:16<00:41,  1.76it/s] 29%|██▉       | 29/100 [00:16<00:37,  1.88it/s] 30%|███       | 30/100 [00:17<00:34,  2.01it/s] 31%|███       | 31/100 [00:17<00:34,  2.03it/s] 32%|███▏      | 32/100 [00:18<00:34,  1.99it/s] 33%|███▎      | 33/100 [00:18<00:35,  1.88it/s] 34%|███▍      | 34/100 [00:19<00:33,  1.96it/s] 35%|███▌      | 35/100 [00:19<00:31,  2.07it/s] 36%|███▌      | 36/100 [00:20<00:32,  1.95it/s] 37%|███▋      | 37/100 [00:20<00:33,  1.87it/s] 38%|███▊      | 38/100 [00:21<00:33,  1.84it/s] 39%|███▉      | 39/100 [00:21<00:33,  1.83it/s] 40%|████      | 40/100 [00:22<00:32,  1.83it/s] 41%|████      | 41/100 [00:23<00:32,  1.81it/s] 42%|████▏     | 42/100 [00:23<00:30,  1.88it/s] 43%|████▎     | 43/100 [00:24<00:29,  1.92it/s] 44%|████▍     | 44/100 [00:24<00:27,  2.03it/s] 45%|████▌     | 45/100 [00:24<00:26,  2.04it/s] 46%|████▌     | 46/100 [00:25<00:27,  1.95it/s] 47%|████▋     | 47/100 [00:25<00:25,  2.05it/s] 48%|████▊     | 48/100 [00:26<00:26,  1.97it/s] 49%|████▉     | 49/100 [00:27<00:27,  1.83it/s] 50%|█████     | 50/100 [00:27<00:27,  1.80it/s] 51%|█████     | 51/100 [00:28<00:28,  1.73it/s] 52%|█████▏    | 52/100 [00:28<00:26,  1.82it/s] 53%|█████▎    | 53/100 [00:29<00:25,  1.84it/s] 54%|█████▍    | 54/100 [00:29<00:23,  1.94it/s] 55%|█████▌    | 55/100 [00:30<00:22,  1.97it/s] 56%|█████▌    | 56/100 [00:30<00:22,  1.93it/s] 57%|█████▋    | 57/100 [00:31<00:24,  1.76it/s] 58%|█████▊    | 58/100 [00:32<00:25,  1.68it/s] 59%|█████▉    | 59/100 [00:32<00:24,  1.68it/s] 60%|██████    | 60/100 [00:33<00:24,  1.65it/s] 61%|██████    | 61/100 [00:34<00:23,  1.66it/s] 62%|██████▏   | 62/100 [00:34<00:23,  1.64it/s] 63%|██████▎   | 63/100 [00:35<00:22,  1.62it/s] 64%|██████▍   | 64/100 [00:35<00:20,  1.73it/s] 65%|██████▌   | 65/100 [00:36<00:19,  1.81it/s] 66%|██████▌   | 66/100 [00:36<00:18,  1.83it/s] 67%|██████▋   | 67/100 [00:37<00:18,  1.77it/s] 68%|██████▊   | 68/100 [00:38<00:19,  1.68it/s] 69%|██████▉   | 69/100 [00:38<00:19,  1.63it/s] 70%|███████   | 70/100 [00:39<00:18,  1.64it/s] 71%|███████   | 71/100 [00:39<00:17,  1.67it/s] 72%|███████▏  | 72/100 [00:40<00:16,  1.70it/s] 73%|███████▎  | 73/100 [00:41<00:15,  1.70it/s] 74%|███████▍  | 74/100 [00:41<00:15,  1.72it/s] 75%|███████▌  | 75/100 [00:42<00:14,  1.72it/s] 76%|███████▌  | 76/100 [00:42<00:14,  1.71it/s] 77%|███████▋  | 77/100 [00:43<00:13,  1.70it/s] 78%|███████▊  | 78/100 [00:43<00:12,  1.70it/s] 79%|███████▉  | 79/100 [00:44<00:12,  1.73it/s] 80%|████████  | 80/100 [00:45<00:11,  1.69it/s] 81%|████████  | 81/100 [00:45<00:11,  1.66it/s] 82%|████████▏ | 82/100 [00:46<00:11,  1.60it/s] 83%|████████▎ | 83/100 [00:47<00:10,  1.58it/s] 84%|████████▍ | 84/100 [00:47<00:09,  1.68it/s] 85%|████████▌ | 85/100 [00:48<00:08,  1.79it/s] 86%|████████▌ | 86/100 [00:48<00:07,  1.90it/s] 87%|████████▋ | 87/100 [00:49<00:06,  1.96it/s] 88%|████████▊ | 88/100 [00:49<00:06,  2.00it/s] 89%|████████▉ | 89/100 [00:49<00:05,  2.01it/s] 90%|█████████ | 90/100 [00:50<00:04,  2.04it/s] 91%|█████████ | 91/100 [00:50<00:04,  2.06it/s] 92%|█████████▏| 92/100 [00:51<00:03,  2.04it/s] 93%|█████████▎| 93/100 [00:51<00:03,  2.00it/s] 94%|█████████▍| 94/100 [00:52<00:03,  1.94it/s] 95%|█████████▌| 95/100 [00:53<00:02,  1.91it/s] 96%|█████████▌| 96/100 [00:53<00:02,  1.80it/s] 97%|█████████▋| 97/100 [00:54<00:01,  1.77it/s] 98%|█████████▊| 98/100 [00:54<00:01,  1.77it/s] 99%|█████████▉| 99/100 [00:55<00:00,  1.81it/s]100%|██████████| 100/100 [00:55<00:00,  1.81it/s]100%|██████████| 100/100 [00:55<00:00,  1.79it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00558, 0.00563
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00552, 0.00547
--- total mse / var(X): 0.00555
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00227, 0.00222
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00201, 0.00205
--- total mse / var(X): 0.00214
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00262, 0.00253
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0021, 0.00218
--- total mse / var(X): 0.00235
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0011, 0.000421
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00128, 0.00206
--- total mse / var(X): 0.00124
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.007, 0.00623
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00901, 0.01
--- total mse / var(X): 0.00812
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:21,  4.63it/s]  2%|▏         | 2/100 [00:00<00:17,  5.53it/s]  3%|▎         | 3/100 [00:00<00:16,  5.88it/s]  4%|▍         | 4/100 [00:00<00:16,  5.71it/s]  5%|▌         | 5/100 [00:00<00:15,  6.07it/s]  6%|▌         | 6/100 [00:00<00:14,  6.41it/s]  7%|▋         | 7/100 [00:01<00:15,  6.13it/s]  8%|▊         | 8/100 [00:01<00:14,  6.17it/s]  9%|▉         | 9/100 [00:01<00:13,  6.56it/s] 10%|█         | 10/100 [00:01<00:13,  6.74it/s] 11%|█         | 11/100 [00:01<00:13,  6.67it/s] 12%|█▏        | 12/100 [00:01<00:13,  6.74it/s] 13%|█▎        | 13/100 [00:02<00:13,  6.50it/s] 14%|█▍        | 14/100 [00:02<00:13,  6.55it/s] 15%|█▌        | 15/100 [00:02<00:12,  6.64it/s] 16%|█▌        | 16/100 [00:02<00:12,  6.98it/s] 17%|█▋        | 17/100 [00:02<00:12,  6.73it/s] 18%|█▊        | 18/100 [00:02<00:12,  6.59it/s] 19%|█▉        | 19/100 [00:02<00:12,  6.71it/s] 20%|██        | 20/100 [00:03<00:12,  6.65it/s] 21%|██        | 21/100 [00:03<00:12,  6.48it/s] 22%|██▏       | 22/100 [00:03<00:12,  6.03it/s] 23%|██▎       | 23/100 [00:03<00:14,  5.20it/s] 24%|██▍       | 24/100 [00:03<00:15,  4.89it/s] 25%|██▌       | 25/100 [00:04<00:13,  5.44it/s] 26%|██▌       | 26/100 [00:04<00:12,  5.71it/s] 27%|██▋       | 27/100 [00:04<00:13,  5.57it/s] 28%|██▊       | 28/100 [00:04<00:13,  5.30it/s] 29%|██▉       | 29/100 [00:04<00:13,  5.19it/s] 30%|███       | 30/100 [00:04<00:12,  5.77it/s] 31%|███       | 31/100 [00:05<00:11,  5.84it/s] 32%|███▏      | 32/100 [00:05<00:11,  5.88it/s] 33%|███▎      | 33/100 [00:05<00:12,  5.38it/s] 34%|███▍      | 34/100 [00:05<00:13,  4.81it/s] 35%|███▌      | 35/100 [00:05<00:13,  4.91it/s] 36%|███▌      | 36/100 [00:06<00:11,  5.37it/s] 37%|███▋      | 37/100 [00:06<00:14,  4.42it/s] 38%|███▊      | 38/100 [00:06<00:14,  4.32it/s] 39%|███▉      | 39/100 [00:06<00:12,  4.91it/s] 40%|████      | 40/100 [00:06<00:11,  5.27it/s] 41%|████      | 41/100 [00:07<00:10,  5.66it/s] 42%|████▏     | 42/100 [00:07<00:09,  5.93it/s] 43%|████▎     | 43/100 [00:07<00:08,  6.42it/s] 44%|████▍     | 44/100 [00:07<00:08,  6.27it/s] 45%|████▌     | 45/100 [00:07<00:08,  6.78it/s] 46%|████▌     | 46/100 [00:07<00:08,  6.53it/s] 47%|████▋     | 47/100 [00:08<00:08,  6.28it/s] 48%|████▊     | 48/100 [00:08<00:08,  6.38it/s] 49%|████▉     | 49/100 [00:08<00:10,  4.86it/s] 50%|█████     | 50/100 [00:08<00:09,  5.46it/s] 51%|█████     | 51/100 [00:08<00:10,  4.58it/s] 52%|█████▏    | 52/100 [00:09<00:09,  5.26it/s] 53%|█████▎    | 53/100 [00:09<00:09,  5.07it/s] 54%|█████▍    | 54/100 [00:09<00:09,  5.02it/s] 55%|█████▌    | 55/100 [00:09<00:08,  5.35it/s] 56%|█████▌    | 56/100 [00:09<00:08,  5.42it/s] 57%|█████▋    | 57/100 [00:09<00:07,  5.56it/s] 58%|█████▊    | 58/100 [00:10<00:07,  5.56it/s] 59%|█████▉    | 59/100 [00:10<00:07,  5.15it/s] 60%|██████    | 60/100 [00:10<00:08,  4.95it/s] 61%|██████    | 61/100 [00:10<00:08,  4.78it/s] 62%|██████▏   | 62/100 [00:11<00:08,  4.69it/s] 63%|██████▎   | 63/100 [00:11<00:08,  4.16it/s] 64%|██████▍   | 64/100 [00:11<00:08,  4.13it/s] 65%|██████▌   | 65/100 [00:11<00:08,  4.00it/s] 66%|██████▌   | 66/100 [00:12<00:09,  3.66it/s] 67%|██████▋   | 67/100 [00:12<00:08,  3.68it/s] 68%|██████▊   | 68/100 [00:12<00:07,  4.31it/s] 69%|██████▉   | 69/100 [00:12<00:08,  3.81it/s] 70%|███████   | 70/100 [00:13<00:06,  4.47it/s] 71%|███████   | 71/100 [00:13<00:06,  4.34it/s] 72%|███████▏  | 72/100 [00:13<00:06,  4.41it/s] 73%|███████▎  | 73/100 [00:13<00:05,  4.52it/s] 74%|███████▍  | 74/100 [00:13<00:05,  4.48it/s] 75%|███████▌  | 75/100 [00:14<00:05,  4.24it/s] 76%|███████▌  | 76/100 [00:14<00:06,  3.88it/s] 77%|███████▋  | 77/100 [00:14<00:05,  4.20it/s] 78%|███████▊  | 78/100 [00:14<00:04,  4.70it/s] 79%|███████▉  | 79/100 [00:15<00:04,  5.19it/s] 80%|████████  | 80/100 [00:15<00:03,  5.36it/s] 81%|████████  | 81/100 [00:15<00:03,  5.44it/s] 82%|████████▏ | 82/100 [00:15<00:03,  5.29it/s] 83%|████████▎ | 83/100 [00:15<00:03,  5.35it/s] 84%|████████▍ | 84/100 [00:15<00:02,  5.74it/s] 85%|████████▌ | 85/100 [00:16<00:02,  5.83it/s] 86%|████████▌ | 86/100 [00:16<00:02,  6.12it/s] 87%|████████▋ | 87/100 [00:16<00:02,  4.68it/s] 88%|████████▊ | 88/100 [00:16<00:02,  4.53it/s] 89%|████████▉ | 89/100 [00:17<00:02,  3.99it/s] 90%|█████████ | 90/100 [00:17<00:02,  3.88it/s] 91%|█████████ | 91/100 [00:17<00:02,  4.29it/s] 92%|█████████▏| 92/100 [00:17<00:02,  3.90it/s] 93%|█████████▎| 93/100 [00:18<00:01,  4.18it/s] 94%|█████████▍| 94/100 [00:18<00:01,  4.42it/s] 95%|█████████▌| 95/100 [00:18<00:01,  4.24it/s] 96%|█████████▌| 96/100 [00:18<00:00,  4.52it/s] 97%|█████████▋| 97/100 [00:18<00:00,  4.87it/s] 98%|█████████▊| 98/100 [00:19<00:00,  5.00it/s] 99%|█████████▉| 99/100 [00:19<00:00,  5.34it/s]100%|██████████| 100/100 [00:19<00:00,  4.84it/s]100%|██████████| 100/100 [00:19<00:00,  5.13it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0101, 0.00381
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00197, 0.0032
--- total mse / var(X): 0.0035
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:21,  4.55it/s]  2%|▏         | 2/100 [00:00<00:17,  5.49it/s]  3%|▎         | 3/100 [00:00<00:15,  6.26it/s]  4%|▍         | 4/100 [00:00<00:14,  6.72it/s]  5%|▌         | 5/100 [00:00<00:13,  6.93it/s]  6%|▌         | 6/100 [00:00<00:13,  7.06it/s]  7%|▋         | 7/100 [00:01<00:12,  7.22it/s]  8%|▊         | 8/100 [00:01<00:13,  7.08it/s]  9%|▉         | 9/100 [00:01<00:12,  7.49it/s] 10%|█         | 10/100 [00:01<00:11,  8.00it/s] 11%|█         | 11/100 [00:01<00:10,  8.28it/s] 13%|█▎        | 13/100 [00:01<00:09,  8.81it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.20it/s] 17%|█▋        | 17/100 [00:02<00:08,  9.71it/s] 19%|█▉        | 19/100 [00:02<00:07, 10.19it/s] 21%|██        | 21/100 [00:02<00:07, 10.86it/s] 23%|██▎       | 23/100 [00:02<00:06, 11.20it/s] 25%|██▌       | 25/100 [00:02<00:06, 11.01it/s] 27%|██▋       | 27/100 [00:03<00:06, 10.52it/s] 29%|██▉       | 29/100 [00:03<00:07,  9.54it/s] 31%|███       | 31/100 [00:03<00:06, 10.29it/s] 33%|███▎      | 33/100 [00:03<00:07,  9.37it/s] 35%|███▌      | 35/100 [00:03<00:06, 10.76it/s] 37%|███▋      | 37/100 [00:03<00:05, 11.04it/s] 39%|███▉      | 39/100 [00:04<00:04, 12.55it/s] 41%|████      | 41/100 [00:04<00:04, 13.13it/s] 43%|████▎     | 43/100 [00:04<00:04, 13.89it/s] 45%|████▌     | 45/100 [00:04<00:03, 14.23it/s] 47%|████▋     | 47/100 [00:04<00:03, 13.90it/s] 49%|████▉     | 49/100 [00:04<00:03, 13.47it/s] 51%|█████     | 51/100 [00:04<00:03, 12.97it/s] 53%|█████▎    | 53/100 [00:05<00:03, 13.31it/s] 55%|█████▌    | 55/100 [00:05<00:03, 13.18it/s] 57%|█████▋    | 57/100 [00:05<00:03, 12.92it/s] 59%|█████▉    | 59/100 [00:05<00:03, 12.41it/s] 61%|██████    | 61/100 [00:05<00:03, 12.32it/s] 63%|██████▎   | 63/100 [00:05<00:03, 11.39it/s] 65%|██████▌   | 65/100 [00:06<00:03, 11.47it/s] 67%|██████▋   | 67/100 [00:06<00:02, 11.87it/s] 69%|██████▉   | 69/100 [00:06<00:02, 10.60it/s] 71%|███████   | 71/100 [00:06<00:03,  8.74it/s] 72%|███████▏  | 72/100 [00:06<00:03,  8.87it/s] 73%|███████▎  | 73/100 [00:07<00:03,  8.87it/s] 74%|███████▍  | 74/100 [00:07<00:03,  7.31it/s] 75%|███████▌  | 75/100 [00:07<00:03,  7.01it/s] 76%|███████▌  | 76/100 [00:07<00:03,  7.55it/s] 77%|███████▋  | 77/100 [00:07<00:03,  6.98it/s] 78%|███████▊  | 78/100 [00:07<00:03,  6.79it/s] 80%|████████  | 80/100 [00:08<00:02,  8.15it/s] 81%|████████  | 81/100 [00:08<00:02,  8.50it/s] 82%|████████▏ | 82/100 [00:08<00:03,  5.82it/s] 83%|████████▎ | 83/100 [00:08<00:03,  5.19it/s] 84%|████████▍ | 84/100 [00:08<00:03,  5.09it/s] 85%|████████▌ | 85/100 [00:09<00:02,  5.23it/s] 86%|████████▌ | 86/100 [00:09<00:02,  5.98it/s] 87%|████████▋ | 87/100 [00:09<00:02,  6.43it/s] 89%|████████▉ | 89/100 [00:09<00:01,  8.55it/s] 90%|█████████ | 90/100 [00:09<00:01,  8.32it/s] 92%|█████████▏| 92/100 [00:09<00:00,  8.80it/s] 94%|█████████▍| 94/100 [00:10<00:00,  9.49it/s] 96%|█████████▌| 96/100 [00:10<00:00, 10.51it/s] 98%|█████████▊| 98/100 [00:10<00:00,  9.96it/s]100%|██████████| 100/100 [00:10<00:00, 10.09it/s]100%|██████████| 100/100 [00:10<00:00,  9.42it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00768, 0.00714
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00838, 0.00897
--- total mse / var(X): 0.00806
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:09, 10.42it/s]  4%|▍         | 4/100 [00:00<00:08, 11.86it/s]  6%|▌         | 6/100 [00:00<00:07, 12.79it/s]  8%|▊         | 8/100 [00:00<00:06, 13.63it/s] 10%|█         | 10/100 [00:00<00:06, 14.03it/s] 12%|█▏        | 12/100 [00:00<00:06, 14.35it/s] 14%|█▍        | 14/100 [00:01<00:05, 14.53it/s] 16%|█▌        | 16/100 [00:01<00:06, 13.86it/s] 18%|█▊        | 18/100 [00:01<00:05, 14.34it/s] 20%|██        | 20/100 [00:01<00:05, 14.86it/s] 22%|██▏       | 22/100 [00:01<00:05, 14.97it/s] 24%|██▍       | 24/100 [00:01<00:05, 15.11it/s] 26%|██▌       | 26/100 [00:01<00:06, 12.30it/s] 28%|██▊       | 28/100 [00:02<00:05, 12.88it/s] 30%|███       | 30/100 [00:02<00:05, 13.98it/s] 32%|███▏      | 32/100 [00:02<00:04, 14.23it/s] 34%|███▍      | 34/100 [00:02<00:04, 13.27it/s] 36%|███▌      | 36/100 [00:02<00:04, 14.29it/s] 38%|███▊      | 38/100 [00:02<00:03, 15.51it/s] 40%|████      | 40/100 [00:02<00:04, 13.11it/s] 42%|████▏     | 42/100 [00:03<00:04, 13.90it/s] 45%|████▌     | 45/100 [00:03<00:03, 16.29it/s] 48%|████▊     | 48/100 [00:03<00:03, 16.86it/s] 50%|█████     | 50/100 [00:03<00:02, 17.09it/s] 52%|█████▏    | 52/100 [00:03<00:02, 16.33it/s] 55%|█████▌    | 55/100 [00:03<00:02, 17.91it/s] 57%|█████▋    | 57/100 [00:03<00:02, 17.91it/s] 59%|█████▉    | 59/100 [00:03<00:02, 18.17it/s] 61%|██████    | 61/100 [00:04<00:02, 17.92it/s] 63%|██████▎   | 63/100 [00:04<00:02, 17.48it/s] 65%|██████▌   | 65/100 [00:04<00:02, 17.36it/s] 67%|██████▋   | 67/100 [00:04<00:01, 17.66it/s] 69%|██████▉   | 69/100 [00:04<00:01, 18.16it/s] 71%|███████   | 71/100 [00:04<00:01, 18.52it/s] 73%|███████▎  | 73/100 [00:04<00:01, 18.62it/s] 76%|███████▌  | 76/100 [00:04<00:01, 19.35it/s] 78%|███████▊  | 78/100 [00:04<00:01, 18.67it/s] 80%|████████  | 80/100 [00:05<00:01, 17.94it/s] 82%|████████▏ | 82/100 [00:05<00:01, 17.93it/s] 85%|████████▌ | 85/100 [00:05<00:00, 20.57it/s] 88%|████████▊ | 88/100 [00:05<00:00, 22.22it/s] 91%|█████████ | 91/100 [00:05<00:00, 23.16it/s] 94%|█████████▍| 94/100 [00:05<00:00, 23.01it/s] 97%|█████████▋| 97/100 [00:05<00:00, 23.12it/s]100%|██████████| 100/100 [00:05<00:00, 22.23it/s]100%|██████████| 100/100 [00:05<00:00, 16.76it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00254, 0.00223
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00233, 0.00261
--- total mse / var(X): 0.00242
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:16,  6.03it/s]  3%|▎         | 3/100 [00:00<00:10,  9.40it/s]  4%|▍         | 4/100 [00:00<00:10,  8.96it/s]  5%|▌         | 5/100 [00:00<00:12,  7.90it/s]  6%|▌         | 6/100 [00:00<00:12,  7.36it/s]  8%|▊         | 8/100 [00:00<00:09,  9.72it/s] 10%|█         | 10/100 [00:01<00:09,  9.19it/s] 12%|█▏        | 12/100 [00:01<00:09,  8.82it/s] 14%|█▍        | 14/100 [00:01<00:08, 10.21it/s] 16%|█▌        | 16/100 [00:01<00:07, 11.06it/s] 18%|█▊        | 18/100 [00:01<00:06, 12.52it/s] 21%|██        | 21/100 [00:01<00:05, 15.68it/s] 23%|██▎       | 23/100 [00:02<00:04, 16.04it/s] 25%|██▌       | 25/100 [00:02<00:04, 16.40it/s] 27%|██▋       | 27/100 [00:02<00:05, 13.46it/s] 29%|██▉       | 29/100 [00:02<00:05, 13.15it/s] 32%|███▏      | 32/100 [00:02<00:04, 14.48it/s] 34%|███▍      | 34/100 [00:02<00:04, 14.22it/s] 36%|███▌      | 36/100 [00:02<00:04, 14.97it/s] 38%|███▊      | 38/100 [00:03<00:04, 14.38it/s] 41%|████      | 41/100 [00:03<00:03, 16.68it/s] 44%|████▍     | 44/100 [00:03<00:03, 17.78it/s] 47%|████▋     | 47/100 [00:03<00:03, 16.93it/s] 49%|████▉     | 49/100 [00:03<00:02, 17.33it/s] 52%|█████▏    | 52/100 [00:03<00:02, 19.20it/s] 55%|█████▌    | 55/100 [00:03<00:02, 20.07it/s] 58%|█████▊    | 58/100 [00:04<00:02, 20.80it/s] 61%|██████    | 61/100 [00:04<00:02, 18.28it/s] 63%|██████▎   | 63/100 [00:04<00:01, 18.59it/s] 65%|██████▌   | 65/100 [00:04<00:02, 17.31it/s] 67%|██████▋   | 67/100 [00:04<00:02, 14.32it/s] 69%|██████▉   | 69/100 [00:04<00:02, 14.21it/s] 72%|███████▏  | 72/100 [00:04<00:01, 16.93it/s] 75%|███████▌  | 75/100 [00:05<00:01, 17.44it/s] 77%|███████▋  | 77/100 [00:05<00:01, 17.47it/s] 80%|████████  | 80/100 [00:05<00:01, 18.23it/s] 82%|████████▏ | 82/100 [00:05<00:01, 12.55it/s] 84%|████████▍ | 84/100 [00:05<00:01, 13.25it/s] 87%|████████▋ | 87/100 [00:06<00:00, 13.38it/s] 90%|█████████ | 90/100 [00:06<00:00, 15.70it/s] 92%|█████████▏| 92/100 [00:06<00:00, 14.58it/s] 94%|█████████▍| 94/100 [00:06<00:00, 15.44it/s] 96%|█████████▌| 96/100 [00:06<00:00, 13.91it/s] 98%|█████████▊| 98/100 [00:06<00:00, 14.86it/s]100%|██████████| 100/100 [00:06<00:00, 14.81it/s]100%|██████████| 100/100 [00:06<00:00, 14.47it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00334, 0.00282
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00654, 0.00755
--- total mse / var(X): 0.00518
start table evaluation...
Elapsed time: 301.45371985435486 seconds
Cosine similarity between AMM and exact (Train): 0.9324147
Cosine similarity between AMM and exact (Test): 0.9190801
p,r,f1: 0.9759338114904328 0.6096598482383686 0.7504919759905146
p,r,f1: 0.9073389182176486 0.4917912662163877 0.6378553767792042
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9759338114904328, 0.6096598482383686, 0.7504919759905146],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9969394207000732,
                                      0.9974357485771179,
                                      0.9974584579467773,
                                      0.9324147701263428],
               'cossim_layer_test': [0.9920830726623535,
                                     0.9966052770614624,
                                     0.996391236782074,
                                     0.9190800786018372],
               'cossim_amm_train': [0.9944331645965576,
                                    0.9978903532028198,
                                    0.9973475933074951,
                                    0.9925083518028259,
                                    0.9962157011032104,
                                    0.9810176491737366,
                                    0.9903329014778137,
                                    0.9531732797622681],
               'cossim_amm_test': [0.9863839745521545,
                                   0.9969002604484558,
                                   0.9960820078849792,
                                   0.9907883405685425,
                                   0.9958125352859497,
                                   0.979095458984375,
                                   0.987308144569397,
                                   0.9478233456611633],
               'f1': [0.9073389182176486,
                      0.4917912662163877,
                      0.6378553767792042],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5612459274 - test_loss: 0.5688281737
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.4221748544 - test_loss: 0.4817404650
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.3395849186 - test_loss: 0.4331813127
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2856382457 - test_loss: 0.4057011329
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2481610029 - test_loss: 0.3845110083
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2173358054 - test_loss: 0.3649780061
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.1923270604 - test_loss: 0.3483815186
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.1712441080 - test_loss: 0.3380195383
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.1559755856 - test_loss: 0.3329030726
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.1445625884 - test_loss: 0.3301743744
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.1359358992 - test_loss: 0.3285367345
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.1293363074 - test_loss: 0.3279655425
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.1241837688 - test_loss: 0.3276533187
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.1200821796 - test_loss: 0.3280180493
Early Stop Left: 4
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.1167087352 - test_loss: 0.3281972929
Early Stop Left: 3
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.1138529131 - test_loss: 0.3284044770
Early Stop Left: 2
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.1113772206 - test_loss: 0.3283058356
Early Stop Left: 1
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.1091971421 - test_loss: 0.3287383117
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/80 [00:00<?, ?it/s] 18%|█▊        | 14/80 [00:00<00:00, 139.75it/s] 35%|███▌      | 28/80 [00:00<00:00, 132.44it/s] 54%|█████▍    | 43/80 [00:00<00:00, 135.94it/s] 71%|███████▏  | 57/80 [00:00<00:00, 136.67it/s] 89%|████████▉ | 71/80 [00:00<00:00, 137.39it/s]100%|██████████| 80/80 [00:00<00:00, 137.62it/s]
Best micro threshold=0.478680, fscore=0.727
p,r,f1: 0.9457303242066675 0.590736873038696 0.7272238228858222
throttleing by fixed threshold: 0.5
p,r,f1: 0.9528054413828215 0.5856771978769019 0.7254373975899627
{'model': 'vit_large',
 'app': '619.lbm-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.4786800742149353,
                 'p': 0.9457303242066675,
                 'r': 0.590736873038696,
                 'f1': 0.7272238228858222},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9528054413828215,
                 'r': 0.5856771978769019,
                 'f1': 0.7254373975899627}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6215150360 - test_loss: 0.6648321763
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.5417945705 - test_loss: 0.5891454995
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.4602304255 - test_loss: 0.5200226095
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3947101924 - test_loss: 0.4740003150
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3476391279 - test_loss: 0.4434763186
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3120280976 - test_loss: 0.4221008044
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2841172741 - test_loss: 0.4071591433
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2619520820 - test_loss: 0.3970770322
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2442418616 - test_loss: 0.3907082357
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2299773358 - test_loss: 0.3871139636
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2183758701 - test_loss: 0.3853304179
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2085523641 - test_loss: 0.3839812981
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.1988780468 - test_loss: 0.3790595915
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.1861986810 - test_loss: 0.3639284035
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.1727772506 - test_loss: 0.3540077833
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.1619323077 - test_loss: 0.3485062007
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.1530671123 - test_loss: 0.3452687452
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.1457585281 - test_loss: 0.3432180081
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.1397056527 - test_loss: 0.3424409781
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.1347618618 - test_loss: 0.3425746656
Early Stop Left: 4
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.1306948751 - test_loss: 0.3426097896
Early Stop Left: 3
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.1273491482 - test_loss: 0.3435252831
Early Stop Left: 2
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.1245757118 - test_loss: 0.3444137039
Early Stop Left: 1
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.1222629328 - test_loss: 0.3449908099
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/80 [00:00<?, ?it/s] 22%|██▎       | 18/80 [00:00<00:00, 174.46it/s] 45%|████▌     | 36/80 [00:00<00:00, 176.48it/s] 68%|██████▊   | 54/80 [00:00<00:00, 177.87it/s] 91%|█████████▏| 73/80 [00:00<00:00, 178.77it/s]100%|██████████| 80/80 [00:00<00:00, 176.89it/s]
Best micro threshold=0.484403, fscore=0.711
p,r,f1: 0.9153948106771214 0.5805535969682022 0.7105001045071176
throttleing by fixed threshold: 0.5
p,r,f1: 0.9234318230758305 0.5769088752789595 0.7101533872028564
{'model': 'vit_min',
 'app': '619.lbm-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.48440277576446533,
                 'p': 0.9153948106771214,
                 'r': 0.5805535969682022,
                 'f1': 0.7105001045071176},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9234318230758305,
                 'r': 0.5769088752789595,
                 'f1': 0.7101533872028564}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0
Manual and Torch results cosine similarity (Test): 1.0000002
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:01<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.144, 0.144
--- total mse / var(X): 0.144
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<02:01,  1.23s/it]  2%|▏         | 2/100 [00:02<01:52,  1.14s/it]  3%|▎         | 3/100 [00:03<01:50,  1.14s/it]  4%|▍         | 4/100 [00:05<02:09,  1.35s/it]  5%|▌         | 5/100 [00:07<02:30,  1.59s/it]  6%|▌         | 6/100 [00:08<02:13,  1.42s/it]  7%|▋         | 7/100 [00:09<01:57,  1.26s/it]  8%|▊         | 8/100 [00:10<01:55,  1.25s/it]  9%|▉         | 9/100 [00:12<02:16,  1.50s/it] 10%|█         | 10/100 [00:13<02:12,  1.47s/it] 11%|█         | 11/100 [00:14<01:58,  1.34s/it] 12%|█▏        | 12/100 [00:15<01:49,  1.25s/it] 13%|█▎        | 13/100 [00:19<02:55,  2.02s/it] 14%|█▍        | 14/100 [00:21<02:36,  1.82s/it] 15%|█▌        | 15/100 [00:22<02:13,  1.57s/it] 16%|█▌        | 16/100 [00:23<01:59,  1.42s/it] 17%|█▋        | 17/100 [00:24<02:02,  1.48s/it] 18%|█▊        | 18/100 [00:27<02:39,  1.94s/it] 19%|█▉        | 19/100 [00:29<02:38,  1.96s/it] 20%|██        | 20/100 [00:30<02:12,  1.66s/it] 21%|██        | 21/100 [00:32<02:23,  1.81s/it] 22%|██▏       | 22/100 [00:35<02:39,  2.05s/it] 23%|██▎       | 23/100 [00:36<02:14,  1.74s/it] 24%|██▍       | 24/100 [00:37<01:49,  1.44s/it] 25%|██▌       | 25/100 [00:37<01:32,  1.23s/it] 26%|██▌       | 26/100 [00:39<01:38,  1.34s/it] 27%|██▋       | 27/100 [00:41<01:52,  1.55s/it] 28%|██▊       | 28/100 [00:43<01:54,  1.59s/it] 29%|██▉       | 29/100 [00:44<01:40,  1.42s/it] 30%|███       | 30/100 [00:45<01:38,  1.41s/it] 31%|███       | 31/100 [00:47<01:42,  1.49s/it] 32%|███▏      | 32/100 [00:49<01:46,  1.57s/it] 33%|███▎      | 33/100 [00:50<01:37,  1.46s/it] 34%|███▍      | 34/100 [00:51<01:30,  1.37s/it] 35%|███▌      | 35/100 [00:52<01:28,  1.36s/it] 36%|███▌      | 36/100 [00:54<01:37,  1.52s/it] 37%|███▋      | 37/100 [00:56<01:35,  1.52s/it] 38%|███▊      | 38/100 [00:57<01:25,  1.39s/it] 39%|███▉      | 39/100 [00:58<01:15,  1.25s/it] 40%|████      | 40/100 [00:59<01:08,  1.15s/it] 41%|████      | 41/100 [01:00<01:05,  1.11s/it] 42%|████▏     | 42/100 [01:00<00:58,  1.01s/it] 43%|████▎     | 43/100 [01:01<00:56,  1.01it/s] 44%|████▍     | 44/100 [01:03<01:03,  1.14s/it] 45%|████▌     | 45/100 [01:04<01:01,  1.11s/it] 46%|████▌     | 46/100 [01:05<00:57,  1.07s/it] 47%|████▋     | 47/100 [01:06<00:55,  1.04s/it] 48%|████▊     | 48/100 [01:07<00:54,  1.06s/it] 49%|████▉     | 49/100 [01:10<01:21,  1.61s/it] 50%|█████     | 50/100 [01:11<01:16,  1.54s/it] 51%|█████     | 51/100 [01:12<01:05,  1.34s/it] 52%|█████▏    | 52/100 [01:13<01:03,  1.32s/it] 53%|█████▎    | 53/100 [01:17<01:36,  2.04s/it] 54%|█████▍    | 54/100 [01:18<01:19,  1.74s/it] 55%|█████▌    | 55/100 [01:19<01:07,  1.50s/it] 56%|█████▌    | 56/100 [01:20<01:03,  1.45s/it] 57%|█████▋    | 57/100 [01:23<01:22,  1.91s/it] 58%|█████▊    | 58/100 [01:25<01:12,  1.72s/it] 59%|█████▉    | 59/100 [01:26<00:59,  1.46s/it] 60%|██████    | 60/100 [01:29<01:18,  1.95s/it] 61%|██████    | 61/100 [01:30<01:09,  1.78s/it] 62%|██████▏   | 62/100 [01:31<00:59,  1.57s/it] 63%|██████▎   | 63/100 [01:32<00:51,  1.40s/it] 64%|██████▍   | 64/100 [01:34<00:55,  1.55s/it] 65%|██████▌   | 65/100 [01:35<00:52,  1.51s/it] 66%|██████▌   | 66/100 [01:37<00:47,  1.39s/it] 67%|██████▋   | 67/100 [01:38<00:43,  1.32s/it] 68%|██████▊   | 68/100 [01:39<00:40,  1.26s/it] 69%|██████▉   | 69/100 [01:40<00:38,  1.23s/it] 70%|███████   | 70/100 [01:41<00:35,  1.17s/it] 71%|███████   | 71/100 [01:42<00:33,  1.15s/it] 72%|███████▏  | 72/100 [01:43<00:30,  1.08s/it] 73%|███████▎  | 73/100 [01:44<00:27,  1.02s/it] 74%|███████▍  | 74/100 [01:45<00:26,  1.00s/it] 75%|███████▌  | 75/100 [01:46<00:24,  1.04it/s] 76%|███████▌  | 76/100 [01:47<00:23,  1.02it/s] 77%|███████▋  | 77/100 [01:48<00:22,  1.04it/s] 78%|███████▊  | 78/100 [01:50<00:29,  1.34s/it] 79%|███████▉  | 79/100 [01:51<00:27,  1.32s/it] 80%|████████  | 80/100 [01:52<00:24,  1.24s/it] 81%|████████  | 81/100 [01:53<00:21,  1.11s/it] 82%|████████▏ | 82/100 [01:54<00:20,  1.16s/it] 83%|████████▎ | 83/100 [01:56<00:23,  1.36s/it] 84%|████████▍ | 84/100 [01:57<00:21,  1.35s/it] 85%|████████▌ | 85/100 [01:59<00:19,  1.27s/it] 86%|████████▌ | 86/100 [01:59<00:15,  1.11s/it] 87%|████████▋ | 87/100 [02:00<00:13,  1.03s/it] 88%|████████▊ | 88/100 [02:01<00:13,  1.09s/it] 89%|████████▉ | 89/100 [02:03<00:12,  1.12s/it] 90%|█████████ | 90/100 [02:04<00:10,  1.10s/it] 91%|█████████ | 91/100 [02:04<00:09,  1.04s/it] 92%|█████████▏| 92/100 [02:05<00:08,  1.01s/it] 93%|█████████▎| 93/100 [02:06<00:06,  1.00it/s] 94%|█████████▍| 94/100 [02:07<00:05,  1.04it/s] 95%|█████████▌| 95/100 [02:09<00:05,  1.09s/it] 96%|█████████▌| 96/100 [02:10<00:04,  1.17s/it] 97%|█████████▋| 97/100 [02:11<00:03,  1.15s/it] 98%|█████████▊| 98/100 [02:12<00:02,  1.08s/it] 99%|█████████▉| 99/100 [02:13<00:01,  1.11s/it]100%|██████████| 100/100 [02:14<00:00,  1.08s/it]100%|██████████| 100/100 [02:14<00:00,  1.35s/it]