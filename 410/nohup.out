===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Traceback (most recent call last):
  File "src/train.py", line 189, in <module>
    main()
  File "src/train.py", line 172, in main
    test_df = torch.load(os.path.join(processed_dir, f"{app_name}.df.pt"))
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'processed/410.bwaves-s0.df.pt'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.3459896847 - test_loss: 0.2084060650
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.1872120857 - test_loss: 0.1629033226
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1532482513 - test_loss: 0.1436176086
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1342058360 - test_loss: 0.1258455566
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1213509223 - test_loss: 0.1158372012
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1132501838 - test_loss: 0.1064497872
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.1069573933 - test_loss: 0.1015156117
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.1023880191 - test_loss: 0.1061478329
Early Stop Left: 4
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0998513665 - test_loss: 0.0961721021
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0982148615 - test_loss: 0.0949503670
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0969109582 - test_loss: 0.0940432700
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0958368134 - test_loss: 0.0934369721
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0950171357 - test_loss: 0.0926723769
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0940587837 - test_loss: 0.0915219359
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0930741231 - test_loss: 0.0914173620
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0921376600 - test_loss: 0.0911430461
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0912746816 - test_loss: 0.0891242281
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0905529850 - test_loss: 0.0885675613
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0899958223 - test_loss: 0.0880190364
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0890411879 - test_loss: 0.0881176292
Early Stop Left: 4
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.0885644612 - test_loss: 0.0920607876
Early Stop Left: 3
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.0878215180 - test_loss: 0.0860736167
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.0870019971 - test_loss: 0.0851504683
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.0864208169 - test_loss: 0.0874904809
Early Stop Left: 4
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.0860328363 - test_loss: 0.0853887495
Early Stop Left: 3
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.0853367153 - test_loss: 0.0835185778
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.0851441103 - test_loss: 0.0840754377
Early Stop Left: 4
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.0844984538 - test_loss: 0.0828404724
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.0840644223 - test_loss: 0.0835231806
Early Stop Left: 4
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.0834166804 - test_loss: 0.0834033478
Early Stop Left: 3
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.0829899160 - test_loss: 0.0844662362
Early Stop Left: 2
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.0823691753 - test_loss: 0.0812874120
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.0815120570 - test_loss: 0.0812650652
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.0806878196 - test_loss: 0.0787855247
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.0794157619 - test_loss: 0.0775504975
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.0786395686 - test_loss: 0.0771573529
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.0780226942 - test_loss: 0.0762115625
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.0772821215 - test_loss: 0.0766498232
Early Stop Left: 4
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.0767490044 - test_loss: 0.0788189561
Early Stop Left: 3
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.0764596018 - test_loss: 0.0742170771
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.0760311438 - test_loss: 0.0751520774
Early Stop Left: 4
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.0755008980 - test_loss: 0.0740483420
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.0753265443 - test_loss: 0.0742104080
Early Stop Left: 4
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.0749241280 - test_loss: 0.0734295499
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.0745377250 - test_loss: 0.0731184465
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.0741872433 - test_loss: 0.0718007466
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.0738132941 - test_loss: 0.0725312951
Early Stop Left: 4
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.0735522212 - test_loss: 0.0712790235
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.0733170457 - test_loss: 0.0713045666
Early Stop Left: 4
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.0730134746 - test_loss: 0.0732929651
Early Stop Left: 3
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.0728602316 - test_loss: 0.0746554315
Early Stop Left: 2
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.0726821508 - test_loss: 0.0743779516
Early Stop Left: 1
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.0723540208 - test_loss: 0.0703492035
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.0722994561 - test_loss: 0.0706766679
Early Stop Left: 4
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.0720526055 - test_loss: 0.0710633369
Early Stop Left: 3
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.0719936620 - test_loss: 0.0709564583
Early Stop Left: 2
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.0719034975 - test_loss: 0.0706759051
Early Stop Left: 1
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.0716830279 - test_loss: 0.0701023072
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.0714053435 - test_loss: 0.0707539148
Early Stop Left: 4
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.0712458960 - test_loss: 0.0694081325
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.0712038621 - test_loss: 0.0695952003
Early Stop Left: 4
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.0709311311 - test_loss: 0.0704015847
Early Stop Left: 3
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.0709220010 - test_loss: 0.0693355828
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.0708912580 - test_loss: 0.0716155104
Early Stop Left: 4
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.0707798415 - test_loss: 0.0693328004
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.0704672123 - test_loss: 0.0699904597
Early Stop Left: 4
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.0704948336 - test_loss: 0.0701700716
Early Stop Left: 3
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.0704473371 - test_loss: 0.0685804693
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.0701032712 - test_loss: 0.0708496298
Early Stop Left: 4
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.0701556353 - test_loss: 0.0683629093
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.0700957089 - test_loss: 0.0690684690
Early Stop Left: 4
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.0697355800 - test_loss: 0.0690159670
Early Stop Left: 3
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.0699409470 - test_loss: 0.0694795666
Early Stop Left: 2
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.0697068070 - test_loss: 0.0696300125
Early Stop Left: 1
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.0697315084 - test_loss: 0.0686442875
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/173 [00:00<?, ?it/s] 11%|█         | 19/173 [00:00<00:00, 186.17it/s] 22%|██▏       | 38/173 [00:00<00:00, 179.74it/s] 33%|███▎      | 57/173 [00:00<00:00, 180.66it/s] 45%|████▍     | 77/173 [00:00<00:00, 185.10it/s] 56%|█████▌    | 97/173 [00:00<00:00, 187.37it/s] 67%|██████▋   | 116/173 [00:00<00:00, 188.16it/s] 78%|███████▊  | 135/173 [00:00<00:00, 187.96it/s] 89%|████████▉ | 154/173 [00:00<00:00, 184.97it/s]100%|██████████| 173/173 [00:00<00:00, 182.45it/s]100%|██████████| 173/173 [00:00<00:00, 184.29it/s]
Best micro threshold=0.476545, fscore=0.924
p,r,f1: 0.9052935784251745 0.9424542386004815 0.9235002334225532
throttleing by fixed threshold: 0.5
p,r,f1: 0.9089488563110346 0.9382372938771066 0.9233608806899023
{'model': 'vit',
 'app': '410.bwaves-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.47654488682746887,
                 'p': 0.9052935784251745,
                 'r': 0.9424542386004815,
                 'f1': 0.9235002334225532},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9089488563110346,
                 'r': 0.9382372938771066,
                 'f1': 0.9233608806899023}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/174 [00:00<?, ?it/s]  1%|          | 1/174 [00:00<01:35,  1.81it/s] 18%|█▊        | 32/174 [00:00<00:02, 65.01it/s] 37%|███▋      | 64/174 [00:00<00:00, 122.52it/s] 55%|█████▌    | 96/174 [00:00<00:00, 169.57it/s] 74%|███████▎  | 128/174 [00:00<00:00, 207.69it/s] 91%|█████████ | 158/174 [00:01<00:00, 231.06it/s]100%|██████████| 174/174 [00:01<00:00, 156.79it/s]
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
             app  mean  max  min  median
0  410.bwaves-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/410.bwaves-s0.vit.pkl.degree_stats.csv
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/174 [00:00<?, ?it/s]  1%|          | 1/174 [00:00<01:33,  1.85it/s]  9%|▉         | 16/174 [00:00<00:04, 32.63it/s] 18%|█▊        | 31/174 [00:00<00:02, 59.11it/s] 26%|██▋       | 46/174 [00:00<00:01, 81.16it/s] 36%|███▌      | 62/174 [00:00<00:01, 100.27it/s] 45%|████▍     | 78/174 [00:01<00:00, 114.68it/s] 54%|█████▍    | 94/174 [00:01<00:00, 125.45it/s] 63%|██████▎   | 110/174 [00:01<00:00, 133.28it/s] 72%|███████▏  | 126/174 [00:01<00:00, 138.75it/s] 82%|████████▏ | 142/174 [00:01<00:00, 142.46it/s] 91%|█████████ | 158/174 [00:01<00:00, 145.36it/s]100%|██████████| 174/174 [00:01<00:00, 147.86it/s]100%|██████████| 174/174 [00:01<00:00, 103.14it/s]
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
             app  mean  max  min  median
0  410.bwaves-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/410.bwaves-s0.vitt.pkl.degree_stats.csv
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000008
Manual and Torch results cosine similarity (Test): 1.0000013
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.138, 0.214
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00753, 0.00338
--- total mse / var(X): 0.109
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.017, 0.0149
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0127, 0.0143
--- total mse / var(X): 0.0146
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0121, 0.0124
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00896, 0.00877
--- total mse / var(X): 0.0106
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0264, 0.0238
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.059, 0.0647
--- total mse / var(X): 0.0443
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00861, 0.00202
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00882, 0.0156
--- total mse / var(X): 0.0088
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.121, 0.0907
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.118, 0.147
--- total mse / var(X): 0.119
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00175, 0.00233
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0149, 0.00993
--- total mse / var(X): 0.00613
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0211, 0.0187
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0164, 0.0182
--- total mse / var(X): 0.0185
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00263, 0.00318
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00319, 0.00252
--- total mse / var(X): 0.00285
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000251, 0.00027
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000111, 0.000103
--- total mse / var(X): 0.000187
start table evaluation...
Elapsed time: 128.57207822799683 seconds
Cosine similarity between AMM and exact (Train): 0.6776999
Cosine similarity between AMM and exact (Test): 0.6914053
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.8029651863884272 0.4308281210302818 0.5607746134208124
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32],
               'cossim_layer_train': [0.9901862740516663,
                                      0.9586554169654846,
                                      0.9405801892280579,
                                      0.6776999235153198],
               'cossim_layer_test': [0.9840981960296631,
                                     0.9593378901481628,
                                     0.9409223198890686,
                                     0.6914053559303284],
               'cossim_amm_train': [0.9830537438392639,
                                    0.9939692616462708,
                                    0.9479004740715027,
                                    0.8876906037330627,
                                    0.950520932674408,
                                    0.8848085999488831,
                                    0.8870238661766052,
                                    0.8886950612068176],
               'cossim_amm_test': [0.9730662107467651,
                                   0.9938348531723022,
                                   0.9482291340827942,
                                   0.8874813318252563,
                                   0.9513506889343262,
                                   0.8862922191619873,
                                   0.8882431983947754,
                                   0.8930703401565552],
               'f1': [0.8029651863884272,
                      0.4308281210302818,
                      0.5607746134208124],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 32),
                              (192, 2, 32),
                              (32, 32, 2),
                              (32, 32, 2),
                              (32, 2, 32),
                              (32, 2, 32),
                              (32, 2, 32),
                              (256, 2, 32)],
               'lut_total_size': 40960}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 1.0000013
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0887, 0.138
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000584, 0.000262
--- total mse / var(X): 0.0689
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0121, 0.0105
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00878, 0.00988
--- total mse / var(X): 0.0102
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00124, 0.00127
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00234, 0.00229
--- total mse / var(X): 0.00178
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00845, 0.00765
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0126, 0.0138
--- total mse / var(X): 0.0107
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0188, 0.00614
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00688, 0.0115
--- total mse / var(X): 0.00882
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0402, 0.0301
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0411, 0.0514
--- total mse / var(X): 0.0407
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00139, 0.0017
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0121, 0.00944
--- total mse / var(X): 0.00557
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0219, 0.0195
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0158, 0.0175
--- total mse / var(X): 0.0185
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00252, 0.0029
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00727, 0.00618
--- total mse / var(X): 0.00454
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00233, 0.00226
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00216, 0.00222
--- total mse / var(X): 0.00224
start table evaluation...
Elapsed time: 119.23718070983887 seconds
Cosine similarity between AMM and exact (Train): 0.62416804
Cosine similarity between AMM and exact (Test): 0.6083907
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.792078790281857 0.31804928802158317 0.4538577128706444
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.9933987855911255,
                                      0.9445173144340515,
                                      0.9323399662971497,
                                      0.6241679787635803],
               'cossim_layer_test': [0.9873737096786499,
                                     0.9443953037261963,
                                     0.9326886534690857,
                                     0.6083906888961792],
               'cossim_amm_train': [0.9886037111282349,
                                    0.9963564276695251,
                                    0.9795109033584595,
                                    0.9090064167976379,
                                    0.9340139031410217,
                                    0.8635061383247375,
                                    0.8880915641784668,
                                    0.8724772930145264],
               'cossim_amm_test': [0.9786274433135986,
                                   0.9959186315536499,
                                   0.9795035123825073,
                                   0.9081918597221375,
                                   0.933891236782074,
                                   0.8638054132461548,
                                   0.8892878890037537,
                                   0.8743926882743835],
               'f1': [0.792078790281857,
                      0.31804928802158317,
                      0.4538577128706444],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 64),
                              (192, 2, 64),
                              (64, 64, 2),
                              (64, 64, 2),
                              (32, 2, 64),
                              (32, 2, 64),
                              (32, 2, 64),
                              (256, 2, 64)],
               'lut_total_size': 90112}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000008
Manual and Torch results cosine similarity (Test): 1.0000013
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0489, 0.076
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000213, 9.49e-05
--- total mse / var(X): 0.0381
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00892, 0.0078
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00638, 0.00718
--- total mse / var(X): 0.00749
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000983, 0.001
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00107, 0.00105
--- total mse / var(X): 0.00103
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.004, 0.00362
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0041, 0.00448
--- total mse / var(X): 0.00405
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0131, 0.00443
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00563, 0.00936
--- total mse / var(X): 0.0069
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0126, 0.00947
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.014, 0.0175
--- total mse / var(X): 0.0135
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00475, 0.00616
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0234, 0.0165
--- total mse / var(X): 0.0113
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0284, 0.0245
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0177, 0.0201
--- total mse / var(X): 0.0223
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00669, 0.00774
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00908, 0.00764
--- total mse / var(X): 0.00769
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0291, 0.0288
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.027, 0.0273
--- total mse / var(X): 0.0281
start table evaluation...
Elapsed time: 161.6651062965393 seconds
Cosine similarity between AMM and exact (Train): 0.78885835
Cosine similarity between AMM and exact (Test): 0.7867152
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7425148805416794 0.624929528049651 0.6786666733235074
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9956901669502258,
                                      0.9795067310333252,
                                      0.9688870906829834,
                                      0.7888583540916443],
               'cossim_layer_test': [0.9895781874656677,
                                     0.9798465967178345,
                                     0.9682247638702393,
                                     0.7867152094841003],
               'cossim_amm_train': [0.9925752282142639,
                                    0.997297465801239,
                                    0.988219141960144,
                                    0.9575676321983337,
                                    0.9754432439804077,
                                    0.9272980690002441,
                                    0.939039409160614,
                                    0.8977654576301575],
               'cossim_amm_test': [0.9824027419090271,
                                   0.9967656135559082,
                                   0.987939715385437,
                                   0.9585319757461548,
                                   0.9762852191925049,
                                   0.9243099093437195,
                                   0.9374080896377563,
                                   0.899186372756958],
               'f1': [0.7425148805416794,
                      0.624929528049651,
                      0.6786666733235074],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000008
Manual and Torch results cosine similarity (Test): 1.0000013
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0269, 0.0417
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000277, 0.000125
--- total mse / var(X): 0.0209
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00656, 0.00574
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00393, 0.00442
--- total mse / var(X): 0.00508
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000839, 0.000857
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00098, 0.000959
--- total mse / var(X): 0.000908
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0035, 0.00317
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00283, 0.00309
--- total mse / var(X): 0.00313
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0082, 0.00274
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00365, 0.00607
--- total mse / var(X): 0.00441
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00784, 0.00587
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00805, 0.0101
--- total mse / var(X): 0.00797
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00658, 0.00855
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0243, 0.017
--- total mse / var(X): 0.0128
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0223, 0.0191
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0158, 0.0181
--- total mse / var(X): 0.0186
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00684, 0.00791
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00785, 0.00662
--- total mse / var(X): 0.00727
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0298, 0.0286
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0308, 0.0319
--- total mse / var(X): 0.0303
start table evaluation...
Elapsed time: 390.2670547962189 seconds
Cosine similarity between AMM and exact (Train): 0.77536756
Cosine similarity between AMM and exact (Test): 0.76805586
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7458401498225375 0.5791398187691302 0.6520034105241366
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256],
               'cossim_layer_train': [0.9976305365562439,
                                      0.9843263626098633,
                                      0.9756028652191162,
                                      0.7753676176071167],
               'cossim_layer_test': [0.9915119409561157,
                                     0.983345091342926,
                                     0.9738415479660034,
                                     0.7680558562278748],
               'cossim_amm_train': [0.9959207773208618,
                                    0.9981951117515564,
                                    0.9919303059577942,
                                    0.9688361883163452,
                                    0.9811393618583679,
                                    0.9361565709114075,
                                    0.9496398568153381,
                                    0.9017704129219055],
               'cossim_amm_test': [0.985664427280426,
                                   0.997366189956665,
                                   0.9910750985145569,
                                   0.9665284752845764,
                                   0.9802769422531128,
                                   0.9336107969284058,
                                   0.9475114941596985,
                                   0.8995645046234131],
               'f1': [0.7458401498225375,
                      0.5791398187691302,
                      0.6520034105241366],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (256, 2, 256)],
               'lut_total_size': 557056}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000006
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0604, 0.0604
--- total mse / var(X): 0.0604
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00815, 0.00815
--- total mse / var(X): 0.00815
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000727, 0.000727
--- total mse / var(X): 0.000727
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00289, 0.00289
--- total mse / var(X): 0.00289
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0127, 0.0127
--- total mse / var(X): 0.0127
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0174, 0.0174
--- total mse / var(X): 0.0174
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0173, 0.0173
--- total mse / var(X): 0.0173
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0152, 0.0152
--- total mse / var(X): 0.0152
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00416, 0.00416
--- total mse / var(X): 0.00416
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0013, 0.0013
--- total mse / var(X): 0.0013
start table evaluation...
Elapsed time: 225.53542590141296 seconds
Cosine similarity between AMM and exact (Train): 0.8174243
Cosine similarity between AMM and exact (Test): 0.81446826
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7177633009549915 0.6964428904992923 0.7069423836949269
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9917206168174744,
                                      0.9757671356201172,
                                      0.9572802186012268,
                                      0.8174242973327637],
               'cossim_layer_test': [0.9791392087936401,
                                     0.9754331707954407,
                                     0.9582725167274475,
                                     0.814468264579773],
               'cossim_amm_train': [0.9857243895530701,
                                    0.995898962020874,
                                    0.9794144630432129,
                                    0.9486754536628723,
                                    0.9714187979698181,
                                    0.9176367521286011,
                                    0.9222381114959717,
                                    0.9098724126815796],
               'cossim_amm_test': [0.9645092487335205,
                                   0.9957063794136047,
                                   0.9825924634933472,
                                   0.9480703473091125,
                                   0.9719217419624329,
                                   0.9215286374092102,
                                   0.9266608953475952,
                                   0.9077505469322205],
               'f1': [0.7177633009549915,
                      0.6964428904992923,
                      0.7069423836949269],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 128),
                              (192, 1, 128),
                              (128, 128, 1),
                              (128, 128, 1),
                              (32, 1, 128),
                              (32, 1, 128),
                              (32, 1, 128),
                              (256, 1, 128)],
               'lut_total_size': 106496}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 0.99999964
start table training...
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0545, 0.0545
--- total mse / var(X): 0.0545
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00751, 0.00751
--- total mse / var(X): 0.00751
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000834, 0.000834
--- total mse / var(X): 0.000834
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00334, 0.00334
--- total mse / var(X): 0.00334
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0101, 0.0101
--- total mse / var(X): 0.0101
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0193, 0.0193
--- total mse / var(X): 0.0193
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0154, 0.0154
--- total mse / var(X): 0.0154
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0244, 0.0244
--- total mse / var(X): 0.0244
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00273, 0.00273
--- total mse / var(X): 0.00273
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00069, 0.00069
--- total mse / var(X): 0.00069
start table evaluation...
Elapsed time: 218.81432461738586 seconds
Cosine similarity between AMM and exact (Train): 0.7956848
Cosine similarity between AMM and exact (Test): 0.7977639
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.702160888153253 0.712773025878026 0.7074271609990295
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9925956130027771,
                                      0.9724940061569214,
                                      0.9571031928062439,
                                      0.795684814453125],
               'cossim_layer_test': [0.9810813069343567,
                                     0.9725924730300903,
                                     0.9569240212440491,
                                     0.7977639436721802],
               'cossim_amm_train': [0.9872211813926697,
                                    0.9962819218635559,
                                    0.9811416268348694,
                                    0.9417380094528198,
                                    0.9673093557357788,
                                    0.9154647588729858,
                                    0.9228003621101379,
                                    0.8962015509605408],
               'cossim_amm_test': [0.9677987098693848,
                                   0.9953423738479614,
                                   0.9794881343841553,
                                   0.9428428411483765,
                                   0.9684382677078247,
                                   0.9166301488876343,
                                   0.9230371117591858,
                                   0.8990252017974854],
               'f1': [0.702160888153253, 0.712773025878026, 0.7074271609990295],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 128),
                              (192, 1, 128),
                              (128, 128, 1),
                              (128, 128, 1),
                              (32, 1, 128),
                              (32, 1, 128),
                              (32, 1, 128),
                              (256, 1, 128)],
               'lut_total_size': 106496}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 0.99999964
start table training...
Traceback (most recent call last):
  File "src/3_vit.py", line 133, in <module>
    layer_amm_res_train, mm_amm_res_train = vit_manual_amm.train_amm(train_data)
  File "/data/neelesh/DART_by_app/410/src/v_amm.py", line 253, in train_amm
    output = self.forward(input_data, mm_type='train_amm')
  File "/data/neelesh/DART_by_app/410/src/v_amm.py", line 214, in forward
    x = self.vector_matrix_multiply(x, patch_weights[0].transpose(),patch_weights[1], mm_type)
  File "/data/neelesh/DART_by_app/410/src/v_amm.py", line 108, in vector_matrix_multiply
    est.fit(vector, weight_t)
  File "/data/neelesh/DART_by_app/410/src/vq_amm.py", line 45, in fit
    raise amm.InvalidParametersException(
amm.InvalidParametersException: D < k: 10 < 16
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (23). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000005
Manual and Torch results cosine similarity (Test): 1.000001
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0145, 0.0226
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000885, 0.000395
--- total mse / var(X): 0.0115
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00412, 0.0036
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00253, 0.00285
--- total mse / var(X): 0.00323
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000693, 0.000708
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000734, 0.000719
--- total mse / var(X): 0.000713
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00271, 0.00246
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00248, 0.00271
--- total mse / var(X): 0.00258
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00506, 0.00173
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00242, 0.00401
--- total mse / var(X): 0.00287
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00509, 0.00381
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00581, 0.00726
--- total mse / var(X): 0.00554
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00711, 0.00916
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0228, 0.0162
--- total mse / var(X): 0.0127
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0176, 0.015
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0135, 0.0154
--- total mse / var(X): 0.0152
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00456, 0.00525
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00609, 0.00517
--- total mse / var(X): 0.00521
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0313, 0.0297
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0298, 0.0313
--- total mse / var(X): 0.0305
start table evaluation...
Elapsed time: 532.1090755462646 seconds
Cosine similarity between AMM and exact (Train): 0.7686887
Cosine similarity between AMM and exact (Test): 0.75404906
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7742415568735693 0.5281807953349383 0.6279676029782615
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512],
               'cossim_layer_train': [0.9986226558685303,
                                      0.9863134026527405,
                                      0.9801360964775085,
                                      0.7686887979507446],
               'cossim_layer_test': [0.9921442270278931,
                                     0.9834141731262207,
                                     0.9768424034118652,
                                     0.7540491223335266],
               'cossim_amm_train': [0.9976239800453186,
                                    0.9988541007041931,
                                    0.9947909712791443,
                                    0.974142849445343,
                                    0.9834362268447876,
                                    0.9412714838981628,
                                    0.9575744867324829,
                                    0.9048743844032288],
               'cossim_amm_test': [0.9866983294487,
                                   0.997650146484375,
                                   0.9922643303871155,
                                   0.9684255719184875,
                                   0.9802904725074768,
                                   0.9359840750694275,
                                   0.9537293910980225,
                                   0.9010684490203857],
               'f1': [0.7742415568735693,
                      0.5281807953349383,
                      0.6279676029782615],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 512),
                              (192, 2, 512),
                              (512, 512, 2),
                              (512, 512, 2),
                              (32, 2, 512),
                              (32, 2, 512),
                              (32, 2, 512),
                              (256, 2, 512)],
               'lut_total_size': 1638400}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000005
Manual and Torch results cosine similarity (Test): 0.99999964
start table training...
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00763, 0.0104
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000123, 0.000156
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00095, 0.0013
running kmeans in subspace 4/4... X.shape:  (100000, 3)
k:  128
nnz_rows:  0
mse / {var(X_subs), var(X)}: 0, 0
--- total mse / var(X): 0.00295
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00923, 0.00619
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00813, 0.00877
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00747, 0.00804
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00449, 0.00527
--- total mse / var(X): 0.00707
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00157, 0.00106
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00101, 0.00138
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00125, 0.00145
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00162, 0.00129
--- total mse / var(X): 0.0013
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0044, 0.00425
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0066, 0.00559
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00493, 0.00618
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00459, 0.00429
--- total mse / var(X): 0.00508
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0173, 0.0106
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00909, 0.000582
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00578, 0.0031
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00227, 0.00633
--- total mse / var(X): 0.00515
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00918, 0.00866
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00505, 0.0028
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0115, 0.0109
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00805, 0.0125
--- total mse / var(X): 0.00871
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00725, 0.00857
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00764, 0.0111
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0401, 0.0199
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0245, 0.0214
--- total mse / var(X): 0.0152
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.027, 0.015
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0261, 0.0302
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0231, 0.025
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.014, 0.017
--- total mse / var(X): 0.0218
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0107, 0.00964
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00461, 0.00657
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00854, 0.00975
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.014, 0.0074
--- total mse / var(X): 0.00834
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0783, 0.0749
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0733, 0.0735
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0768, 0.0807
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0741, 0.0733
--- total mse / var(X): 0.0756
start table evaluation...
Elapsed time: 235.4977879524231 seconds
Cosine similarity between AMM and exact (Train): 0.7749413
Cosine similarity between AMM and exact (Test): 0.775617
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7649969985150549 0.5858649600154857 0.6635540117430238
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9996177554130554,
                                      0.9866701364517212,
                                      0.9772117137908936,
                                      0.7749413251876831],
               'cossim_layer_test': [0.9972381591796875,
                                     0.9869006872177124,
                                     0.9773560166358948,
                                     0.7756170034408569],
               'cossim_amm_train': [0.9993399381637573,
                                    0.9982837438583374,
                                    0.9936951398849487,
                                    0.9717928171157837,
                                    0.9838114976882935,
                                    0.9405328035354614,
                                    0.9531101584434509,
                                    0.9000903964042664],
               'cossim_amm_test': [0.9953330755233765,
                                   0.9979739785194397,
                                   0.9939953088760376,
                                   0.9719135761260986,
                                   0.9841777682304382,
                                   0.942205548286438,
                                   0.9534547924995422,
                                   0.9013790488243103],
               'f1': [0.7649969985150549,
                      0.5858649600154857,
                      0.6635540117430238],
               'lut_num': 8,
               'lut_shapes': [(32, 4, 128),
                              (192, 4, 128),
                              (128, 128, 4),
                              (128, 128, 4),
                              (32, 4, 128),
                              (32, 4, 128),
                              (32, 4, 128),
                              (256, 4, 128)],
               'lut_total_size': 425984}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 0.99999964
start table training...
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 3.05e-06, 4.07e-06
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 2.11e-09, 2.89e-09
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 1.22e-06, 1.77e-06
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 5.59e-05, 6.04e-05
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 1.62e-05, 1.56e-05
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 9.79e-05, 0.000129
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 4.76e-05, 2.25e-05
running kmeans in subspace 8/8... X.shape:  (100000, 2)
k:  128
nnz_rows:  0
mse / {var(X_subs), var(X)}: 0, 0
--- total mse / var(X): 2.92e-05
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00627, 0.00387
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0065, 0.00471
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00573, 0.00653
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00493, 0.00502
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00514, 0.00556
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00573, 0.00614
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00537, 0.00504
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00194, 0.00273
--- total mse / var(X): 0.00495
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00166, 0.00158
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00246, 0.000978
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00178, 0.00103
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00096, 0.00207
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00169, 0.00184
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00119, 0.00146
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00178, 0.00156
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00182, 0.00131
--- total mse / var(X): 0.00148
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00542, 0.00521
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00431, 0.00417
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00608, 0.00627
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00676, 0.00449
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00504, 0.00533
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00476, 0.0069
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00487, 0.00466
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00555, 0.00507
--- total mse / var(X): 0.00526
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000561, 1.78e-05
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00152, 0.00127
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00557, 0.00178
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00299, 0.000138
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00304, 0.000259
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00415, 0.00333
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00214, 0.00583
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00271, 0.00856
--- total mse / var(X): 0.00265
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 5.97e-08, 3.68e-08
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000373, 0.000225
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0003, 0.000201
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000846, 0.000369
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000279, 0.000187
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00594, 0.00753
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00445, 0.00656
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00369, 0.00836
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (32). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000008
Manual and Torch results cosine similarity (Test): 1.0000013
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00778, 0.0121
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 2.85e-05, 1.27e-05
--- total mse / var(X): 0.00605
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0025, 0.00219
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00165, 0.00185
--- total mse / var(X): 0.00202
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000437, 0.000447
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000513, 0.000501
--- total mse / var(X): 0.000474
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00198, 0.0018
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0018, 0.00196
--- total mse / var(X): 0.00188
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00369, 0.00123
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00158, 0.00263
--- total mse / var(X): 0.00193
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00341, 0.00255
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00438, 0.00548
--- total mse / var(X): 0.00402
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00621, 0.00799
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0198, 0.0141
--- total mse / var(X): 0.011
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0145, 0.0124
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0102, 0.0116
--- total mse / var(X): 0.012
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00434, 0.00495
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0047, 0.00403
--- total mse / var(X): 0.00449
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0267, 0.0252
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0246, 0.026
--- total mse / var(X): 0.0256
start table evaluation...
Elapsed time: 791.7592582702637 seconds
Cosine similarity between AMM and exact (Train): 0.79150075
Cosine similarity between AMM and exact (Test): 0.78574497
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7760331795078484 0.584218154542265 0.6666013267500146
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024],
               'cossim_layer_train': [0.9992527365684509,
                                      0.989993155002594,
                                      0.9852740168571472,
                                      0.7915007472038269],
               'cossim_layer_test': [0.9930314421653748,
                                     0.9856093525886536,
                                     0.9803329706192017,
                                     0.7857449054718018],
               'cossim_amm_train': [0.9987117648124695,
                                    0.999302089214325,
                                    0.9966883063316345,
                                    0.981377899646759,
                                    0.9878865480422974,
                                    0.9508296251296997,
                                    0.9665735363960266,
                                    0.9147127866744995],
               'cossim_amm_test': [0.9882046580314636,
                                   0.9979735016822815,
                                   0.9934929013252258,
                                   0.9729451537132263,
                                   0.9829140305519104,
                                   0.9426567554473877,
                                   0.9607667922973633,
                                   0.9108313322067261],
               'f1': [0.7760331795078484,
                      0.584218154542265,
                      0.6666013267500146],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 1024),
                              (192, 2, 1024),
                              (1024, 1024, 2),
                              (1024, 1024, 2),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (256, 2, 1024)],
               'lut_total_size': 5373952}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
--- total mse / var(X): 0.00293
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0121, 0.0107
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00891, 0.0129
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0081, 0.0142
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0112, 0.0126
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.03, 0.0183
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0568, 0.0234
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0226, 0.0219
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0259, 0.0206
--- total mse / var(X): 0.0168
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0199, 0.0111
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0171, 0.00902
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0199, 0.0168
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0187, 0.0271
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0172, 0.0164
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0156, 0.0191
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0105, 0.0145
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00903, 0.00965
--- total mse / var(X): 0.0155
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00756, 0.00862
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00667, 0.00436
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00383, 0.00723
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00545, 0.00506
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00594, 0.00404
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00489, 0.008
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00749, 0.0029
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0099, 0.00679
--- total mse / var(X): 0.00587
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0742, 0.0698
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0651, 0.0666
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0687, 0.0687
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0657, 0.0544
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0658, 0.0621
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0704, 0.0768
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0674, 0.0592
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0458, 0.0595
--- total mse / var(X): 0.0646
start table evaluation...
Elapsed time: 327.43975472450256 seconds
Cosine similarity between AMM and exact (Train): 0.806478
Cosine similarity between AMM and exact (Test): 0.7983673
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7613800111711391 0.6279879502038545 0.6882805503422733
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9999985694885254,
                                      0.9919880628585815,
                                      0.9855798482894897,
                                      0.8064780235290527],
               'cossim_layer_test': [0.9999134540557861,
                                     0.9920644760131836,
                                     0.9854927062988281,
                                     0.798367440700531],
               'cossim_amm_train': [0.9999973773956299,
                                    0.9988152980804443,
                                    0.9960343837738037,
                                    0.9836552143096924,
                                    0.9902395009994507,
                                    0.9564136266708374,
                                    0.9667686223983765,
                                    0.9188222289085388],
               'cossim_amm_test': [0.9998542070388794,
                                   0.9986246824264526,
                                   0.9961941838264465,
                                   0.9837086796760559,
                                   0.9902709126472473,
                                   0.9565887451171875,
                                   0.9667627811431885,
                                   0.9189369678497314],
               'f1': [0.7613800111711391,
                      0.6279879502038545,
                      0.6882805503422733],
               'lut_num': 8,
               'lut_shapes': [(32, 8, 128),
                              (192, 8, 128),
                              (128, 128, 8),
                              (128, 128, 8),
                              (32, 8, 128),
                              (32, 8, 128),
                              (32, 8, 128),
                              (256, 8, 128)],
               'lut_total_size': 851968}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.20838417
Manual and Torch results cosine similarity (Test): 0.20486261
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.141, 0.218
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0104, 0.00473
--- total mse / var(X): 0.111
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0718, 0.0627
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0127, 0.0143
--- total mse / var(X): 0.0385
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0142, 0.0146
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0141, 0.0137
--- total mse / var(X): 0.0142
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0591, 0.0538
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0517, 0.0564
--- total mse / var(X): 0.0551
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00266, 0.000895
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00657, 0.0109
--- total mse / var(X): 0.00591
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.124, 0.103
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.13, 0.152
--- total mse / var(X): 0.127
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000527, 0.000748
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0115, 0.0067
--- total mse / var(X): 0.00372
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0119, 0.0105
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0119, 0.0134
--- total mse / var(X): 0.0119
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000845, 0.00103
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00166, 0.0013
--- total mse / var(X): 0.00116
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 1.99e-05, 2.56e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000166, 0.000118
--- total mse / var(X): 7.18e-05
start table evaluation...
Elapsed time: 125.20367741584778 seconds
Cosine similarity between AMM and exact (Train): 0.073160216
Cosine similarity between AMM and exact (Test): 0.07161666
p,r,f1: 0.9308168981496487 0.9033296635493666 0.9168673136488084
p,r,f1: 0.8953999329854961 0.09052252077863944 0.16442238175916954
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9308168981496487, 0.9033296635493666, 0.9168673136488084],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32],
               'cossim_layer_train': [0.9903512001037598,
                                      0.90118408203125,
                                      0.89253169298172,
                                      0.36870309710502625],
               'cossim_layer_test': [0.9845324158668518,
                                     0.9005861282348633,
                                     0.8925556540489197,
                                     0.3731688857078552],
               'cossim_amm_train': [0.9833512306213379,
                                    0.9856612086296082,
                                    0.9288136959075928,
                                    0.8154558539390564,
                                    0.8815993666648865,
                                    0.7933216691017151,
                                    0.8213034868240356,
                                    0.7792358994483948],
               'cossim_amm_test': [0.9738169312477112,
                                   0.9854512810707092,
                                   0.9295262694358826,
                                   0.8121657371520996,
                                   0.8802803754806519,
                                   0.794517457485199,
                                   0.8231233954429626,
                                   0.7831263542175293],
               'f1': [0.8953999329854961,
                      0.09052252077863944,
                      0.16442238175916954],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 32),
                              (192, 2, 32),
                              (32, 32, 2),
                              (32, 32, 2),
                              (32, 2, 32),
                              (32, 2, 32),
                              (32, 2, 32),
                              (256, 2, 32)],
               'lut_total_size': 40960}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.20976503
Manual and Torch results cosine similarity (Test): 0.20486261
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0894, 0.139
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000807, 0.000362
--- total mse / var(X): 0.0695
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0116, 0.0101
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00848, 0.00954
--- total mse / var(X): 0.00982
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00131, 0.00133
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00165, 0.00161
--- total mse / var(X): 0.00147
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0156, 0.0141
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00935, 0.0102
--- total mse / var(X): 0.0122
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0172, 0.00625
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00816, 0.0134
--- total mse / var(X): 0.0098
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0316, 0.0237
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0318, 0.0398
--- total mse / var(X): 0.0317
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0022, 0.00292
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0142, 0.00961
--- total mse / var(X): 0.00626
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0237, 0.0207
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0172, 0.0194
--- total mse / var(X): 0.02
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00421, 0.00488
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00889, 0.00748
--- total mse / var(X): 0.00618
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.018, 0.0173
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0152, 0.0158
--- total mse / var(X): 0.0166
start table evaluation...
Elapsed time: 154.0441870689392 seconds
Cosine similarity between AMM and exact (Train): 0.12697232
Cosine similarity between AMM and exact (Test): 0.122062586
p,r,f1: 0.9308168981496487 0.9033296635493666 0.9168673136488084
p,r,f1: 0.7110874179769207 0.7103761326929359 0.7107315973751223
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9308168981496487, 0.9033296635493666, 0.9168673136488084],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.993220329284668,
                                      0.9720852971076965,
                                      0.9573283195495605,
                                      0.8123063445091248],
               'cossim_layer_test': [0.9872809052467346,
                                     0.9719710946083069,
                                     0.9565849900245667,
                                     0.8062817454338074],
               'cossim_amm_train': [0.9882894158363342,
                                    0.9965046644210815,
                                    0.9785274863243103,
                                    0.939734697341919,
                                    0.9666187167167664,
                                    0.9143499732017517,
                                    0.9276026487350464,
                                    0.9075234532356262],
               'cossim_amm_test': [0.9785203337669373,
                                   0.9960188269615173,
                                   0.9782418012619019,
                                   0.9393632411956787,
                                   0.9668546915054321,
                                   0.9144976735115051,
                                   0.9268645644187927,
                                   0.9094558358192444],
               'f1': [0.7110874179769207,
                      0.7103761326929359,
                      0.7107315973751223],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 64),
                              (192, 2, 64),
                              (64, 64, 2),
                              (64, 64, 2),
                              (32, 2, 64),
                              (32, 2, 64),
                              (32, 2, 64),
                              (256, 2, 64)],
               'lut_total_size': 90112}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.20864934
Manual and Torch results cosine similarity (Test): 0.20486261
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0496, 0.0768
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00028, 0.000126
--- total mse / var(X): 0.0385
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0093, 0.00814
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00593, 0.00668
--- total mse / var(X): 0.00741
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000946, 0.000966
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00119, 0.00116
--- total mse / var(X): 0.00107
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00402, 0.00365
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00373, 0.00409
--- total mse / var(X): 0.00387
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0106, 0.0036
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00515, 0.00855
--- total mse / var(X): 0.00608
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0119, 0.00893
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0116, 0.0145
--- total mse / var(X): 0.0117
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00487, 0.00639
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0222, 0.0153
--- total mse / var(X): 0.0108
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0289, 0.0246
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0176, 0.0202
--- total mse / var(X): 0.0224
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00746, 0.00867
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00746, 0.00625
--- total mse / var(X): 0.00746
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0201, 0.0203
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0206, 0.0204
--- total mse / var(X): 0.0204
start table evaluation...
Elapsed time: 185.78594779968262 seconds
Cosine similarity between AMM and exact (Train): 0.13317591
Cosine similarity between AMM and exact (Test): 0.12651429
p,r,f1: 0.9308168981496487 0.9033296635493666 0.9168673136488084
p,r,f1: 0.7381776233787527 0.6732192070846994 0.7042035855153924
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9308168981496487, 0.9033296635493666, 0.9168673136488084],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9955856800079346,
                                      0.9828299283981323,
                                      0.9693974256515503,
                                      0.8200661540031433],
               'cossim_layer_test': [0.9897048473358154,
                                     0.9801408648490906,
                                     0.9668622612953186,
                                     0.796730637550354],
               'cossim_amm_train': [0.99239182472229,
                                    0.9973435997962952,
                                    0.988432765007019,
                                    0.9632742404937744,
                                    0.9795437455177307,
                                    0.9418355822563171,
                                    0.9440054893493652,
                                    0.9137673377990723],
               'cossim_amm_test': [0.9826138615608215,
                                   0.9967784285545349,
                                   0.9878515601158142,
                                   0.9586125016212463,
                                   0.9766521453857422,
                                   0.9356420040130615,
                                   0.9405935406684875,
                                   0.906679630279541],
               'f1': [0.7381776233787527,
                      0.6732192070846994,
                      0.7042035855153924],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.20955607
Manual and Torch results cosine similarity (Test): 0.20486261
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0263, 0.0407
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000455, 0.000204
--- total mse / var(X): 0.0205
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00631, 0.00552
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0039, 0.00439
--- total mse / var(X): 0.00496
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000878, 0.000897
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00101, 0.000985
--- total mse / var(X): 0.000941
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00361, 0.00327
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00322, 0.00352
--- total mse / var(X): 0.00339
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00934, 0.00313
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00374, 0.00623
--- total mse / var(X): 0.00468
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00728, 0.00544
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00807, 0.0101
--- total mse / var(X): 0.00778
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00701, 0.00903
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0235, 0.0167
--- total mse / var(X): 0.0128
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0206, 0.0178
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0149, 0.0169
--- total mse / var(X): 0.0173
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0063, 0.00731
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00749, 0.00629
--- total mse / var(X): 0.0068
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0278, 0.0263
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0262, 0.0275
--- total mse / var(X): 0.0269
start table evaluation...
Elapsed time: 229.94070553779602 seconds
Cosine similarity between AMM and exact (Train): 0.14018133
Cosine similarity between AMM and exact (Test): 0.13218679
p,r,f1: 0.9308168981496487 0.9033296635493666 0.9168673136488084
p,r,f1: 0.7661941876190625 0.49651741534292315 0.602558425526467
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9308168981496487, 0.9033296635493666, 0.9168673136488084],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256],
               'cossim_layer_train': [0.997625470161438,
                                      0.9828516840934753,
                                      0.973827600479126,
                                      0.7511816620826721],
               'cossim_layer_test': [0.9908902645111084,
                                     0.9811595678329468,
                                     0.9712195992469788,
                                     0.741472065448761],
               'cossim_amm_train': [0.9959003329277039,
                                    0.9982348680496216,
                                    0.9921481609344482,
                                    0.9666087627410889,
                                    0.979336678981781,
                                    0.9310075044631958,
                                    0.9466961622238159,
                                    0.8953882455825806],
               'cossim_amm_test': [0.9846022725105286,
                                   0.9971889853477478,
                                   0.9903233647346497,
                                   0.963059663772583,
                                   0.9777358770370483,
                                   0.9272585511207581,
                                   0.942410945892334,
                                   0.8844902515411377],
               'f1': [0.7661941876190625,
                      0.49651741534292315,
                      0.602558425526467],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (256, 2, 256)],
               'lut_total_size': 557056}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_2_vit_finetune.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_2_vit_finetune.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 0.99999964
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0477, 0.0736
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00054, 0.000246
--- total mse / var(X): 0.0369
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0093, 0.00814
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00626, 0.00704
--- total mse / var(X): 0.00759
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00101, 0.00103
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00121, 0.00118
--- total mse / var(X): 0.00111
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00438, 0.00396
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0051, 0.00558
--- total mse / var(X): 0.00477
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0118, 0.00381
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00565, 0.00948
--- total mse / var(X): 0.00664
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0163, 0.0122
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0151, 0.019
--- total mse / var(X): 0.0156
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00472, 0.00603
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0235, 0.017
--- total mse / var(X): 0.0115
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0232, 0.0202
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0168, 0.0189
--- total mse / var(X): 0.0196
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00546, 0.00626
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00701, 0.00598
--- total mse / var(X): 0.00612
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0237, 0.0221
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0158, 0.0168
--- total mse / var(X): 0.0195
start table evaluation...
Elapsed time: 272.57785201072693 seconds
Cosine similarity between AMM and exact (Train): 0.6694141
Cosine similarity between AMM and exact (Test): 0.703612
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.781887824664258 0.44403305225207784 0.5664052939170263
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9958982467651367,
                                      0.9733046293258667,
                                      0.9619705080986023,
                                      0.6694140434265137],
               'cossim_layer_test': [0.9897584915161133,
                                     0.9743490219116211,
                                     0.9622566103935242,
                                     0.7036120295524597],
               'cossim_amm_train': [0.992933452129364,
                                    0.9973986744880676,
                                    0.9882604479789734,
                                    0.9509404301643372,
                                    0.9679576754570007,
                                    0.9091225266456604,
                                    0.9293981790542603,
                                    0.8797523975372314],
               'cossim_amm_test': [0.9827220439910889,
                                   0.9968245029449463,
                                   0.9879293441772461,
                                   0.952727198600769,
                                   0.9696696400642395,
                                   0.9076559543609619,
                                   0.9286155104637146,
                                   0.8836325407028198],
               'f1': [0.781887824664258,
                      0.44403305225207784,
                      0.5664052939170263],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.3493733745 - test_loss: 0.2041715440
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.1704420483 - test_loss: 0.1491817100
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1422029133 - test_loss: 0.1378592404
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1350785349 - test_loss: 0.1340095981
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1293795324 - test_loss: 0.1218061482
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1211906804 - test_loss: 0.1170365409
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.1178124009 - test_loss: 0.1166272965
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.1136519588 - test_loss: 0.1079668874
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.1072846833 - test_loss: 0.1284648185
Early Stop Left: 4
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.1030419664 - test_loss: 0.1015299420
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.1001782658 - test_loss: 0.0980000890
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0982657052 - test_loss: 0.0965308317
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0968104635 - test_loss: 0.0943971725
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0954010076 - test_loss: 0.1037737315
Early Stop Left: 4
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0943143493 - test_loss: 0.0964728285
Early Stop Left: 3
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0930496116 - test_loss: 0.0920425229
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0919615865 - test_loss: 0.0937841851
Early Stop Left: 4
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0911580131 - test_loss: 0.0936644319
Early Stop Left: 3
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0902195396 - test_loss: 0.0907560184
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0892079731 - test_loss: 0.0902777137
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.0885306922 - test_loss: 0.0889781775
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.0876104467 - test_loss: 0.0920054816
Early Stop Left: 4
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.0862182825 - test_loss: 0.0859126226
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.0844235719 - test_loss: 0.0888745132
Early Stop Left: 4
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.0822205781 - test_loss: 0.0841770439
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.0798027862 - test_loss: 0.0825209918
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.0782219247 - test_loss: 0.0827664066
Early Stop Left: 4
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.0768246531 - test_loss: 0.0804136950
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.0760922188 - test_loss: 0.0784430583
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.0752812945 - test_loss: 0.0777905055
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.0743250550 - test_loss: 0.0843868705
Early Stop Left: 4
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.0735779495 - test_loss: 0.0760703038
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.0726824373 - test_loss: 0.0750642212
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.0720654948 - test_loss: 0.0737629798
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.0715148477 - test_loss: 0.0733379758
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.0705260107 - test_loss: 0.0724795711
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.0693506637 - test_loss: 0.0746869913
Early Stop Left: 4
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.0689990560 - test_loss: 0.0722197208
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.0677106631 - test_loss: 0.0704245063
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.0660936929 - test_loss: 0.0670297036
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.0644385381 - test_loss: 0.0760466752
Early Stop Left: 4
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.0635581521 - test_loss: 0.0677163517
Early Stop Left: 3
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.0623339910 - test_loss: 0.0648520295
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.0616360166 - test_loss: 0.0677156904
Early Stop Left: 4
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.0608211230 - test_loss: 0.0661991240
Early Stop Left: 3
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.0601248000 - test_loss: 0.0644716700
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.0593326197 - test_loss: 0.0668615170
Early Stop Left: 4
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.0589943371 - test_loss: 0.0620290210
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.0583672462 - test_loss: 0.0790577240
Early Stop Left: 4
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.0582006337 - test_loss: 0.0714661286
Early Stop Left: 3
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.0575715702 - test_loss: 0.0611482925
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.0571821445 - test_loss: 0.0620269547
Early Stop Left: 4
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.0569316215 - test_loss: 0.0599830974
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.0566303261 - test_loss: 0.0648768345
Early Stop Left: 4
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.0563290296 - test_loss: 0.0612458061
Early Stop Left: 3
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.0557896783 - test_loss: 0.0637200592
Early Stop Left: 2
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.0557164987 - test_loss: 0.0612409326
Early Stop Left: 1
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.0551654545 - test_loss: 0.0609999477
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/173 [00:00<?, ?it/s]  8%|▊         | 13/173 [00:00<00:01, 128.71it/s] 15%|█▌        | 26/173 [00:00<00:01, 127.27it/s] 23%|██▎       | 39/173 [00:00<00:01, 124.59it/s] 31%|███       | 53/173 [00:00<00:00, 126.81it/s] 39%|███▊      | 67/173 [00:00<00:00, 128.20it/s] 46%|████▌     | 80/173 [00:00<00:00, 126.60it/s] 54%|█████▍    | 93/173 [00:00<00:00, 126.02it/s] 61%|██████▏   | 106/173 [00:00<00:00, 123.88it/s] 69%|██████▉   | 119/173 [00:00<00:00, 125.01it/s] 76%|███████▋  | 132/173 [00:01<00:00, 125.36it/s] 84%|████████▍ | 145/173 [00:01<00:00, 125.69it/s] 91%|█████████▏| 158/173 [00:01<00:00, 124.95it/s] 99%|█████████▉| 172/173 [00:01<00:00, 127.05it/s]100%|██████████| 173/173 [00:01<00:00, 126.54it/s]
Best micro threshold=0.459687, fscore=0.936
p,r,f1: 0.9340722874369766 0.9374204241625028 0.9357433608589998
throttleing by fixed threshold: 0.5
p,r,f1: 0.9402454020726427 0.9305946259844902 0.9353951221410435
{'model': 'vit_large',
 'app': '410.bwaves-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.459686815738678,
                 'p': 0.9340722874369766,
                 'r': 0.9374204241625028,
                 'f1': 0.9357433608589998},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9402454020726427,
                 'r': 0.9305946259844902,
                 'f1': 0.9353951221410435}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 0.99999964
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.108, 0.108
--- total mse / var(X): 0.108
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:19,  4.96it/s]  2%|▏         | 2/100 [00:00<00:21,  4.60it/s]  3%|▎         | 3/100 [00:00<00:21,  4.59it/s]  4%|▍         | 4/100 [00:00<00:21,  4.55it/s]  5%|▌         | 5/100 [00:01<00:20,  4.54it/s]  6%|▌         | 6/100 [00:01<00:20,  4.64it/s]  7%|▋         | 7/100 [00:01<00:19,  4.78it/s]  8%|▊         | 8/100 [00:01<00:19,  4.83it/s]  9%|▉         | 9/100 [00:01<00:18,  4.90it/s] 10%|█         | 10/100 [00:02<00:18,  4.97it/s] 11%|█         | 11/100 [00:02<00:18,  4.92it/s] 12%|█▏        | 12/100 [00:02<00:17,  5.01it/s] 13%|█▎        | 13/100 [00:02<00:17,  5.03it/s] 14%|█▍        | 14/100 [00:02<00:17,  5.03it/s] 15%|█▌        | 15/100 [00:03<00:16,  5.14it/s] 16%|█▌        | 16/100 [00:03<00:17,  4.86it/s] 17%|█▋        | 17/100 [00:03<00:17,  4.88it/s] 18%|█▊        | 18/100 [00:03<00:16,  4.93it/s] 19%|█▉        | 19/100 [00:03<00:16,  5.01it/s] 20%|██        | 20/100 [00:04<00:15,  5.08it/s] 21%|██        | 21/100 [00:04<00:15,  5.05it/s] 22%|██▏       | 22/100 [00:04<00:15,  5.08it/s] 23%|██▎       | 23/100 [00:04<00:15,  5.12it/s] 24%|██▍       | 24/100 [00:05<00:19,  3.93it/s] 25%|██▌       | 25/100 [00:05<00:19,  3.92it/s] 26%|██▌       | 26/100 [00:05<00:17,  4.18it/s] 27%|██▋       | 27/100 [00:05<00:16,  4.38it/s] 28%|██▊       | 28/100 [00:05<00:16,  4.48it/s] 29%|██▉       | 29/100 [00:06<00:15,  4.48it/s] 30%|███       | 30/100 [00:06<00:15,  4.49it/s] 31%|███       | 31/100 [00:06<00:16,  4.31it/s] 32%|███▏      | 32/100 [00:06<00:15,  4.51it/s] 33%|███▎      | 33/100 [00:07<00:14,  4.68it/s] 34%|███▍      | 34/100 [00:07<00:13,  4.77it/s] 35%|███▌      | 35/100 [00:07<00:13,  4.85it/s] 36%|███▌      | 36/100 [00:07<00:12,  4.93it/s] 37%|███▋      | 37/100 [00:07<00:12,  4.97it/s] 38%|███▊      | 38/100 [00:08<00:12,  4.97it/s] 39%|███▉      | 39/100 [00:08<00:12,  5.02it/s] 40%|████      | 40/100 [00:08<00:11,  5.09it/s] 41%|████      | 41/100 [00:08<00:11,  5.07it/s] 42%|████▏     | 42/100 [00:08<00:11,  5.00it/s] 43%|████▎     | 43/100 [00:09<00:11,  4.98it/s] 44%|████▍     | 44/100 [00:09<00:11,  4.92it/s] 45%|████▌     | 45/100 [00:09<00:11,  4.96it/s] 46%|████▌     | 46/100 [00:09<00:10,  4.91it/s] 47%|████▋     | 47/100 [00:09<00:10,  4.98it/s] 48%|████▊     | 48/100 [00:10<00:10,  5.13it/s] 49%|████▉     | 49/100 [00:10<00:18,  2.70it/s] 50%|█████     | 50/100 [00:10<00:15,  3.14it/s] 51%|█████     | 51/100 [00:11<00:13,  3.59it/s] 52%|█████▏    | 52/100 [00:11<00:12,  3.94it/s] 53%|█████▎    | 53/100 [00:11<00:10,  4.29it/s] 54%|█████▍    | 54/100 [00:11<00:09,  4.70it/s] 55%|█████▌    | 55/100 [00:11<00:08,  5.02it/s] 56%|█████▌    | 56/100 [00:12<00:08,  5.35it/s] 57%|█████▋    | 57/100 [00:12<00:07,  5.61it/s] 58%|█████▊    | 58/100 [00:12<00:07,  5.70it/s] 59%|█████▉    | 59/100 [00:12<00:07,  5.85it/s] 60%|██████    | 60/100 [00:12<00:06,  5.79it/s] 61%|██████    | 61/100 [00:12<00:06,  5.92it/s] 62%|██████▏   | 62/100 [00:13<00:06,  6.07it/s] 63%|██████▎   | 63/100 [00:13<00:06,  6.06it/s] 64%|██████▍   | 64/100 [00:13<00:05,  6.04it/s] 65%|██████▌   | 65/100 [00:13<00:05,  6.09it/s] 66%|██████▌   | 66/100 [00:13<00:05,  6.17it/s] 67%|██████▋   | 67/100 [00:13<00:05,  6.08it/s] 68%|██████▊   | 68/100 [00:13<00:05,  6.09it/s] 69%|██████▉   | 69/100 [00:14<00:05,  6.11it/s] 70%|███████   | 70/100 [00:14<00:04,  6.08it/s] 71%|███████   | 71/100 [00:14<00:04,  6.06it/s] 72%|███████▏  | 72/100 [00:14<00:04,  6.19it/s] 73%|███████▎  | 73/100 [00:14<00:04,  6.16it/s] 74%|███████▍  | 74/100 [00:14<00:04,  6.17it/s] 75%|███████▌  | 75/100 [00:15<00:03,  6.26it/s] 76%|███████▌  | 76/100 [00:15<00:03,  6.24it/s] 77%|███████▋  | 77/100 [00:17<00:19,  1.19it/s] 78%|███████▊  | 78/100 [00:17<00:14,  1.51it/s] 79%|███████▉  | 79/100 [00:18<00:11,  1.90it/s] 80%|████████  | 80/100 [00:18<00:08,  2.36it/s] 81%|████████  | 81/100 [00:18<00:06,  2.87it/s] 82%|████████▏ | 82/100 [00:18<00:05,  3.40it/s] 83%|████████▎ | 83/100 [00:18<00:04,  3.84it/s] 84%|████████▍ | 84/100 [00:19<00:03,  4.27it/s] 85%|████████▌ | 85/100 [00:19<00:03,  4.60it/s] 86%|████████▌ | 86/100 [00:19<00:02,  4.94it/s] 87%|████████▋ | 87/100 [00:19<00:02,  5.13it/s] 88%|████████▊ | 88/100 [00:19<00:02,  5.26it/s] 89%|████████▉ | 89/100 [00:19<00:02,  5.38it/s] 90%|█████████ | 90/100 [00:20<00:01,  5.50it/s] 91%|█████████ | 91/100 [00:20<00:01,  5.57it/s] 92%|█████████▏| 92/100 [00:20<00:01,  5.66it/s] 93%|█████████▎| 93/100 [00:20<00:01,  5.69it/s] 94%|█████████▍| 94/100 [00:20<00:01,  5.75it/s] 95%|█████████▌| 95/100 [00:20<00:00,  5.73it/s] 96%|█████████▌| 96/100 [00:21<00:00,  5.83it/s] 97%|█████████▋| 97/100 [00:21<00:00,  5.92it/s] 98%|█████████▊| 98/100 [00:21<00:00,  5.99it/s] 99%|█████████▉| 99/100 [00:21<00:00,  6.00it/s]100%|██████████| 100/100 [00:21<00:00,  6.04it/s]100%|██████████| 100/100 [00:21<00:00,  4.59it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0099, 0.0099
--- total mse / var(X): 0.0099
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00116, 0.00116
--- total mse / var(X): 0.00116
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.01, 0.01
--- total mse / var(X): 0.01
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00923, 0.00923
--- total mse / var(X): 0.00923
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0529, 0.0529
--- total mse / var(X): 0.0529
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:15,  6.53it/s]  2%|▏         | 2/100 [00:00<00:13,  7.37it/s]  3%|▎         | 3/100 [00:00<00:11,  8.23it/s]  4%|▍         | 4/100 [00:00<00:12,  7.68it/s]  5%|▌         | 5/100 [00:00<00:13,  6.91it/s]  6%|▌         | 6/100 [00:00<00:14,  6.67it/s]  7%|▋         | 7/100 [00:01<00:14,  6.38it/s]  8%|▊         | 8/100 [00:01<00:13,  6.85it/s]  9%|▉         | 9/100 [00:01<00:12,  7.06it/s] 10%|█         | 10/100 [00:01<00:12,  7.08it/s] 11%|█         | 11/100 [00:01<00:12,  6.94it/s] 12%|█▏        | 12/100 [00:01<00:14,  5.89it/s] 13%|█▎        | 13/100 [00:01<00:14,  6.12it/s] 14%|█▍        | 14/100 [00:02<00:13,  6.28it/s] 16%|█▌        | 16/100 [00:02<00:10,  7.72it/s] 17%|█▋        | 17/100 [00:02<00:10,  8.12it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.32it/s] 20%|██        | 20/100 [00:02<00:08,  9.45it/s] 22%|██▏       | 22/100 [00:02<00:08,  9.72it/s] 23%|██▎       | 23/100 [00:03<00:08,  8.95it/s] 24%|██▍       | 24/100 [00:03<00:08,  8.73it/s] 26%|██▌       | 26/100 [00:03<00:07, 10.01it/s] 28%|██▊       | 28/100 [00:03<00:06, 10.87it/s] 30%|███       | 30/100 [00:03<00:07,  9.90it/s] 32%|███▏      | 32/100 [00:03<00:07,  9.38it/s] 34%|███▍      | 34/100 [00:04<00:06,  9.71it/s] 35%|███▌      | 35/100 [00:04<00:06,  9.55it/s] 37%|███▋      | 37/100 [00:04<00:05, 10.60it/s] 39%|███▉      | 39/100 [00:04<00:05, 10.94it/s] 41%|████      | 41/100 [00:04<00:05, 10.15it/s] 43%|████▎     | 43/100 [00:04<00:05,  9.82it/s] 44%|████▍     | 44/100 [00:05<00:05,  9.71it/s] 46%|████▌     | 46/100 [00:05<00:05,  9.20it/s] 48%|████▊     | 48/100 [00:05<00:05, 10.10it/s] 50%|█████     | 50/100 [00:05<00:04, 10.14it/s] 52%|█████▏    | 52/100 [00:05<00:04,  9.76it/s] 54%|█████▍    | 54/100 [00:06<00:04,  9.53it/s] 55%|█████▌    | 55/100 [00:06<00:04,  9.37it/s] 56%|█████▌    | 56/100 [00:06<00:04,  9.42it/s] 57%|█████▋    | 57/100 [00:06<00:04,  9.33it/s] 58%|█████▊    | 58/100 [00:06<00:04,  8.73it/s] 59%|█████▉    | 59/100 [00:06<00:04,  8.58it/s] 60%|██████    | 60/100 [00:06<00:04,  8.47it/s] 62%|██████▏   | 62/100 [00:06<00:03, 10.09it/s] 63%|██████▎   | 63/100 [00:07<00:03,  9.99it/s] 65%|██████▌   | 65/100 [00:07<00:03, 10.10it/s] 66%|██████▌   | 66/100 [00:07<00:03,  9.54it/s] 67%|██████▋   | 67/100 [00:07<00:03,  9.07it/s] 69%|██████▉   | 69/100 [00:07<00:03,  9.93it/s] 71%|███████   | 71/100 [00:07<00:02, 10.86it/s] 73%|███████▎  | 73/100 [00:08<00:02, 11.49it/s] 75%|███████▌  | 75/100 [00:08<00:02, 10.46it/s] 77%|███████▋  | 77/100 [00:08<00:02,  9.95it/s] 79%|███████▉  | 79/100 [00:08<00:02,  9.40it/s] 80%|████████  | 80/100 [00:08<00:02,  9.12it/s] 81%|████████  | 81/100 [00:08<00:02,  8.75it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.72it/s] 84%|████████▍ | 84/100 [00:09<00:01,  9.07it/s] 85%|████████▌ | 85/100 [00:09<00:01,  9.11it/s] 86%|████████▌ | 86/100 [00:09<00:01,  9.29it/s] 88%|████████▊ | 88/100 [00:09<00:01, 10.08it/s] 89%|████████▉ | 89/100 [00:09<00:01,  9.90it/s] 91%|█████████ | 91/100 [00:09<00:00,  9.62it/s] 92%|█████████▏| 92/100 [00:10<00:00,  9.22it/s] 93%|█████████▎| 93/100 [00:10<00:00,  9.07it/s] 94%|█████████▍| 94/100 [00:10<00:00,  8.69it/s] 96%|█████████▌| 96/100 [00:10<00:00,  9.40it/s] 97%|█████████▋| 97/100 [00:10<00:00,  9.13it/s] 98%|█████████▊| 98/100 [00:10<00:00,  8.89it/s] 99%|█████████▉| 99/100 [00:10<00:00,  8.75it/s]100%|██████████| 100/100 [00:10<00:00,  9.09it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00898, 0.00898
--- total mse / var(X): 0.00898
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:14,  6.88it/s]  2%|▏         | 2/100 [00:00<00:11,  8.21it/s]  3%|▎         | 3/100 [00:00<00:11,  8.74it/s]  4%|▍         | 4/100 [00:00<00:11,  8.46it/s]  5%|▌         | 5/100 [00:00<00:12,  7.85it/s]  6%|▌         | 6/100 [00:00<00:11,  8.38it/s]  7%|▋         | 7/100 [00:00<00:10,  8.83it/s]  9%|▉         | 9/100 [00:00<00:08, 10.24it/s] 11%|█         | 11/100 [00:01<00:08, 10.43it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.08it/s] 14%|█▍        | 14/100 [00:01<00:09,  9.02it/s] 15%|█▌        | 15/100 [00:01<00:09,  9.23it/s] 17%|█▋        | 17/100 [00:01<00:07, 10.54it/s] 19%|█▉        | 19/100 [00:01<00:07, 10.52it/s] 21%|██        | 21/100 [00:02<00:07, 11.27it/s] 23%|██▎       | 23/100 [00:02<00:06, 11.29it/s] 25%|██▌       | 25/100 [00:02<00:07, 10.59it/s] 27%|██▋       | 27/100 [00:02<00:07,  9.78it/s] 29%|██▉       | 29/100 [00:02<00:07, 10.01it/s] 31%|███       | 31/100 [00:03<00:06, 10.63it/s] 33%|███▎      | 33/100 [00:03<00:06, 10.78it/s] 35%|███▌      | 35/100 [00:03<00:05, 11.76it/s] 37%|███▋      | 37/100 [00:03<00:05, 12.33it/s] 39%|███▉      | 39/100 [00:03<00:05, 12.12it/s] 41%|████      | 41/100 [00:03<00:04, 12.27it/s] 43%|████▎     | 43/100 [00:04<00:04, 12.81it/s] 45%|████▌     | 45/100 [00:04<00:04, 12.06it/s] 47%|████▋     | 47/100 [00:04<00:04, 12.83it/s] 49%|████▉     | 49/100 [00:04<00:04, 12.44it/s] 51%|█████     | 51/100 [00:04<00:03, 12.69it/s] 53%|█████▎    | 53/100 [00:04<00:04, 11.22it/s] 55%|█████▌    | 55/100 [00:05<00:03, 11.45it/s] 57%|█████▋    | 57/100 [00:05<00:03, 12.25it/s] 59%|█████▉    | 59/100 [00:05<00:03, 12.07it/s] 61%|██████    | 61/100 [00:05<00:03, 11.97it/s] 63%|██████▎   | 63/100 [00:05<00:03, 12.10it/s] 65%|██████▌   | 65/100 [00:05<00:02, 12.85it/s] 67%|██████▋   | 67/100 [00:06<00:02, 12.54it/s] 69%|██████▉   | 69/100 [00:06<00:02, 13.41it/s] 71%|███████   | 71/100 [00:06<00:02, 13.69it/s] 73%|███████▎  | 73/100 [00:06<00:01, 14.33it/s] 75%|███████▌  | 75/100 [00:06<00:01, 14.50it/s] 77%|███████▋  | 77/100 [00:06<00:01, 13.62it/s] 79%|███████▉  | 79/100 [00:07<00:02,  9.95it/s] 81%|████████  | 81/100 [00:07<00:01, 10.33it/s] 83%|████████▎ | 83/100 [00:07<00:01, 10.12it/s] 85%|████████▌ | 85/100 [00:07<00:01, 10.85it/s] 87%|████████▋ | 87/100 [00:07<00:01, 11.10it/s] 89%|████████▉ | 89/100 [00:07<00:00, 11.05it/s] 91%|█████████ | 91/100 [00:08<00:00, 11.55it/s] 93%|█████████▎| 93/100 [00:08<00:00, 10.76it/s] 95%|█████████▌| 95/100 [00:08<00:00, 11.12it/s] 97%|█████████▋| 97/100 [00:08<00:00, 10.99it/s] 99%|█████████▉| 99/100 [00:08<00:00, 10.98it/s]100%|██████████| 100/100 [00:08<00:00, 11.19it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0126, 0.0126
--- total mse / var(X): 0.0126
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.32it/s]  2%|▏         | 2/100 [00:00<00:17,  5.45it/s]  4%|▍         | 4/100 [00:00<00:10,  9.18it/s]  6%|▌         | 6/100 [00:00<00:07, 12.23it/s]  8%|▊         | 8/100 [00:00<00:07, 11.93it/s] 10%|█         | 10/100 [00:00<00:08, 11.17it/s] 12%|█▏        | 12/100 [00:01<00:07, 12.23it/s] 14%|█▍        | 14/100 [00:01<00:06, 13.95it/s] 16%|█▌        | 16/100 [00:01<00:05, 14.32it/s] 18%|█▊        | 18/100 [00:01<00:05, 14.55it/s] 20%|██        | 20/100 [00:01<00:05, 14.80it/s] 22%|██▏       | 22/100 [00:01<00:05, 15.13it/s] 24%|██▍       | 24/100 [00:01<00:04, 15.42it/s] 26%|██▌       | 26/100 [00:02<00:05, 13.32it/s] 28%|██▊       | 28/100 [00:02<00:05, 12.21it/s] 30%|███       | 30/100 [00:02<00:07,  9.98it/s] 32%|███▏      | 32/100 [00:02<00:06, 10.04it/s] 34%|███▍      | 34/100 [00:02<00:06,  9.70it/s] 36%|███▌      | 36/100 [00:03<00:06,  9.51it/s] 37%|███▋      | 37/100 [00:03<00:06,  9.57it/s] 39%|███▉      | 39/100 [00:03<00:06,  9.28it/s] 41%|████      | 41/100 [00:03<00:06,  9.00it/s] 42%|████▏     | 42/100 [00:03<00:08,  7.18it/s] 43%|████▎     | 43/100 [00:04<00:07,  7.19it/s] 44%|████▍     | 44/100 [00:04<00:07,  7.54it/s] 45%|████▌     | 45/100 [00:04<00:07,  7.47it/s] 47%|████▋     | 47/100 [00:04<00:05,  9.02it/s] 49%|████▉     | 49/100 [00:04<00:05,  9.98it/s] 51%|█████     | 51/100 [00:04<00:04, 10.62it/s] 53%|█████▎    | 53/100 [00:05<00:04, 11.22it/s] 55%|█████▌    | 55/100 [00:05<00:04,  9.43it/s] 57%|█████▋    | 57/100 [00:05<00:05,  8.35it/s] 59%|█████▉    | 59/100 [00:05<00:04,  9.30it/s] 61%|██████    | 61/100 [00:05<00:04,  9.71it/s] 63%|██████▎   | 63/100 [00:06<00:03, 10.40it/s] 65%|██████▌   | 65/100 [00:06<00:03,  9.67it/s] 67%|██████▋   | 67/100 [00:06<00:03, 10.59it/s] 69%|██████▉   | 69/100 [00:06<00:02, 10.61it/s] 71%|███████   | 71/100 [00:06<00:02, 11.09it/s] 73%|███████▎  | 73/100 [00:07<00:02, 10.92it/s] 75%|███████▌  | 75/100 [00:07<00:02, 11.80it/s] 77%|███████▋  | 77/100 [00:07<00:01, 13.10it/s] 79%|███████▉  | 79/100 [00:07<00:01, 13.59it/s] 81%|████████  | 81/100 [00:07<00:01, 11.05it/s] 83%|████████▎ | 83/100 [00:07<00:01, 12.72it/s] 85%|████████▌ | 85/100 [00:07<00:01, 11.57it/s] 87%|████████▋ | 87/100 [00:08<00:01, 12.39it/s] 89%|████████▉ | 89/100 [00:08<00:00, 13.57it/s] 91%|█████████ | 91/100 [00:08<00:00, 14.08it/s] 93%|█████████▎| 93/100 [00:08<00:00, 14.78it/s] 95%|█████████▌| 95/100 [00:08<00:00, 11.37it/s] 97%|█████████▋| 97/100 [00:08<00:00, 12.37it/s] 99%|█████████▉| 99/100 [00:09<00:00, 13.13it/s]100%|██████████| 100/100 [00:09<00:00, 11.04it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00129, 0.00129
--- total mse / var(X): 0.00129
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:32,  3.02it/s]  3%|▎         | 3/100 [00:00<00:13,  7.14it/s]  4%|▍         | 4/100 [00:00<00:12,  7.41it/s]  5%|▌         | 5/100 [00:00<00:12,  7.56it/s]  6%|▌         | 6/100 [00:00<00:11,  8.20it/s]  8%|▊         | 8/100 [00:00<00:08, 10.49it/s] 10%|█         | 10/100 [00:01<00:08, 11.07it/s] 12%|█▏        | 12/100 [00:01<00:07, 11.29it/s] 14%|█▍        | 14/100 [00:01<00:07, 11.11it/s] 16%|█▌        | 16/100 [00:01<00:07, 10.71it/s] 18%|█▊        | 18/100 [00:01<00:07, 11.15it/s] 20%|██        | 20/100 [00:02<00:06, 11.58it/s] 22%|██▏       | 22/100 [00:02<00:06, 12.08it/s] 24%|██▍       | 24/100 [00:02<00:06, 11.86it/s] 26%|██▌       | 26/100 [00:02<00:05, 12.72it/s] 28%|██▊       | 28/100 [00:02<00:07,  9.85it/s] 30%|███       | 30/100 [00:02<00:06, 11.07it/s] 32%|███▏      | 32/100 [00:03<00:05, 11.34it/s] 34%|███▍      | 34/100 [00:03<00:05, 11.20it/s] 36%|███▌      | 36/100 [00:03<00:05, 11.48it/s] 38%|███▊      | 38/100 [00:03<00:04, 12.42it/s] 40%|████      | 40/100 [00:03<00:04, 13.56it/s] 42%|████▏     | 42/100 [00:03<00:04, 14.16it/s] 44%|████▍     | 44/100 [00:03<00:03, 14.94it/s] 46%|████▌     | 46/100 [00:04<00:03, 15.07it/s] 48%|████▊     | 48/100 [00:04<00:03, 16.07it/s] 50%|█████     | 50/100 [00:04<00:02, 16.87it/s] 52%|█████▏    | 52/100 [00:04<00:02, 16.48it/s] 54%|█████▍    | 54/100 [00:04<00:02, 16.58it/s] 56%|█████▌    | 56/100 [00:04<00:02, 16.70it/s] 58%|█████▊    | 58/100 [00:04<00:02, 17.07it/s] 60%|██████    | 60/100 [00:04<00:02, 16.30it/s] 62%|██████▏   | 62/100 [00:04<00:02, 17.07it/s] 64%|██████▍   | 64/100 [00:05<00:02, 17.00it/s] 66%|██████▌   | 66/100 [00:05<00:02, 16.83it/s] 68%|██████▊   | 68/100 [00:05<00:01, 16.88it/s] 70%|███████   | 70/100 [00:05<00:01, 16.82it/s] 72%|███████▏  | 72/100 [00:05<00:01, 17.11it/s] 74%|███████▍  | 74/100 [00:05<00:01, 17.50it/s] 76%|███████▌  | 76/100 [00:05<00:01, 17.95it/s] 78%|███████▊  | 78/100 [00:05<00:01, 17.86it/s] 80%|████████  | 80/100 [00:05<00:01, 17.37it/s] 82%|████████▏ | 82/100 [00:06<00:01, 17.32it/s] 84%|████████▍ | 84/100 [00:06<00:00, 17.92it/s] 86%|████████▌ | 86/100 [00:06<00:00, 18.06it/s] 88%|████████▊ | 88/100 [00:06<00:00, 16.67it/s] 90%|█████████ | 90/100 [00:06<00:00, 16.77it/s] 92%|█████████▏| 92/100 [00:06<00:00, 16.53it/s] 94%|█████████▍| 94/100 [00:06<00:00, 16.89it/s] 96%|█████████▌| 96/100 [00:06<00:00, 16.65it/s] 98%|█████████▊| 98/100 [00:07<00:00, 17.30it/s]100%|██████████| 100/100 [00:07<00:00, 16.96it/s]100%|██████████| 100/100 [00:07<00:00, 13.94it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000116, 0.000116
--- total mse / var(X): 0.000116
start table evaluation...
Elapsed time: 199.52457451820374 seconds
Cosine similarity between AMM and exact (Train): 0.85398656
Cosine similarity between AMM and exact (Test): 0.85716003
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7417032207109494 0.7925712280871553 0.7662939742959001
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.9863512516021729,
                                      0.9721618890762329,
                                      0.9574658870697021,
                                      0.8539867997169495],
               'cossim_layer_test': [0.97543865442276,
                                     0.9722755551338196,
                                     0.9595734477043152,
                                     0.8571600317955017],
               'cossim_amm_train': [0.9763956069946289,
                                    0.994312584400177,
                                    0.9637330174446106,
                                    0.8669089674949646,
                                    0.9676001071929932,
                                    0.943230926990509,
                                    0.9446815252304077,
                                    0.9328904151916504],
               'cossim_amm_test': [0.9581049680709839,
                                   0.9946845173835754,
                                   0.9682025909423828,
                                   0.8652447462081909,
                                   0.9686030745506287,
                                   0.9448719620704651,
                                   0.9485803246498108,
                                   0.9384554624557495],
               'f1': [0.7417032207109494,
                      0.7925712280871553,
                      0.7662939742959001],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 64),
                              (192, 1, 64),
                              (64, 64, 1),
                              (64, 64, 1),
                              (32, 1, 64),
                              (32, 1, 64),
                              (32, 1, 64),
                              (256, 1, 64)],
               'lut_total_size': 45056}}
python: can't open file 'train.py': [Errno 2] No such file or directory
Traceback (most recent call last):
  File "src/train.py", line 6, in <module>
    import yaml
ModuleNotFoundError: No module named 'yaml'
--- loading ---
<class 'pandas.core.frame.DataFrame'>
<class 'torch.utils.data.dataloader.DataLoader'>
--- prediction ---
predicting
  0%|          | 0/173 [00:00<?, ?it/s]  1%|          | 1/173 [00:00<01:34,  1.82it/s]  7%|▋         | 12/173 [00:00<00:06, 23.88it/s] 13%|█▎        | 23/173 [00:00<00:03, 43.04it/s] 20%|█▉        | 34/173 [00:00<00:02, 58.87it/s] 26%|██▌       | 45/173 [00:00<00:01, 71.28it/s] 33%|███▎      | 57/173 [00:01<00:01, 82.77it/s] 40%|███▉      | 69/173 [00:01<00:01, 90.77it/s] 46%|████▌     | 80/173 [00:01<00:00, 93.81it/s] 53%|█████▎    | 91/173 [00:01<00:00, 97.23it/s] 59%|█████▉    | 102/173 [00:01<00:00, 99.89it/s] 65%|██████▌   | 113/173 [00:01<00:00, 101.94it/s] 72%|███████▏  | 124/173 [00:01<00:00, 103.45it/s] 78%|███████▊  | 135/173 [00:01<00:00, 104.53it/s] 84%|████████▍ | 146/173 [00:01<00:00, 105.22it/s] 91%|█████████ | 157/173 [00:02<00:00, 105.20it/s] 97%|█████████▋| 168/173 [00:02<00:00, 106.22it/s]100%|██████████| 173/173 [00:02<00:00, 80.31it/s] 
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
--- post processing delta filter ---
post_processing, opt_threshold<0.9
filtering
             app       mean   max  min  median
0  410.bwaves-s0  14.630779  16.0  1.0    16.0
Done: results saved at: res/410.bwaves-s0.vitt.pkl.degree_stats.csv
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 0.99999964
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.106, 0.106
--- total mse / var(X): 0.106
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:49,  1.98it/s]  2%|▏         | 2/100 [00:01<00:50,  1.95it/s]  3%|▎         | 3/100 [00:01<00:49,  1.95it/s]  4%|▍         | 4/100 [00:02<00:49,  1.95it/s]  5%|▌         | 5/100 [00:02<00:46,  2.03it/s]  6%|▌         | 6/100 [00:02<00:44,  2.09it/s]  7%|▋         | 7/100 [00:03<00:42,  2.21it/s]  8%|▊         | 8/100 [00:03<00:39,  2.35it/s]  9%|▉         | 9/100 [00:04<00:39,  2.28it/s] 10%|█         | 10/100 [00:04<00:38,  2.32it/s] 11%|█         | 11/100 [00:05<00:37,  2.35it/s] 12%|█▏        | 12/100 [00:05<00:39,  2.24it/s] 13%|█▎        | 13/100 [00:05<00:39,  2.19it/s] 14%|█▍        | 14/100 [00:06<00:37,  2.29it/s] 15%|█▌        | 15/100 [00:06<00:36,  2.34it/s] 16%|█▌        | 16/100 [00:07<00:36,  2.29it/s] 17%|█▋        | 17/100 [00:07<00:35,  2.31it/s] 18%|█▊        | 18/100 [00:08<00:34,  2.35it/s] 19%|█▉        | 19/100 [00:08<00:35,  2.29it/s] 20%|██        | 20/100 [00:09<00:37,  2.12it/s] 21%|██        | 21/100 [00:09<00:37,  2.10it/s] 22%|██▏       | 22/100 [00:10<00:36,  2.15it/s] 23%|██▎       | 23/100 [00:10<00:36,  2.13it/s] 24%|██▍       | 24/100 [00:10<00:35,  2.12it/s] 25%|██▌       | 25/100 [00:11<00:35,  2.13it/s] 26%|██▌       | 26/100 [00:11<00:34,  2.12it/s] 27%|██▋       | 27/100 [00:12<00:33,  2.20it/s] 28%|██▊       | 28/100 [00:12<00:32,  2.23it/s] 29%|██▉       | 29/100 [00:13<00:31,  2.26it/s] 30%|███       | 30/100 [00:13<00:30,  2.30it/s] 31%|███       | 31/100 [00:14<00:29,  2.35it/s] 32%|███▏      | 32/100 [00:14<00:28,  2.41it/s] 33%|███▎      | 33/100 [00:14<00:27,  2.42it/s] 34%|███▍      | 34/100 [00:15<00:27,  2.43it/s] 35%|███▌      | 35/100 [00:15<00:26,  2.44it/s] 36%|███▌      | 36/100 [00:16<00:26,  2.43it/s] 37%|███▋      | 37/100 [00:16<00:26,  2.40it/s] 38%|███▊      | 38/100 [00:16<00:26,  2.33it/s] 39%|███▉      | 39/100 [00:17<00:27,  2.22it/s] 40%|████      | 40/100 [00:17<00:26,  2.23it/s] 41%|████      | 41/100 [00:18<00:26,  2.23it/s] 42%|████▏     | 42/100 [00:18<00:24,  2.33it/s] 43%|████▎     | 43/100 [00:19<00:24,  2.31it/s] 44%|████▍     | 44/100 [00:19<00:23,  2.33it/s] 45%|████▌     | 45/100 [00:20<00:24,  2.28it/s] 46%|████▌     | 46/100 [00:20<00:23,  2.27it/s] 47%|████▋     | 47/100 [00:20<00:24,  2.18it/s] 48%|████▊     | 48/100 [00:21<00:25,  2.03it/s] 49%|████▉     | 49/100 [00:22<00:25,  1.96it/s] 50%|█████     | 50/100 [00:22<00:25,  1.95it/s] 51%|█████     | 51/100 [00:23<00:24,  2.00it/s] 52%|█████▏    | 52/100 [00:23<00:22,  2.10it/s] 53%|█████▎    | 53/100 [00:23<00:22,  2.11it/s] 54%|█████▍    | 54/100 [00:24<00:21,  2.17it/s] 55%|█████▌    | 55/100 [00:24<00:20,  2.17it/s] 56%|█████▌    | 56/100 [00:25<00:19,  2.23it/s] 57%|█████▋    | 57/100 [00:25<00:19,  2.18it/s] 58%|█████▊    | 58/100 [00:26<00:18,  2.26it/s] 59%|█████▉    | 59/100 [00:26<00:17,  2.36it/s] 60%|██████    | 60/100 [00:27<00:17,  2.31it/s] 61%|██████    | 61/100 [00:27<00:16,  2.40it/s] 62%|██████▏   | 62/100 [00:27<00:16,  2.24it/s] 63%|██████▎   | 63/100 [00:28<00:16,  2.26it/s] 64%|██████▍   | 64/100 [00:28<00:15,  2.26it/s] 65%|██████▌   | 65/100 [00:29<00:15,  2.25it/s] 66%|██████▌   | 66/100 [00:29<00:14,  2.27it/s] 67%|██████▋   | 67/100 [00:30<00:15,  2.17it/s] 68%|██████▊   | 68/100 [00:30<00:15,  2.11it/s] 69%|██████▉   | 69/100 [00:31<00:14,  2.07it/s] 70%|███████   | 70/100 [00:31<00:14,  2.06it/s] 71%|███████   | 71/100 [00:32<00:13,  2.13it/s] 72%|███████▏  | 72/100 [00:32<00:12,  2.18it/s] 73%|███████▎  | 73/100 [00:32<00:12,  2.24it/s] 74%|███████▍  | 74/100 [00:33<00:11,  2.33it/s] 75%|███████▌  | 75/100 [00:33<00:10,  2.30it/s] 76%|███████▌  | 76/100 [00:34<00:10,  2.34it/s] 77%|███████▋  | 77/100 [00:34<00:09,  2.33it/s] 78%|███████▊  | 78/100 [00:35<00:09,  2.31it/s] 79%|███████▉  | 79/100 [00:35<00:09,  2.28it/s] 80%|████████  | 80/100 [00:35<00:08,  2.24it/s] 81%|████████  | 81/100 [00:36<00:08,  2.25it/s] 82%|████████▏ | 82/100 [00:36<00:08,  2.25it/s] 83%|████████▎ | 83/100 [00:37<00:07,  2.20it/s] 84%|████████▍ | 84/100 [00:37<00:07,  2.24it/s] 85%|████████▌ | 85/100 [00:38<00:06,  2.23it/s] 86%|████████▌ | 86/100 [00:38<00:06,  2.21it/s] 87%|████████▋ | 87/100 [00:39<00:05,  2.26it/s] 88%|████████▊ | 88/100 [00:39<00:05,  2.24it/s] 89%|████████▉ | 89/100 [00:40<00:05,  2.20it/s] 90%|█████████ | 90/100 [00:40<00:04,  2.20it/s] 91%|█████████ | 91/100 [00:41<00:04,  2.06it/s] 92%|█████████▏| 92/100 [00:41<00:03,  2.05it/s] 93%|█████████▎| 93/100 [00:42<00:03,  2.00it/s] 94%|█████████▍| 94/100 [00:42<00:03,  1.77it/s] 95%|█████████▌| 95/100 [00:43<00:02,  1.67it/s] 96%|█████████▌| 96/100 [00:44<00:02,  1.69it/s] 97%|█████████▋| 97/100 [00:44<00:01,  1.67it/s] 98%|█████████▊| 98/100 [00:45<00:01,  1.72it/s] 99%|█████████▉| 99/100 [00:45<00:00,  1.72it/s]100%|██████████| 100/100 [00:46<00:00,  1.77it/s]100%|██████████| 100/100 [00:46<00:00,  2.16it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999998
Manual and Torch results cosine similarity (Test): 0.99999964
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0478, 0.0741
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000639, 0.000287
--- total mse / var(X): 0.0372
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:08,  1.46it/s]  2%|▏         | 2/100 [00:01<01:08,  1.42it/s]  3%|▎         | 3/100 [00:02<01:06,  1.46it/s]  4%|▍         | 4/100 [00:02<01:05,  1.46it/s]  5%|▌         | 5/100 [00:03<01:06,  1.44it/s]  6%|▌         | 6/100 [00:04<01:04,  1.45it/s]  7%|▋         | 7/100 [00:04<01:02,  1.48it/s]  8%|▊         | 8/100 [00:05<01:01,  1.51it/s]  9%|▉         | 9/100 [00:06<01:03,  1.44it/s] 10%|█         | 10/100 [00:06<00:58,  1.53it/s] 11%|█         | 11/100 [00:07<00:55,  1.62it/s] 12%|█▏        | 12/100 [00:07<00:53,  1.65it/s] 13%|█▎        | 13/100 [00:08<00:53,  1.62it/s] 14%|█▍        | 14/100 [00:09<00:55,  1.55it/s] 15%|█▌        | 15/100 [00:09<00:58,  1.47it/s] 16%|█▌        | 16/100 [00:10<00:57,  1.47it/s] 17%|█▋        | 17/100 [00:11<00:54,  1.52it/s] 18%|█▊        | 18/100 [00:12<00:55,  1.47it/s] 19%|█▉        | 19/100 [00:12<00:53,  1.51it/s] 20%|██        | 20/100 [00:13<00:53,  1.50it/s] 21%|██        | 21/100 [00:13<00:51,  1.53it/s] 22%|██▏       | 22/100 [00:14<00:50,  1.55it/s] 23%|██▎       | 23/100 [00:15<00:48,  1.60it/s] 24%|██▍       | 24/100 [00:15<00:45,  1.69it/s] 25%|██▌       | 25/100 [00:16<00:47,  1.59it/s] 26%|██▌       | 26/100 [00:17<00:48,  1.53it/s] 27%|██▋       | 27/100 [00:17<00:48,  1.50it/s] 28%|██▊       | 28/100 [00:18<00:48,  1.49it/s] 29%|██▉       | 29/100 [00:19<00:50,  1.40it/s] 30%|███       | 30/100 [00:19<00:47,  1.46it/s] 31%|███       | 31/100 [00:20<00:44,  1.55it/s] 32%|███▏      | 32/100 [00:21<00:43,  1.55it/s] 33%|███▎      | 33/100 [00:21<00:43,  1.54it/s] 34%|███▍      | 34/100 [00:22<00:43,  1.50it/s] 35%|███▌      | 35/100 [00:23<00:43,  1.49it/s] 36%|███▌      | 36/100 [00:23<00:42,  1.51it/s] 37%|███▋      | 37/100 [00:24<00:44,  1.41it/s] 38%|███▊      | 38/100 [00:25<00:43,  1.41it/s] 39%|███▉      | 39/100 [00:25<00:41,  1.46it/s] 40%|████      | 40/100 [00:26<00:42,  1.42it/s] 41%|████      | 41/100 [00:27<00:40,  1.47it/s] 42%|████▏     | 42/100 [00:27<00:37,  1.53it/s] 43%|████▎     | 43/100 [00:28<00:35,  1.62it/s] 44%|████▍     | 44/100 [00:28<00:33,  1.67it/s] 45%|████▌     | 45/100 [00:29<00:31,  1.74it/s] 46%|████▌     | 46/100 [00:30<00:30,  1.77it/s] 47%|████▋     | 47/100 [00:30<00:31,  1.67it/s] 48%|████▊     | 48/100 [00:31<00:32,  1.61it/s] 49%|████▉     | 49/100 [00:32<00:33,  1.53it/s] 50%|█████     | 50/100 [00:32<00:32,  1.54it/s] 51%|█████     | 51/100 [00:33<00:31,  1.56it/s] 52%|█████▏    | 52/100 [00:34<00:31,  1.55it/s] 53%|█████▎    | 53/100 [00:34<00:30,  1.56it/s] 54%|█████▍    | 54/100 [00:36<00:41,  1.10it/s] 55%|█████▌    | 55/100 [00:36<00:38,  1.18it/s] 56%|█████▌    | 56/100 [00:37<00:33,  1.31it/s] 57%|█████▋    | 57/100 [00:38<00:30,  1.43it/s] 58%|█████▊    | 58/100 [00:38<00:27,  1.50it/s] 59%|█████▉    | 59/100 [00:39<00:25,  1.59it/s] 60%|██████    | 60/100 [00:39<00:24,  1.65it/s] 61%|██████    | 61/100 [00:40<00:22,  1.77it/s] 62%|██████▏   | 62/100 [00:40<00:20,  1.86it/s] 63%|██████▎   | 63/100 [00:41<00:19,  1.88it/s] 64%|██████▍   | 64/100 [00:41<00:18,  1.94it/s] 65%|██████▌   | 65/100 [00:42<00:17,  1.96it/s] 66%|██████▌   | 66/100 [00:42<00:17,  1.98it/s] 67%|██████▋   | 67/100 [00:43<00:16,  2.02it/s] 68%|██████▊   | 68/100 [00:43<00:17,  1.84it/s] 69%|██████▉   | 69/100 [00:44<00:18,  1.68it/s] 70%|███████   | 70/100 [00:45<00:20,  1.50it/s] 71%|███████   | 71/100 [00:46<00:19,  1.46it/s] 72%|███████▏  | 72/100 [00:46<00:18,  1.54it/s] 73%|███████▎  | 73/100 [00:47<00:17,  1.52it/s] 74%|███████▍  | 74/100 [00:47<00:16,  1.56it/s] 75%|███████▌  | 75/100 [00:48<00:15,  1.60it/s] 76%|███████▌  | 76/100 [00:49<00:14,  1.60it/s] 77%|███████▋  | 77/100 [00:49<00:13,  1.66it/s] 78%|███████▊  | 78/100 [00:50<00:12,  1.69it/s] 79%|███████▉  | 79/100 [00:50<00:12,  1.69it/s] 80%|████████  | 80/100 [00:51<00:11,  1.67it/s] 81%|████████  | 81/100 [00:52<00:12,  1.48it/s] 82%|████████▏ | 82/100 [00:52<00:12,  1.47it/s] 83%|████████▎ | 83/100 [00:53<00:11,  1.46it/s] 84%|████████▍ | 84/100 [00:54<00:10,  1.49it/s] 85%|████████▌ | 85/100 [00:54<00:09,  1.57it/s] 86%|████████▌ | 86/100 [00:55<00:08,  1.57it/s] 87%|████████▋ | 87/100 [00:56<00:07,  1.66it/s] 88%|████████▊ | 88/100 [00:56<00:07,  1.70it/s] 89%|████████▉ | 89/100 [00:57<00:06,  1.60it/s] 90%|█████████ | 90/100 [00:57<00:06,  1.65it/s] 91%|█████████ | 91/100 [00:58<00:05,  1.67it/s] 92%|█████████▏| 92/100 [00:59<00:04,  1.70it/s] 93%|█████████▎| 93/100 [00:59<00:04,  1.67it/s] 94%|█████████▍| 94/100 [01:00<00:03,  1.62it/s] 95%|█████████▌| 95/100 [01:00<00:02,  1.71it/s] 96%|█████████▌| 96/100 [01:01<00:02,  1.80it/s] 97%|█████████▋| 97/100 [01:01<00:01,  1.96it/s] 98%|█████████▊| 98/100 [01:02<00:00,  2.06it/s] 99%|█████████▉| 99/100 [01:02<00:00,  2.12it/s]100%|██████████| 100/100 [01:02<00:00,  2.17it/s]100%|██████████| 100/100 [01:02<00:00,  1.59it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00936, 0.00936
--- total mse / var(X): 0.00936
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00111, 0.00111
--- total mse / var(X): 0.00111
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00683, 0.00683
--- total mse / var(X): 0.00683
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.011, 0.011
--- total mse / var(X): 0.011
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0636, 0.0636
--- total mse / var(X): 0.0636
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.30it/s]  2%|▏         | 2/100 [00:00<00:13,  7.27it/s]  3%|▎         | 3/100 [00:00<00:17,  5.43it/s]  4%|▍         | 4/100 [00:00<00:15,  6.09it/s]  6%|▌         | 6/100 [00:00<00:12,  7.26it/s]  7%|▋         | 7/100 [00:01<00:12,  7.25it/s]  9%|▉         | 9/100 [00:01<00:10,  8.61it/s] 11%|█         | 11/100 [00:01<00:08, 10.23it/s] 13%|█▎        | 13/100 [00:01<00:07, 11.34it/s] 15%|█▌        | 15/100 [00:01<00:07, 12.05it/s] 17%|█▋        | 17/100 [00:01<00:06, 13.16it/s] 19%|█▉        | 19/100 [00:01<00:06, 13.34it/s] 21%|██        | 21/100 [00:02<00:06, 12.24it/s] 23%|██▎       | 23/100 [00:02<00:07, 10.11it/s] 25%|██▌       | 25/100 [00:02<00:07, 10.62it/s] 27%|██▋       | 27/100 [00:02<00:06, 11.12it/s] 29%|██▉       | 29/100 [00:02<00:06, 11.48it/s] 31%|███       | 31/100 [00:02<00:05, 12.30it/s] 33%|███▎      | 33/100 [00:03<00:05, 12.04it/s] 35%|███▌      | 35/100 [00:03<00:05, 12.59it/s] 37%|███▋      | 37/100 [00:03<00:04, 12.95it/s] 39%|███▉      | 39/100 [00:03<00:04, 13.38it/s] 41%|████      | 41/100 [00:03<00:05, 11.33it/s] 43%|████▎     | 43/100 [00:04<00:05, 10.87it/s] 45%|████▌     | 45/100 [00:04<00:05,  9.90it/s] 47%|████▋     | 47/100 [00:04<00:04, 10.98it/s] 49%|████▉     | 49/100 [00:04<00:04, 11.10it/s] 51%|█████     | 51/100 [00:04<00:04, 11.68it/s] 53%|█████▎    | 53/100 [00:04<00:04, 11.52it/s] 55%|█████▌    | 55/100 [00:05<00:03, 12.22it/s] 57%|█████▋    | 57/100 [00:05<00:03, 12.22it/s] 59%|█████▉    | 59/100 [00:05<00:03, 11.95it/s] 61%|██████    | 61/100 [00:05<00:04,  9.59it/s] 63%|██████▎   | 63/100 [00:05<00:03, 10.08it/s] 65%|██████▌   | 65/100 [00:06<00:03, 10.61it/s] 67%|██████▋   | 67/100 [00:06<00:02, 11.44it/s] 69%|██████▉   | 69/100 [00:06<00:02, 11.77it/s] 71%|███████   | 71/100 [00:06<00:02, 12.69it/s] 73%|███████▎  | 73/100 [00:06<00:01, 13.59it/s] 75%|███████▌  | 75/100 [00:06<00:01, 13.91it/s] 77%|███████▋  | 77/100 [00:06<00:01, 14.27it/s] 79%|███████▉  | 79/100 [00:06<00:01, 14.55it/s] 81%|████████  | 81/100 [00:07<00:01, 15.57it/s] 83%|████████▎ | 83/100 [00:07<00:01, 12.44it/s] 85%|████████▌ | 85/100 [00:07<00:01, 10.32it/s] 87%|████████▋ | 87/100 [00:07<00:01,  9.68it/s] 89%|████████▉ | 89/100 [00:07<00:01, 10.45it/s] 91%|█████████ | 91/100 [00:08<00:00, 11.70it/s] 93%|█████████▎| 93/100 [00:08<00:00, 12.42it/s] 95%|█████████▌| 95/100 [00:08<00:00, 13.23it/s] 97%|█████████▋| 97/100 [00:08<00:00, 14.06it/s] 99%|█████████▉| 99/100 [00:08<00:00, 13.53it/s]100%|██████████| 100/100 [00:08<00:00, 11.47it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00834, 0.00834
--- total mse / var(X): 0.00834
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:09, 10.40it/s]  4%|▍         | 4/100 [00:00<00:09,  9.88it/s]  6%|▌         | 6/100 [00:00<00:08, 10.57it/s]  8%|▊         | 8/100 [00:00<00:07, 12.50it/s] 10%|█         | 10/100 [00:00<00:06, 13.13it/s] 12%|█▏        | 12/100 [00:00<00:06, 14.00it/s] 14%|█▍        | 14/100 [00:01<00:07, 12.21it/s] 16%|█▌        | 16/100 [00:01<00:06, 12.90it/s] 18%|█▊        | 18/100 [00:01<00:07, 11.24it/s] 20%|██        | 20/100 [00:01<00:06, 11.78it/s] 22%|██▏       | 22/100 [00:01<00:06, 12.49it/s] 24%|██▍       | 24/100 [00:01<00:05, 13.16it/s] 26%|██▌       | 26/100 [00:02<00:05, 12.64it/s] 28%|██▊       | 28/100 [00:02<00:05, 13.01it/s] 30%|███       | 30/100 [00:02<00:05, 13.51it/s] 32%|███▏      | 32/100 [00:02<00:04, 14.64it/s] 34%|███▍      | 34/100 [00:02<00:04, 13.45it/s] 36%|███▌      | 36/100 [00:02<00:05, 11.71it/s] 38%|███▊      | 38/100 [00:03<00:05, 12.15it/s] 40%|████      | 40/100 [00:03<00:04, 13.06it/s] 42%|████▏     | 42/100 [00:03<00:04, 13.82it/s] 44%|████▍     | 44/100 [00:03<00:03, 14.35it/s] 46%|████▌     | 46/100 [00:03<00:03, 13.71it/s] 48%|████▊     | 48/100 [00:03<00:04, 12.15it/s] 50%|█████     | 50/100 [00:03<00:04, 11.87it/s] 52%|█████▏    | 52/100 [00:04<00:04, 11.30it/s] 54%|█████▍    | 54/100 [00:04<00:03, 12.38it/s] 56%|█████▌    | 56/100 [00:04<00:03, 13.27it/s] 58%|█████▊    | 58/100 [00:04<00:03, 13.92it/s] 60%|██████    | 60/100 [00:04<00:03, 12.25it/s] 62%|██████▏   | 62/100 [00:04<00:03, 12.36it/s] 64%|██████▍   | 64/100 [00:05<00:02, 13.41it/s] 66%|██████▌   | 66/100 [00:05<00:02, 14.45it/s] 68%|██████▊   | 68/100 [00:05<00:02, 14.95it/s] 70%|███████   | 70/100 [00:05<00:01, 15.31it/s] 72%|███████▏  | 72/100 [00:05<00:01, 14.20it/s] 74%|███████▍  | 74/100 [00:05<00:02, 11.38it/s] 76%|███████▌  | 76/100 [00:05<00:01, 12.50it/s] 78%|███████▊  | 78/100 [00:06<00:01, 14.00it/s] 80%|████████  | 80/100 [00:06<00:01, 14.88it/s] 82%|████████▏ | 82/100 [00:06<00:01, 14.88it/s] 84%|████████▍ | 84/100 [00:06<00:01, 15.13it/s] 86%|████████▌ | 86/100 [00:06<00:00, 15.70it/s] 89%|████████▉ | 89/100 [00:06<00:00, 17.44it/s] 91%|█████████ | 91/100 [00:06<00:00, 17.00it/s] 93%|█████████▎| 93/100 [00:06<00:00, 14.82it/s] 95%|█████████▌| 95/100 [00:07<00:00, 11.48it/s] 97%|█████████▋| 97/100 [00:07<00:00, 11.11it/s] 99%|█████████▉| 99/100 [00:07<00:00, 12.16it/s]100%|██████████| 100/100 [00:07<00:00, 13.01it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0126, 0.0126
--- total mse / var(X): 0.0126
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:14,  6.97it/s]  3%|▎         | 3/100 [00:00<00:09, 10.71it/s]  5%|▌         | 5/100 [00:00<00:08, 10.84it/s]  7%|▋         | 7/100 [00:00<00:07, 11.82it/s]  9%|▉         | 9/100 [00:00<00:07, 11.94it/s] 11%|█         | 11/100 [00:01<00:08, 10.71it/s] 13%|█▎        | 13/100 [00:01<00:07, 11.35it/s] 15%|█▌        | 15/100 [00:01<00:08,  9.59it/s] 17%|█▋        | 17/100 [00:01<00:08,  9.80it/s] 19%|█▉        | 19/100 [00:01<00:07, 10.82it/s] 21%|██        | 21/100 [00:01<00:06, 11.72it/s] 23%|██▎       | 23/100 [00:02<00:06, 11.83it/s] 25%|██▌       | 25/100 [00:02<00:06, 12.06it/s] 27%|██▋       | 27/100 [00:02<00:05, 12.66it/s] 29%|██▉       | 29/100 [00:02<00:05, 13.14it/s] 31%|███       | 31/100 [00:02<00:05, 13.72it/s] 33%|███▎      | 33/100 [00:02<00:04, 13.96it/s] 35%|███▌      | 35/100 [00:02<00:04, 14.31it/s] 37%|███▋      | 37/100 [00:03<00:04, 14.28it/s] 39%|███▉      | 39/100 [00:03<00:05, 11.07it/s] 41%|████      | 41/100 [00:03<00:05, 10.29it/s] 43%|████▎     | 43/100 [00:03<00:05, 10.90it/s] 45%|████▌     | 45/100 [00:03<00:05, 10.78it/s] 47%|████▋     | 47/100 [00:04<00:04, 11.79it/s] 49%|████▉     | 49/100 [00:04<00:04, 12.67it/s] 51%|█████     | 51/100 [00:04<00:03, 13.55it/s] 53%|█████▎    | 53/100 [00:04<00:03, 13.86it/s] 55%|█████▌    | 55/100 [00:04<00:03, 14.32it/s] 57%|█████▋    | 57/100 [00:04<00:02, 15.58it/s] 59%|█████▉    | 59/100 [00:04<00:02, 15.91it/s] 61%|██████    | 61/100 [00:04<00:02, 16.90it/s] 64%|██████▍   | 64/100 [00:05<00:01, 18.83it/s] 67%|██████▋   | 67/100 [00:05<00:01, 19.68it/s] 70%|███████   | 70/100 [00:05<00:01, 21.69it/s] 74%|███████▍  | 74/100 [00:05<00:01, 23.49it/s] 77%|███████▋  | 77/100 [00:05<00:01, 22.34it/s] 80%|████████  | 80/100 [00:05<00:00, 21.63it/s] 83%|████████▎ | 83/100 [00:05<00:00, 20.85it/s] 86%|████████▌ | 86/100 [00:06<00:00, 14.83it/s] 88%|████████▊ | 88/100 [00:06<00:00, 15.40it/s] 90%|█████████ | 90/100 [00:06<00:00, 16.21it/s] 93%|█████████▎| 93/100 [00:06<00:00, 18.68it/s] 96%|█████████▌| 96/100 [00:06<00:00, 19.01it/s] 99%|█████████▉| 99/100 [00:06<00:00, 18.90it/s]100%|██████████| 100/100 [00:06<00:00, 14.50it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00266, 0.00266
--- total mse / var(X): 0.00266
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  7.92it/s]  3%|▎         | 3/100 [00:00<00:07, 12.80it/s]  5%|▌         | 5/100 [00:00<00:06, 13.94it/s]  7%|▋         | 7/100 [00:00<00:06, 15.49it/s] 10%|█         | 10/100 [00:00<00:04, 19.18it/s] 12%|█▏        | 12/100 [00:00<00:05, 17.03it/s] 14%|█▍        | 14/100 [00:00<00:04, 17.50it/s] 17%|█▋        | 17/100 [00:00<00:04, 19.17it/s] 20%|██        | 20/100 [00:01<00:03, 20.38it/s] 23%|██▎       | 23/100 [00:01<00:03, 22.69it/s] 26%|██▌       | 26/100 [00:01<00:03, 24.07it/s] 29%|██▉       | 29/100 [00:01<00:02, 25.23it/s] 32%|███▏      | 32/100 [00:01<00:02, 24.65it/s] 35%|███▌      | 35/100 [00:01<00:02, 22.43it/s] 38%|███▊      | 38/100 [00:01<00:02, 23.09it/s] 41%|████      | 41/100 [00:01<00:02, 23.30it/s] 44%|████▍     | 44/100 [00:02<00:02, 21.70it/s] 47%|████▋     | 47/100 [00:02<00:02, 21.77it/s] 50%|█████     | 50/100 [00:02<00:02, 21.85it/s] 53%|█████▎    | 53/100 [00:02<00:02, 22.39it/s] 56%|█████▌    | 56/100 [00:02<00:02, 16.85it/s] 58%|█████▊    | 58/100 [00:03<00:03, 13.08it/s] 60%|██████    | 60/100 [00:03<00:03, 12.32it/s] 62%|██████▏   | 62/100 [00:03<00:03, 12.60it/s] 64%|██████▍   | 64/100 [00:03<00:02, 12.22it/s] 67%|██████▋   | 67/100 [00:03<00:02, 14.93it/s] 69%|██████▉   | 69/100 [00:03<00:02, 14.70it/s] 71%|███████   | 71/100 [00:03<00:01, 15.68it/s] 74%|███████▍  | 74/100 [00:04<00:01, 17.38it/s] 76%|███████▌  | 76/100 [00:04<00:01, 17.18it/s] 78%|███████▊  | 78/100 [00:04<00:01, 16.61it/s] 80%|████████  | 80/100 [00:04<00:01, 16.57it/s] 82%|████████▏ | 82/100 [00:04<00:01, 16.05it/s] 85%|████████▌ | 85/100 [00:04<00:00, 17.78it/s] 88%|████████▊ | 88/100 [00:04<00:00, 19.17it/s] 91%|█████████ | 91/100 [00:05<00:00, 20.34it/s] 94%|█████████▍| 94/100 [00:05<00:00, 20.99it/s] 97%|█████████▋| 97/100 [00:05<00:00, 23.05it/s]100%|██████████| 100/100 [00:05<00:00, 22.94it/s]100%|██████████| 100/100 [00:05<00:00, 18.53it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 1.000001
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 2.48e-05, 2.48e-05
--- total mse / var(X): 2.48e-05
start table evaluation...
Elapsed time: 234.70107746124268 seconds
4
(44138, 256)
Cosine similarity between AMM and exact (Train): 0.87222224
Cosine similarity between AMM and exact (Test): 0.8754967
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7630292669119728 0.8153521177879671 0.788323449251968
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.9868717193603516,
                                      0.977902889251709,
                                      0.958767831325531,
                                      0.8722221255302429],
               'cossim_layer_test': [0.9751067757606506,
                                     0.9783322811126709,
                                     0.9599167108535767,
                                     0.8754966259002686],
               'cossim_amm_train': [0.9772964119911194,
                                    0.9947893023490906,
                                    0.970413088798523,
                                    0.9179152250289917,
                                    0.9745864272117615,
                                    0.9409409165382385,
                                    0.9363579154014587,
                                    0.9407453536987305],
               'cossim_amm_test': [0.9575371146202087,
                                   0.9947242140769958,
                                   0.9735687971115112,
                                   0.9199224710464478,
                                   0.9761071801185608,
                                   0.9430790543556213,
                                   0.9393093585968018,
                                   0.9446460604667664],
               'f1': [0.7630292669119728,
                      0.8153521177879671,
                      0.788323449251968],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 64),
                              (192, 1, 64),
                              (64, 64, 1),
                              (64, 64, 1),
                              (32, 1, 64),
                              (32, 1, 64),
                              (32, 1, 64),
                              (256, 1, 64)],
               'lut_total_size': 45056}}

/data/neelesh/DART_by_app/410/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.027, 0.0418
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000204, 9.19e-05
--- total mse / var(X): 0.021
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:52,  1.90it/s]  2%|▏         | 2/100 [00:01<01:09,  1.42it/s]  3%|▎         | 3/100 [00:01<00:59,  1.63it/s]  4%|▍         | 4/100 [00:02<00:52,  1.85it/s]  5%|▌         | 5/100 [00:02<00:47,  2.01it/s]  6%|▌         | 6/100 [00:03<00:43,  2.15it/s]  7%|▋         | 7/100 [00:03<00:41,  2.22it/s]  8%|▊         | 8/100 [00:03<00:39,  2.34it/s]  9%|▉         | 9/100 [00:04<00:37,  2.45it/s] 10%|█         | 10/100 [00:04<00:36,  2.47it/s] 11%|█         | 11/100 [00:05<00:36,  2.45it/s] 12%|█▏        | 12/100 [00:05<00:33,  2.63it/s] 13%|█▎        | 13/100 [00:05<00:31,  2.73it/s] 14%|█▍        | 14/100 [00:06<00:30,  2.84it/s] 15%|█▌        | 15/100 [00:06<00:31,  2.73it/s] 16%|█▌        | 16/100 [00:06<00:30,  2.73it/s] 17%|█▋        | 17/100 [00:07<00:30,  2.76it/s] 18%|█▊        | 18/100 [00:07<00:29,  2.77it/s] 19%|█▉        | 19/100 [00:07<00:29,  2.75it/s] 20%|██        | 20/100 [00:08<00:28,  2.77it/s] 21%|██        | 21/100 [00:08<00:28,  2.82it/s] 22%|██▏       | 22/100 [00:08<00:27,  2.86it/s] 23%|██▎       | 23/100 [00:09<00:28,  2.75it/s] 24%|██▍       | 24/100 [00:09<00:30,  2.46it/s] 25%|██▌       | 25/100 [00:10<00:30,  2.43it/s] 26%|██▌       | 26/100 [00:10<00:31,  2.38it/s] 27%|██▋       | 27/100 [00:11<00:30,  2.37it/s] 28%|██▊       | 28/100 [00:11<00:30,  2.38it/s] 29%|██▉       | 29/100 [00:12<00:30,  2.31it/s] 30%|███       | 30/100 [00:12<00:32,  2.18it/s] 31%|███       | 31/100 [00:13<00:32,  2.13it/s] 32%|███▏      | 32/100 [00:13<00:31,  2.14it/s] 33%|███▎      | 33/100 [00:13<00:31,  2.15it/s] 34%|███▍      | 34/100 [00:14<00:32,  2.04it/s] 35%|███▌      | 35/100 [00:15<00:32,  2.00it/s] 36%|███▌      | 36/100 [00:15<00:32,  1.97it/s] 37%|███▋      | 37/100 [00:16<00:33,  1.85it/s] 38%|███▊      | 38/100 [00:16<00:32,  1.89it/s] 39%|███▉      | 39/100 [00:17<00:32,  1.88it/s] 40%|████      | 40/100 [00:17<00:30,  1.96it/s] 41%|████      | 41/100 [00:18<00:31,  1.85it/s] 42%|████▏     | 42/100 [00:18<00:30,  1.91it/s] 43%|████▎     | 43/100 [00:19<00:28,  1.97it/s] 44%|████▍     | 44/100 [00:19<00:27,  2.07it/s] 45%|████▌     | 45/100 [00:20<00:25,  2.13it/s] 46%|████▌     | 46/100 [00:20<00:24,  2.20it/s] 47%|████▋     | 47/100 [00:20<00:23,  2.25it/s] 48%|████▊     | 48/100 [00:21<00:23,  2.26it/s] 49%|████▉     | 49/100 [00:21<00:23,  2.19it/s] 50%|█████     | 50/100 [00:22<00:22,  2.20it/s] 51%|█████     | 51/100 [00:22<00:23,  2.10it/s] 52%|█████▏    | 52/100 [00:23<00:21,  2.23it/s] 53%|█████▎    | 53/100 [00:23<00:20,  2.30it/s] 54%|█████▍    | 54/100 [00:24<00:19,  2.38it/s] 55%|█████▌    | 55/100 [00:24<00:19,  2.34it/s] 56%|█████▌    | 56/100 [00:24<00:18,  2.37it/s] 57%|█████▋    | 57/100 [00:25<00:17,  2.44it/s] 58%|█████▊    | 58/100 [00:25<00:17,  2.36it/s] 59%|█████▉    | 59/100 [00:26<00:17,  2.31it/s] 60%|██████    | 60/100 [00:26<00:17,  2.32it/s] 61%|██████    | 61/100 [00:27<00:17,  2.25it/s] 62%|██████▏   | 62/100 [00:27<00:16,  2.25it/s] 63%|██████▎   | 63/100 [00:27<00:16,  2.19it/s] 64%|██████▍   | 64/100 [00:28<00:16,  2.14it/s] 65%|██████▌   | 65/100 [00:28<00:16,  2.17it/s] 66%|██████▌   | 66/100 [00:29<00:15,  2.26it/s] 67%|██████▋   | 67/100 [00:29<00:14,  2.26it/s] 68%|██████▊   | 68/100 [00:30<00:14,  2.24it/s] 69%|██████▉   | 69/100 [00:30<00:15,  2.02it/s] 70%|███████   | 70/100 [00:31<00:14,  2.13it/s] 71%|███████   | 71/100 [00:31<00:13,  2.21it/s] 72%|███████▏  | 72/100 [00:32<00:11,  2.35it/s] 73%|███████▎  | 73/100 [00:32<00:11,  2.45it/s] 74%|███████▍  | 74/100 [00:32<00:10,  2.57it/s] 75%|███████▌  | 75/100 [00:33<00:09,  2.62it/s] 76%|███████▌  | 76/100 [00:33<00:08,  2.69it/s] 77%|███████▋  | 77/100 [00:33<00:09,  2.49it/s] 78%|███████▊  | 78/100 [00:34<00:09,  2.37it/s] 79%|███████▉  | 79/100 [00:34<00:08,  2.34it/s] 80%|████████  | 80/100 [00:35<00:08,  2.30it/s] 81%|████████  | 81/100 [00:35<00:08,  2.17it/s] 82%|████████▏ | 82/100 [00:36<00:08,  2.17it/s] 83%|████████▎ | 83/100 [00:36<00:07,  2.19it/s] 84%|████████▍ | 84/100 [00:37<00:07,  2.22it/s] 85%|████████▌ | 85/100 [00:37<00:06,  2.16it/s] 86%|████████▌ | 86/100 [00:38<00:06,  2.18it/s] 87%|████████▋ | 87/100 [00:38<00:05,  2.23it/s] 88%|████████▊ | 88/100 [00:38<00:05,  2.21it/s] 89%|████████▉ | 89/100 [00:39<00:05,  2.12it/s] 90%|█████████ | 90/100 [00:39<00:04,  2.19it/s] 91%|█████████ | 91/100 [00:40<00:04,  2.20it/s] 92%|█████████▏| 92/100 [00:40<00:03,  2.26it/s] 93%|█████████▎| 93/100 [00:41<00:03,  2.27it/s] 94%|█████████▍| 94/100 [00:41<00:02,  2.29it/s] 95%|█████████▌| 95/100 [00:42<00:02,  2.32it/s] 96%|█████████▌| 96/100 [00:42<00:01,  2.36it/s] 97%|█████████▋| 97/100 [00:43<00:01,  2.07it/s] 98%|█████████▊| 98/100 [00:43<00:00,  2.05it/s] 99%|█████████▉| 99/100 [00:44<00:00,  1.96it/s]100%|██████████| 100/100 [00:44<00:00,  1.97it/s]100%|██████████| 100/100 [00:44<00:00,  2.24it/s]post_processing, opt_threshold<0.9
filtering
             app       mean   max  min  median
0  410.bwaves-s0  15.753251  16.0  1.0    16.0
Done: results saved at: res/410.bwaves-s0.vit.pkl.k.64.c.1.fine.degree_stats.csv

Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00901, 0.00788
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00632, 0.00711
--- total mse / var(X): 0.0075
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00114, 0.00116
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00111, 0.00109
--- total mse / var(X): 0.00112
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00512, 0.00464
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00373, 0.00408
--- total mse / var(X): 0.00436
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0116, 0.00389
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00572, 0.00953
--- total mse / var(X): 0.00671
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0125, 0.00934
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0148, 0.0186
--- total mse / var(X): 0.014
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:24,  4.10it/s]  3%|▎         | 3/100 [00:00<00:11,  8.70it/s]  5%|▌         | 5/100 [00:00<00:10,  8.94it/s]  6%|▌         | 6/100 [00:00<00:11,  8.42it/s]  8%|▊         | 8/100 [00:00<00:10,  9.16it/s] 10%|█         | 10/100 [00:01<00:08, 11.08it/s] 12%|█▏        | 12/100 [00:01<00:08, 10.69it/s] 14%|█▍        | 14/100 [00:01<00:06, 12.62it/s] 16%|█▌        | 16/100 [00:01<00:06, 13.74it/s] 18%|█▊        | 18/100 [00:01<00:05, 14.52it/s] 21%|██        | 21/100 [00:01<00:05, 15.51it/s] 23%|██▎       | 23/100 [00:01<00:04, 16.21it/s] 25%|██▌       | 25/100 [00:01<00:04, 17.02it/s] 28%|██▊       | 28/100 [00:02<00:04, 17.93it/s] 30%|███       | 30/100 [00:02<00:03, 17.70it/s] 33%|███▎      | 33/100 [00:02<00:03, 18.67it/s] 36%|███▌      | 36/100 [00:02<00:03, 19.92it/s] 39%|███▉      | 39/100 [00:02<00:03, 20.24it/s] 42%|████▏     | 42/100 [00:02<00:02, 20.12it/s] 45%|████▌     | 45/100 [00:02<00:02, 20.40it/s] 48%|████▊     | 48/100 [00:03<00:02, 19.55it/s] 51%|█████     | 51/100 [00:03<00:02, 19.59it/s] 53%|█████▎    | 53/100 [00:03<00:02, 18.93it/s] 56%|█████▌    | 56/100 [00:03<00:02, 19.91it/s] 59%|█████▉    | 59/100 [00:03<00:01, 20.97it/s] 62%|██████▏   | 62/100 [00:03<00:01, 19.60it/s] 64%|██████▍   | 64/100 [00:03<00:01, 19.14it/s] 66%|██████▌   | 66/100 [00:04<00:01, 18.40it/s] 68%|██████▊   | 68/100 [00:04<00:01, 16.69it/s] 71%|███████   | 71/100 [00:04<00:01, 18.56it/s] 73%|███████▎  | 73/100 [00:04<00:01, 18.08it/s] 75%|███████▌  | 75/100 [00:04<00:01, 17.39it/s] 78%|███████▊  | 78/100 [00:04<00:01, 19.52it/s] 81%|████████  | 81/100 [00:04<00:01, 18.77it/s] 84%|████████▍ | 84/100 [00:05<00:00, 20.13it/s] 87%|████████▋ | 87/100 [00:05<00:00, 20.56it/s] 90%|█████████ | 90/100 [00:05<00:00, 19.54it/s] 93%|█████████▎| 93/100 [00:05<00:00, 19.56it/s] 96%|█████████▌| 96/100 [00:05<00:00, 20.28it/s] 99%|█████████▉| 99/100 [00:05<00:00, 21.56it/s]100%|██████████| 100/100 [00:05<00:00, 17.30it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00399, 0.0052
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0227, 0.0159
--- total mse / var(X): 0.0105
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:10,  9.62it/s]  4%|▍         | 4/100 [00:00<00:07, 13.34it/s]  6%|▌         | 6/100 [00:00<00:06, 15.38it/s]  9%|▉         | 9/100 [00:00<00:04, 18.58it/s] 12%|█▏        | 12/100 [00:00<00:04, 21.35it/s] 15%|█▌        | 15/100 [00:00<00:03, 23.83it/s] 19%|█▉        | 19/100 [00:00<00:03, 26.34it/s] 22%|██▏       | 22/100 [00:01<00:03, 25.42it/s] 25%|██▌       | 25/100 [00:01<00:02, 25.60it/s] 29%|██▉       | 29/100 [00:01<00:02, 27.99it/s] 33%|███▎      | 33/100 [00:01<00:02, 29.44it/s] 37%|███▋      | 37/100 [00:01<00:02, 31.12it/s] 41%|████      | 41/100 [00:01<00:01, 32.02it/s] 45%|████▌     | 45/100 [00:01<00:01, 31.70it/s] 49%|████▉     | 49/100 [00:01<00:01, 32.29it/s] 53%|█████▎    | 53/100 [00:01<00:01, 31.32it/s] 57%|█████▋    | 57/100 [00:02<00:01, 29.91it/s] 61%|██████    | 61/100 [00:02<00:01, 26.10it/s] 64%|██████▍   | 64/100 [00:02<00:01, 26.91it/s] 68%|██████▊   | 68/100 [00:02<00:01, 28.08it/s] 71%|███████   | 71/100 [00:02<00:01, 27.61it/s] 74%|███████▍  | 74/100 [00:02<00:00, 27.97it/s] 78%|███████▊  | 78/100 [00:02<00:00, 28.46it/s] 81%|████████  | 81/100 [00:03<00:00, 28.32it/s] 85%|████████▌ | 85/100 [00:03<00:00, 29.73it/s] 89%|████████▉ | 89/100 [00:03<00:00, 30.48it/s] 93%|█████████▎| 93/100 [00:03<00:00, 30.97it/s] 97%|█████████▋| 97/100 [00:03<00:00, 31.38it/s]100%|██████████| 100/100 [00:03<00:00, 27.60it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0302, 0.0252
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0141, 0.0164
--- total mse / var(X): 0.0208
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  7.83it/s]  2%|▏         | 2/100 [00:00<00:13,  7.34it/s]  4%|▍         | 4/100 [00:00<00:09, 10.50it/s]  6%|▌         | 6/100 [00:00<00:07, 12.99it/s]  9%|▉         | 9/100 [00:00<00:05, 16.74it/s] 13%|█▎        | 13/100 [00:00<00:04, 21.36it/s] 16%|█▌        | 16/100 [00:00<00:03, 22.75it/s] 20%|██        | 20/100 [00:01<00:02, 26.88it/s] 25%|██▌       | 25/100 [00:01<00:02, 31.41it/s] 30%|███       | 30/100 [00:01<00:02, 34.27it/s] 35%|███▌      | 35/100 [00:01<00:01, 37.69it/s] 40%|████      | 40/100 [00:01<00:01, 39.81it/s] 45%|████▌     | 45/100 [00:01<00:01, 41.37it/s] 50%|█████     | 50/100 [00:01<00:01, 41.56it/s] 55%|█████▌    | 55/100 [00:01<00:01, 41.73it/s] 60%|██████    | 60/100 [00:01<00:00, 42.54it/s] 65%|██████▌   | 65/100 [00:02<00:00, 41.87it/s] 70%|███████   | 70/100 [00:02<00:00, 39.80it/s] 75%|███████▌  | 75/100 [00:02<00:00, 39.46it/s] 79%|███████▉  | 79/100 [00:02<00:00, 37.58it/s] 83%|████████▎ | 83/100 [00:02<00:00, 37.54it/s] 87%|████████▋ | 87/100 [00:02<00:00, 36.71it/s] 92%|█████████▏| 92/100 [00:02<00:00, 37.70it/s] 96%|█████████▌| 96/100 [00:02<00:00, 37.31it/s]100%|██████████| 100/100 [00:03<00:00, 37.84it/s]100%|██████████| 100/100 [00:03<00:00, 33.19it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00447, 0.0051
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00817, 0.00702
--- total mse / var(X): 0.00606
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.60it/s]  3%|▎         | 3/100 [00:00<00:07, 12.90it/s]  5%|▌         | 5/100 [00:00<00:06, 13.61it/s]  8%|▊         | 8/100 [00:00<00:05, 16.40it/s] 11%|█         | 11/100 [00:00<00:05, 17.75it/s] 14%|█▍        | 14/100 [00:00<00:04, 20.89it/s] 18%|█▊        | 18/100 [00:00<00:03, 25.47it/s] 22%|██▏       | 22/100 [00:00<00:02, 29.42it/s] 26%|██▌       | 26/100 [00:01<00:02, 31.82it/s] 30%|███       | 30/100 [00:01<00:02, 32.17it/s] 34%|███▍      | 34/100 [00:01<00:02, 26.65it/s] 37%|███▋      | 37/100 [00:01<00:02, 26.88it/s] 41%|████      | 41/100 [00:01<00:02, 29.23it/s] 45%|████▌     | 45/100 [00:01<00:01, 30.86it/s] 49%|████▉     | 49/100 [00:01<00:01, 31.15it/s] 53%|█████▎    | 53/100 [00:01<00:01, 33.09it/s] 58%|█████▊    | 58/100 [00:02<00:01, 36.82it/s] 62%|██████▏   | 62/100 [00:02<00:01, 36.00it/s] 66%|██████▌   | 66/100 [00:02<00:00, 34.85it/s] 70%|███████   | 70/100 [00:02<00:00, 35.64it/s] 74%|███████▍  | 74/100 [00:02<00:00, 35.49it/s] 78%|███████▊  | 78/100 [00:02<00:00, 36.57it/s] 83%|████████▎ | 83/100 [00:02<00:00, 37.97it/s] 87%|████████▋ | 87/100 [00:02<00:00, 36.34it/s] 92%|█████████▏| 92/100 [00:03<00:00, 37.71it/s] 96%|█████████▌| 96/100 [00:03<00:00, 36.11it/s]100%|██████████| 100/100 [00:03<00:00, 35.94it/s]100%|██████████| 100/100 [00:03<00:00, 30.56it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.018, 0.0165
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0172, 0.0187
--- total mse / var(X): 0.0176
start table evaluation...
Elapsed time: 305.2107470035553 seconds
4
(44138, 256)
Cosine similarity between AMM and exact (Train): 0.8819068
Cosine similarity between AMM and exact (Test): 0.86983454
p,r,f1: 0.905294645388917 0.9424474636146969 0.9234975359530355
p,r,f1: 0.7614959967157244 0.8033807179065294 0.7818778243781366
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.905294645388917, 0.9424474636146969, 0.9234975359530355],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.995673656463623,
                                      0.9865816235542297,
                                      0.9775331616401672,
                                      0.8819068074226379],
               'cossim_layer_test': [0.989564061164856,
                                     0.9850167632102966,
                                     0.9759901762008667,
                                     0.8698346614837646],
               'cossim_amm_train': [0.9925349354743958,
                                    0.9972943067550659,
                                    0.9878403544425964,
                                    0.9578825831413269,
                                    0.9841138124465942,
                                    0.9581055641174316,
                                    0.9626854658126831,
                                    0.9420220851898193],
               'cossim_amm_test': [0.9823887944221497,
                                   0.9967252016067505,
                                   0.9876332879066467,
                                   0.9548302292823792,
                                   0.9826416969299316,
                                   0.9533702731132507,
                                   0.9613185524940491,
                                   0.9398837685585022],
               'f1': [0.7614959967157244,
                      0.8033807179065294,
                      0.7818778243781366],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}

Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00539, 0.00458
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00428, 0.00493
--- total mse / var(X): 0.00475
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00225, 0.00214
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00206, 0.00216
--- total mse / var(X): 0.00215
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00391, 0.00388
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00452, 0.00455
--- total mse / var(X): 0.00422
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00277, 0.00219
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00404, 0.0049
--- total mse / var(X): 0.00354
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00798, 0.00634
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00967, 0.0117
--- total mse / var(X): 0.009
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:23,  4.16it/s]  2%|▏         | 2/100 [00:00<00:20,  4.78it/s]  3%|▎         | 3/100 [00:00<00:19,  4.98it/s]  4%|▍         | 4/100 [00:00<00:16,  5.83it/s]  5%|▌         | 5/100 [00:00<00:16,  5.88it/s]  6%|▌         | 6/100 [00:01<00:14,  6.55it/s]  7%|▋         | 7/100 [00:01<00:12,  7.29it/s]  9%|▉         | 9/100 [00:01<00:10,  8.52it/s] 11%|█         | 11/100 [00:01<00:09,  9.50it/s] 12%|█▏        | 12/100 [00:01<00:09,  9.39it/s] 13%|█▎        | 13/100 [00:01<00:09,  9.51it/s] 15%|█▌        | 15/100 [00:01<00:07, 10.83it/s] 17%|█▋        | 17/100 [00:01<00:06, 12.25it/s] 19%|█▉        | 19/100 [00:02<00:06, 13.40it/s] 21%|██        | 21/100 [00:02<00:05, 14.16it/s] 23%|██▎       | 23/100 [00:02<00:05, 14.87it/s] 25%|██▌       | 25/100 [00:02<00:04, 15.33it/s] 27%|██▋       | 27/100 [00:02<00:04, 15.72it/s] 29%|██▉       | 29/100 [00:02<00:04, 15.94it/s] 31%|███       | 31/100 [00:02<00:04, 15.81it/s] 33%|███▎      | 33/100 [00:02<00:04, 15.49it/s] 35%|███▌      | 35/100 [00:03<00:03, 16.38it/s] 37%|███▋      | 37/100 [00:03<00:03, 16.56it/s] 39%|███▉      | 39/100 [00:03<00:03, 16.08it/s] 41%|████      | 41/100 [00:03<00:04, 12.83it/s] 43%|████▎     | 43/100 [00:03<00:05, 10.10it/s] 45%|████▌     | 45/100 [00:04<00:05,  9.57it/s] 47%|████▋     | 47/100 [00:04<00:05,  9.89it/s] 49%|████▉     | 49/100 [00:04<00:05, 10.00it/s] 51%|█████     | 51/100 [00:04<00:04, 10.15it/s] 53%|█████▎    | 53/100 [00:04<00:04, 10.29it/s] 55%|█████▌    | 55/100 [00:05<00:04, 10.71it/s] 57%|█████▋    | 57/100 [00:05<00:03, 11.37it/s] 59%|█████▉    | 59/100 [00:05<00:03, 12.56it/s] 61%|██████    | 61/100 [00:05<00:03, 12.72it/s] 63%|██████▎   | 63/100 [00:05<00:02, 14.06it/s] 65%|██████▌   | 65/100 [00:05<00:02, 15.25it/s] 68%|██████▊   | 68/100 [00:05<00:01, 17.03it/s] 70%|███████   | 70/100 [00:05<00:01, 17.45it/s] 72%|███████▏  | 72/100 [00:06<00:01, 17.96it/s] 75%|███████▌  | 75/100 [00:06<00:01, 18.69it/s] 77%|███████▋  | 77/100 [00:06<00:01, 18.83it/s] 79%|███████▉  | 79/100 [00:06<00:01, 18.87it/s] 81%|████████  | 81/100 [00:06<00:01, 18.64it/s] 84%|████████▍ | 84/100 [00:06<00:00, 19.20it/s] 86%|████████▌ | 86/100 [00:06<00:00, 17.69it/s] 88%|████████▊ | 88/100 [00:06<00:00, 15.39it/s] 90%|█████████ | 90/100 [00:07<00:00, 14.97it/s] 92%|█████████▏| 92/100 [00:07<00:00, 15.94it/s] 94%|█████████▍| 94/100 [00:07<00:00, 15.81it/s] 96%|█████████▌| 96/100 [00:07<00:00, 16.37it/s] 98%|█████████▊| 98/100 [00:07<00:00, 16.48it/s]100%|██████████| 100/100 [00:07<00:00, 17.22it/s]100%|██████████| 100/100 [00:07<00:00, 13.04it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0242, 0.0167
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.018, 0.0236
--- total mse / var(X): 0.0201
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:10,  9.44it/s]  3%|▎         | 3/100 [00:00<00:06, 14.91it/s]  5%|▌         | 5/100 [00:00<00:06, 14.58it/s]  7%|▋         | 7/100 [00:00<00:05, 15.69it/s] 10%|█         | 10/100 [00:00<00:04, 18.58it/s] 12%|█▏        | 12/100 [00:00<00:04, 18.36it/s] 14%|█▍        | 14/100 [00:00<00:05, 15.39it/s] 17%|█▋        | 17/100 [00:01<00:04, 18.07it/s] 20%|██        | 20/100 [00:01<00:04, 19.93it/s] 23%|██▎       | 23/100 [00:01<00:03, 21.07it/s] 26%|██▌       | 26/100 [00:01<00:03, 20.39it/s] 29%|██▉       | 29/100 [00:02<00:07,  9.42it/s] 31%|███       | 31/100 [00:02<00:08,  7.85it/s] 33%|███▎      | 33/100 [00:02<00:08,  7.85it/s] 35%|███▌      | 35/100 [00:03<00:08,  7.70it/s] 36%|███▌      | 36/100 [00:03<00:08,  7.91it/s] 37%|███▋      | 37/100 [00:03<00:07,  8.04it/s] 39%|███▉      | 39/100 [00:03<00:06,  8.78it/s] 41%|████      | 41/100 [00:03<00:05,  9.85it/s] 43%|████▎     | 43/100 [00:03<00:05, 10.92it/s] 45%|████▌     | 45/100 [00:03<00:04, 12.72it/s] 48%|████▊     | 48/100 [00:03<00:03, 15.89it/s] 51%|█████     | 51/100 [00:04<00:02, 18.74it/s] 54%|█████▍    | 54/100 [00:04<00:02, 19.96it/s] 58%|█████▊    | 58/100 [00:04<00:01, 23.21it/s] 61%|██████    | 61/100 [00:04<00:01, 23.21it/s] 64%|██████▍   | 64/100 [00:04<00:01, 24.06it/s] 67%|██████▋   | 67/100 [00:04<00:01, 22.54it/s] 70%|███████   | 70/100 [00:04<00:01, 21.88it/s] 73%|███████▎  | 73/100 [00:04<00:01, 22.04it/s] 76%|███████▌  | 76/100 [00:05<00:01, 21.88it/s] 80%|████████  | 80/100 [00:05<00:00, 24.31it/s] 83%|████████▎ | 83/100 [00:05<00:00, 24.68it/s] 86%|████████▌ | 86/100 [00:05<00:00, 25.18it/s] 89%|████████▉ | 89/100 [00:05<00:00, 20.28it/s] 92%|█████████▏| 92/100 [00:06<00:00, 11.95it/s] 94%|█████████▍| 94/100 [00:06<00:00, 12.01it/s] 96%|█████████▌| 96/100 [00:06<00:00, 10.97it/s] 98%|█████████▊| 98/100 [00:06<00:00,  9.39it/s]post_processing, opt_threshold<0.9
filtering
             app       mean   max  min  median
0  410.bwaves-s0  15.250079  16.0  1.0    16.0
Done: results saved at: res/410.bwaves-s0.vit.pkl.k.128.c.2.fine.degree_stats.csv
100%|██████████| 100/100 [00:07<00:00,  9.04it/s]100%|██████████| 100/100 [00:07<00:00, 13.97it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00949, 0.00913
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00998, 0.0104
--- total mse / var(X): 0.00975
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:19,  4.99it/s]  3%|▎         | 3/100 [00:00<00:12,  8.01it/s]  5%|▌         | 5/100 [00:00<00:09, 10.55it/s]  8%|▊         | 8/100 [00:00<00:06, 14.97it/s] 10%|█         | 10/100 [00:00<00:06, 14.00it/s] 13%|█▎        | 13/100 [00:00<00:05, 17.24it/s] 16%|█▌        | 16/100 [00:01<00:04, 18.67it/s] 18%|█▊        | 18/100 [00:01<00:04, 18.62it/s] 20%|██        | 20/100 [00:01<00:04, 18.97it/s] 23%|██▎       | 23/100 [00:01<00:03, 21.34it/s] 26%|██▌       | 26/100 [00:01<00:03, 23.20it/s] 30%|███       | 30/100 [00:01<00:02, 25.79it/s] 35%|███▌      | 35/100 [00:01<00:02, 30.61it/s] 39%|███▉      | 39/100 [00:01<00:01, 31.13it/s] 43%|████▎     | 43/100 [00:01<00:01, 32.04it/s] 47%|████▋     | 47/100 [00:02<00:01, 30.25it/s] 52%|█████▏    | 52/100 [00:02<00:01, 33.41it/s] 57%|█████▋    | 57/100 [00:02<00:01, 36.41it/s] 61%|██████    | 61/100 [00:02<00:01, 35.69it/s] 66%|██████▌   | 66/100 [00:02<00:00, 37.68it/s] 71%|███████   | 71/100 [00:02<00:00, 39.80it/s] 76%|███████▌  | 76/100 [00:02<00:00, 35.95it/s] 80%|████████  | 80/100 [00:03<00:00, 32.55it/s] 84%|████████▍ | 84/100 [00:03<00:00, 24.08it/s] 87%|████████▋ | 87/100 [00:03<00:00, 25.09it/s] 91%|█████████ | 91/100 [00:03<00:00, 27.36it/s] 95%|█████████▌| 95/100 [00:03<00:00, 27.03it/s] 99%|█████████▉| 99/100 [00:03<00:00, 29.18it/s]100%|██████████| 100/100 [00:03<00:00, 26.10it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00321, 0.00329
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00347, 0.00338
--- total mse / var(X): 0.00334
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:01,  1.60it/s]  2%|▏         | 2/100 [00:01<00:54,  1.80it/s]  3%|▎         | 3/100 [00:01<00:47,  2.02it/s]  4%|▍         | 4/100 [00:02<00:46,  2.09it/s]  5%|▌         | 5/100 [00:02<00:48,  1.96it/s]  6%|▌         | 6/100 [00:02<00:42,  2.22it/s]  7%|▋         | 7/100 [00:03<00:39,  2.38it/s]  8%|▊         | 8/100 [00:03<00:35,  2.61it/s]  9%|▉         | 9/100 [00:03<00:32,  2.80it/s] 10%|█         | 10/100 [00:04<00:30,  2.93it/s] 11%|█         | 11/100 [00:04<00:29,  3.01it/s] 12%|█▏        | 12/100 [00:04<00:29,  2.99it/s] 13%|█▎        | 13/100 [00:05<00:28,  3.05it/s] 14%|█▍        | 14/100 [00:05<00:28,  3.06it/s] 15%|█▌        | 15/100 [00:05<00:27,  3.06it/s] 16%|█▌        | 16/100 [00:06<00:27,  3.06it/s] 17%|█▋        | 17/100 [00:06<00:27,  3.05it/s] 18%|█▊        | 18/100 [00:06<00:25,  3.22it/s] 19%|█▉        | 19/100 [00:06<00:24,  3.35it/s] 20%|██        | 20/100 [00:07<00:24,  3.27it/s] 21%|██        | 21/100 [00:07<00:25,  3.16it/s] 22%|██▏       | 22/100 [00:07<00:24,  3.13it/s] 23%|██▎       | 23/100 [00:08<00:25,  3.08it/s] 24%|██▍       | 24/100 [00:08<00:23,  3.19it/s] 25%|██▌       | 25/100 [00:08<00:24,  3.09it/s] 26%|██▌       | 26/100 [00:09<00:23,  3.09it/s] 27%|██▋       | 27/100 [00:09<00:23,  3.14it/s] 28%|██▊       | 28/100 [00:09<00:22,  3.22it/s] 29%|██▉       | 29/100 [00:10<00:22,  3.15it/s] 30%|███       | 30/100 [00:10<00:21,  3.26it/s] 31%|███       | 31/100 [00:10<00:20,  3.31it/s] 32%|███▏      | 32/100 [00:11<00:20,  3.24it/s] 33%|███▎      | 33/100 [00:11<00:20,  3.19it/s] 34%|███▍      | 34/100 [00:11<00:20,  3.14it/s] 35%|███▌      | 35/100 [00:12<00:20,  3.23it/s] 36%|███▌      | 36/100 [00:12<00:19,  3.24it/s] 37%|███▋      | 37/100 [00:12<00:19,  3.25it/s] 38%|███▊      | 38/100 [00:12<00:18,  3.34it/s] 39%|███▉      | 39/100 [00:13<00:18,  3.26it/s] 40%|████      | 40/100 [00:13<00:18,  3.24it/s] 41%|████      | 41/100 [00:13<00:17,  3.37it/s] 42%|████▏     | 42/100 [00:14<00:16,  3.45it/s] 43%|████▎     | 43/100 [00:14<00:21,  2.62it/s] 44%|████▍     | 44/100 [00:15<00:23,  2.38it/s] 45%|████▌     | 45/100 [00:15<00:22,  2.48it/s] 46%|████▌     | 46/100 [00:15<00:21,  2.48it/s] 47%|████▋     | 47/100 [00:16<00:21,  2.52it/s] 48%|████▊     | 48/100 [00:16<00:20,  2.56it/s] 49%|████▉     | 49/100 [00:17<00:19,  2.62it/s] 50%|█████     | 50/100 [00:17<00:20,  2.46it/s] 51%|█████     | 51/100 [00:17<00:18,  2.64it/s] 52%|█████▏    | 52/100 [00:18<00:17,  2.80it/s] 53%|█████▎    | 53/100 [00:18<00:16,  2.86it/s] 54%|█████▍    | 54/100 [00:18<00:15,  2.93it/s] 55%|█████▌    | 55/100 [00:19<00:15,  2.87it/s] 56%|█████▌    | 56/100 [00:19<00:14,  2.96it/s] 57%|█████▋    | 57/100 [00:19<00:14,  2.92it/s] 58%|█████▊    | 58/100 [00:21<00:24,  1.72it/s] 59%|█████▉    | 59/100 [00:21<00:20,  1.97it/s] 60%|██████    | 60/100 [00:21<00:18,  2.13it/s] 61%|██████    | 61/100 [00:22<00:16,  2.35it/s] 62%|██████▏   | 62/100 [00:22<00:17,  2.20it/s] 63%|██████▎   | 63/100 [00:22<00:14,  2.53it/s] 64%|██████▍   | 64/100 [00:23<00:12,  2.85it/s] 65%|██████▌   | 65/100 [00:23<00:11,  3.17it/s] 66%|██████▌   | 66/100 [00:23<00:10,  3.37it/s] 67%|██████▋   | 67/100 [00:23<00:09,  3.47it/s] 68%|██████▊   | 68/100 [00:24<00:09,  3.34it/s] 69%|██████▉   | 69/100 [00:24<00:09,  3.42it/s] 70%|███████   | 70/100 [00:24<00:09,  3.31it/s] 71%|███████   | 71/100 [00:25<00:08,  3.51it/s] 72%|███████▏  | 72/100 [00:25<00:07,  3.66it/s] 73%|███████▎  | 73/100 [00:25<00:08,  3.31it/s] 74%|███████▍  | 74/100 [00:25<00:07,  3.26it/s] 75%|███████▌  | 75/100 [00:26<00:07,  3.33it/s] 76%|███████▌  | 76/100 [00:26<00:07,  3.41it/s] 77%|███████▋  | 77/100 [00:26<00:06,  3.53it/s] 78%|███████▊  | 78/100 [00:27<00:06,  3.50it/s] 79%|███████▉  | 79/100 [00:27<00:05,  3.54it/s] 80%|████████  | 80/100 [00:27<00:05,  3.35it/s] 81%|████████  | 81/100 [00:28<00:06,  2.94it/s] 82%|████████▏ | 82/100 [00:28<00:06,  2.64it/s] 83%|████████▎ | 83/100 [00:28<00:06,  2.62it/s] 84%|████████▍ | 84/100 [00:29<00:05,  2.82it/s] 85%|████████▌ | 85/100 [00:29<00:05,  2.98it/s] 86%|████████▌ | 86/100 [00:29<00:04,  3.16it/s] 87%|████████▋ | 87/100 [00:30<00:04,  3.18it/s] 88%|████████▊ | 88/100 [00:30<00:03,  3.34it/s] 89%|████████▉ | 89/100 [00:30<00:03,  2.83it/s] 90%|█████████ | 90/100 [00:31<00:03,  2.68it/s] 91%|█████████ | 91/100 [00:31<00:03,  2.87it/s] 92%|█████████▏| 92/100 [00:31<00:02,  3.07it/s] 93%|█████████▎| 93/100 [00:32<00:02,  3.11it/s] 94%|█████████▍| 94/100 [00:32<00:01,  3.19it/s] 95%|█████████▌| 95/100 [00:32<00:01,  3.28it/s] 96%|█████████▌| 96/100 [00:33<00:01,  3.29it/s] 97%|█████████▋| 97/100 [00:33<00:01,  2.65it/s]