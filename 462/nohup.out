===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.0522702757 - test_loss: 0.0428904901
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.0228784036 - test_loss: 0.0422588541
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0216878604 - test_loss: 0.0814220518
Early Stop Left: 4
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0202073826 - test_loss: 0.0580171790
Early Stop Left: 3
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0198736485 - test_loss: 0.0836014380
Early Stop Left: 2
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0195528684 - test_loss: 0.0607658680
Early Stop Left: 1
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0205946013 - test_loss: 0.0784483717
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  6%|▌         | 12/205 [00:00<00:01, 111.31it/s] 12%|█▏        | 24/205 [00:00<00:01, 114.78it/s] 18%|█▊        | 36/205 [00:00<00:01, 114.70it/s] 23%|██▎       | 48/205 [00:00<00:01, 115.13it/s] 29%|██▉       | 60/205 [00:00<00:01, 115.54it/s] 35%|███▌      | 72/205 [00:00<00:01, 116.52it/s] 41%|████      | 84/205 [00:00<00:01, 116.08it/s] 47%|████▋     | 96/205 [00:00<00:00, 116.44it/s] 53%|█████▎    | 108/205 [00:00<00:00, 116.35it/s] 59%|█████▊    | 120/205 [00:01<00:00, 116.68it/s] 64%|██████▍   | 132/205 [00:01<00:00, 116.07it/s] 70%|███████   | 144/205 [00:01<00:00, 116.18it/s] 76%|███████▌  | 156/205 [00:01<00:00, 116.36it/s] 82%|████████▏ | 168/205 [00:01<00:00, 116.59it/s] 88%|████████▊ | 180/205 [00:01<00:00, 116.61it/s] 94%|█████████▎| 192/205 [00:01<00:00, 117.03it/s]100%|█████████▉| 204/205 [00:01<00:00, 115.69it/s]100%|██████████| 205/205 [00:01<00:00, 116.07it/s]
Best micro threshold=0.753600, fscore=0.992
p,r,f1: 0.9838558392431814 0.9994604543338248 0.9915967586950065
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vitt',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.7536002993583679,
                 'p': 0.9838558392431814,
                 'r': 0.9994604543338248,
                 'f1': 0.9915967586950065},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4729292184 - test_loss: 0.3501713354
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2404719189 - test_loss: 0.1871908873
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1503931886 - test_loss: 0.1173042391
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1154762516 - test_loss: 0.0859217172
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1022119832 - test_loss: 0.0711333345
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0973867158 - test_loss: 0.0640415861
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0957686713 - test_loss: 0.0607974264
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0952812956 - test_loss: 0.0593438146
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0951489228 - test_loss: 0.0588300549
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0951140603 - test_loss: 0.0587735011
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0951034141 - test_loss: 0.0586235418
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0950954091 - test_loss: 0.0584723474
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0950860384 - test_loss: 0.0587046184
Early Stop Left: 4
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0950660104 - test_loss: 0.0585155259
Early Stop Left: 3
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0950178776 - test_loss: 0.0585467938
Early Stop Left: 2
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0948962640 - test_loss: 0.0601831913
Early Stop Left: 1
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0943748426 - test_loss: 0.0636054572
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s] 10%|▉         | 20/205 [00:00<00:00, 194.67it/s] 20%|█▉        | 40/205 [00:00<00:00, 193.88it/s] 29%|██▉       | 60/205 [00:00<00:00, 194.17it/s] 39%|███▉      | 80/205 [00:00<00:00, 192.98it/s] 49%|████▉     | 100/205 [00:00<00:00, 192.30it/s] 59%|█████▊    | 120/205 [00:00<00:00, 192.47it/s] 68%|██████▊   | 140/205 [00:00<00:00, 192.68it/s] 78%|███████▊  | 160/205 [00:00<00:00, 193.14it/s] 88%|████████▊ | 180/205 [00:00<00:00, 193.61it/s] 98%|█████████▊| 200/205 [00:01<00:00, 193.84it/s]100%|██████████| 205/205 [00:01<00:00, 193.56it/s]
Best micro threshold=0.940127, fscore=0.991
p,r,f1: 0.9830463197274706 0.9999998484422286 0.9914506142300132
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9401269555091858,
                 'p': 0.9830463197274706,
                 'r': 0.9999998484422286,
                 'f1': 0.9914506142300132},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4043358771 - test_loss: 0.3549193606
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2279546416 - test_loss: 0.2003675802
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1708267642 - test_loss: 0.1379596192
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1538289798 - test_loss: 0.1129312543
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1493231298 - test_loss: 0.1033461481
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1482573356 - test_loss: 0.1000078572
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.1480269941 - test_loss: 0.0992436362
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.1479762197 - test_loss: 0.0987929375
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.1479641464 - test_loss: 0.0987262340
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.1479608500 - test_loss: 0.0989076242
Early Stop Left: 4
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.1479593144 - test_loss: 0.0988239118
Early Stop Left: 3
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.1479565091 - test_loss: 0.0984883729
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.1479532387 - test_loss: 0.0988546170
Early Stop Left: 4
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.1479482091 - test_loss: 0.0985499023
Early Stop Left: 3
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.1479395278 - test_loss: 0.0988119751
Early Stop Left: 2
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.1479304529 - test_loss: 0.0991972358
Early Stop Left: 1
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.1479155123 - test_loss: 0.0990450160
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s] 10%|▉         | 20/205 [00:00<00:00, 196.10it/s] 20%|█▉        | 40/205 [00:00<00:00, 193.88it/s] 29%|██▉       | 60/205 [00:00<00:00, 194.15it/s] 39%|███▉      | 80/205 [00:00<00:00, 194.50it/s] 49%|████▉     | 100/205 [00:00<00:00, 194.39it/s] 59%|█████▊    | 120/205 [00:00<00:00, 194.36it/s] 68%|██████▊   | 140/205 [00:00<00:00, 189.79it/s] 78%|███████▊  | 160/205 [00:00<00:00, 186.81it/s] 88%|████████▊ | 180/205 [00:00<00:00, 187.88it/s] 98%|█████████▊| 200/205 [00:01<00:00, 189.59it/s]100%|██████████| 205/205 [00:01<00:00, 191.22it/s]
Best micro threshold=0.867186, fscore=0.991
p,r,f1: 0.9830463197274706 0.9999998484422286 0.9914506142300132
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.8671858906745911,
                 'p': 0.9830463197274706,
                 'r': 0.9999998484422286,
                 'f1': 0.9914506142300132},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4957471977 - test_loss: 0.3490610930
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2440331641 - test_loss: 0.1841566574
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1414788920 - test_loss: 0.1128525191
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0984433257 - test_loss: 0.0804517751
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0800023830 - test_loss: 0.0648199494
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0720529422 - test_loss: 0.0569026238
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0687148600 - test_loss: 0.0527713389
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0673936138 - test_loss: 0.0506000310
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0669164344 - test_loss: 0.0495168396
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0667624853 - test_loss: 0.0490592048
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0667155100 - test_loss: 0.0488199247
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0666955185 - test_loss: 0.0486970311
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0666795823 - test_loss: 0.0487661660
Early Stop Left: 4
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0666447478 - test_loss: 0.0486004560
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0665186128 - test_loss: 0.0485454068
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0658770998 - test_loss: 0.0559405921
Early Stop Left: 4
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0652055797 - test_loss: 0.0550956649
Early Stop Left: 3
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0650378771 - test_loss: 0.0559799337
Early Stop Left: 2
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0649257413 - test_loss: 0.0598591575
Early Stop Left: 1
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0648664159 - test_loss: 0.0542613932
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  9%|▉         | 18/205 [00:00<00:01, 173.31it/s] 18%|█▊        | 36/205 [00:00<00:00, 172.58it/s] 26%|██▋       | 54/205 [00:00<00:00, 172.49it/s] 35%|███▌      | 72/205 [00:00<00:00, 173.10it/s] 44%|████▍     | 90/205 [00:00<00:00, 172.37it/s] 53%|█████▎    | 108/205 [00:00<00:00, 173.69it/s] 61%|██████▏   | 126/205 [00:00<00:00, 172.25it/s] 70%|███████   | 144/205 [00:00<00:00, 171.93it/s] 79%|███████▉  | 162/205 [00:00<00:00, 171.59it/s] 88%|████████▊ | 180/205 [00:01<00:00, 171.97it/s] 97%|█████████▋| 198/205 [00:01<00:00, 173.65it/s]100%|██████████| 205/205 [00:01<00:00, 172.99it/s]
Best micro threshold=0.938169, fscore=0.991
p,r,f1: 0.9830605066829604 0.9999898456293164 0.9914529131102641
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9381691217422485,
                 'p': 0.9830605066829604,
                 'r': 0.9999898456293164,
                 'f1': 0.9914529131102641},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/206 [00:00<?, ?it/s]  0%|          | 1/206 [00:01<05:25,  1.59s/it] 11%|█         | 23/206 [00:01<00:09, 18.74it/s] 22%|██▏       | 46/206 [00:01<00:03, 41.01it/s] 34%|███▍      | 70/206 [00:01<00:02, 66.81it/s] 46%|████▌     | 94/206 [00:01<00:01, 93.50it/s] 57%|█████▋    | 118/206 [00:02<00:00, 119.95it/s] 69%|██████▉   | 142/206 [00:02<00:00, 144.07it/s] 80%|████████  | 165/206 [00:02<00:00, 162.87it/s] 91%|█████████▏| 188/206 [00:02<00:00, 177.04it/s]100%|██████████| 206/206 [00:02<00:00, 82.89it/s] 
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
                 app  mean  max  min  median
0  462.libquantum-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/462.libquantum-s0.vit.stu.95.0.pkl.degree_stats.csv
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/206 [00:00<?, ?it/s]  0%|          | 1/206 [00:01<06:10,  1.81s/it]  5%|▍         | 10/206 [00:01<00:27,  7.06it/s]  9%|▉         | 19/206 [00:02<00:12, 14.75it/s] 14%|█▎        | 28/206 [00:02<00:07, 23.39it/s] 18%|█▊        | 37/206 [00:02<00:05, 32.56it/s] 22%|██▏       | 46/206 [00:02<00:03, 41.69it/s] 27%|██▋       | 55/206 [00:02<00:03, 50.17it/s] 31%|███       | 64/206 [00:02<00:02, 57.69it/s] 35%|███▌      | 73/206 [00:02<00:02, 63.62it/s] 40%|███▉      | 82/206 [00:02<00:01, 69.06it/s] 44%|████▍     | 91/206 [00:02<00:01, 72.83it/s] 49%|████▊     | 100/206 [00:02<00:01, 75.75it/s] 53%|█████▎    | 109/206 [00:03<00:01, 77.52it/s] 57%|█████▋    | 118/206 [00:03<00:01, 79.76it/s] 62%|██████▏   | 127/206 [00:03<00:00, 80.88it/s] 66%|██████▌   | 136/206 [00:03<00:00, 81.57it/s] 70%|███████   | 145/206 [00:03<00:00, 82.22it/s] 75%|███████▍  | 154/206 [00:03<00:00, 82.53it/s] 79%|███████▉  | 163/206 [00:03<00:00, 82.76it/s] 83%|████████▎ | 172/206 [00:03<00:00, 82.60it/s] 88%|████████▊ | 181/206 [00:03<00:00, 80.51it/s] 92%|█████████▏| 190/206 [00:04<00:00, 80.87it/s] 97%|█████████▋| 199/206 [00:04<00:00, 81.05it/s]100%|██████████| 206/206 [00:04<00:00, 48.15it/s]
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
                 app  mean  max  min  median
0  462.libquantum-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/462.libquantum-s0.vitt.pkl.degree_stats.csv
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_vit.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_vit.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_vit.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_vit.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_vit.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_vit.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_vit.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_vit.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Traceback (most recent call last):
  File "src/3_vit.py", line 110, in <module>
    train_data, train_target, test_data, test_target, all_params, best_threshold = load_data_n_model(model_save_path, res_path)
  File "src/3_vit.py", line 55, in load_data_n_model
    with open(model_save_path+'.tensor_dict.pkl', 'rb') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'model/433.milc-s0.vit.stu.90.0.pkl.tensor_dict.pkl'
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (2) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999997
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.218, 0.305
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00366, 0.00221
--- total mse / var(X): 0.153
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0974, 0.1
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0168, 0.0163
--- total mse / var(X): 0.0582
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.255, 0.261
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.137, 0.134
--- total mse / var(X): 0.197
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.175, 0.166
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.226, 0.237
--- total mse / var(X): 0.202
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00343, 0.00512
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0326, 0.0166
--- total mse / var(X): 0.0108
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.215, 0.218
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.259, 0.256
--- total mse / var(X): 0.237
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00381, 0.00148
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 3.5e-07, 5.63e-07
--- total mse / var(X): 0.000741
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0136, 0.0134
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0767, 0.0782
--- total mse / var(X): 0.0458
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00106, 0.000943
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00178, 0.00198
--- total mse / var(X): 0.00146
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.000238, 0.000152
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 3.85e-05, 5.25e-05
--- total mse / var(X): 0.000102
start table evaluation...
Elapsed time: 116.92339396476746 seconds
Cosine similarity between AMM and exact (Train): 0.99998766
Cosine similarity between AMM and exact (Test): 0.99997884
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16],
               'cossim_layer_train': [0.992205023765564,
                                      0.9882912039756775,
                                      0.9870885014533997,
                                      0.9999876618385315],
               'cossim_layer_test': [0.9821855425834656,
                                     0.985470712184906,
                                     0.9842981100082397,
                                     0.9999788403511047],
               'cossim_amm_train': [0.984262228012085,
                                    0.9779192805290222,
                                    0.9143030047416687,
                                    0.8953810334205627,
                                    0.9562426209449768,
                                    0.9715214371681213,
                                    0.9771029353141785,
                                    0.9989858269691467],
               'cossim_amm_test': [0.9662219285964966,
                                   0.9753377437591553,
                                   0.9127565026283264,
                                   0.8888059854507446,
                                   0.9485949873924255,
                                   0.9686425924301147,
                                   0.9748637080192566,
                                   0.9984761476516724],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 16),
                              (192, 2, 16),
                              (16, 16, 2),
                              (16, 16, 2),
                              (32, 2, 16),
                              (32, 2, 16),
                              (32, 2, 16),
                              (256, 2, 16)],
               'lut_total_size': 19456}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999994
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.154, 0.215
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00138, 0.000832
--- total mse / var(X): 0.108
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0106, 0.0109
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0107, 0.0104
--- total mse / var(X): 0.0106
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0632, 0.0649
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0291, 0.0283
--- total mse / var(X): 0.0466
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0352, 0.0336
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0643, 0.0673
--- total mse / var(X): 0.0504
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00227, 0.00368
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000998, 0.000381
--- total mse / var(X): 0.00203
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.106, 0.106
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.129, 0.128
--- total mse / var(X): 0.117
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00502, 0.00189
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000917, 0.00149
--- total mse / var(X): 0.00169
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0107, 0.0104
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0109, 0.0112
--- total mse / var(X): 0.0108
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00458, 0.00407
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00364, 0.00404
--- total mse / var(X): 0.00406
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 4.63e-08, 5.34e-08
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 3e-09, 2.54e-09
--- total mse / var(X): 2.8e-08
start table evaluation...
Elapsed time: 121.81079602241516 seconds
Cosine similarity between AMM and exact (Train): 0.9999927
Cosine similarity between AMM and exact (Test): 0.9999843
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32],
               'cossim_layer_train': [0.9945094585418701,
                                      0.9937084913253784,
                                      0.9929966330528259,
                                      0.9999927282333374],
               'cossim_layer_test': [0.986270010471344,
                                     0.9901130795478821,
                                     0.9893276691436768,
                                     0.9999843239784241],
               'cossim_amm_train': [0.9889515042304993,
                                    0.9953600764274597,
                                    0.9682527184486389,
                                    0.9377561211585999,
                                    0.9737586379051208,
                                    0.9887022376060486,
                                    0.9892395734786987,
                                    0.9994903206825256],
               'cossim_amm_test': [0.9739676117897034,
                                   0.9926953911781311,
                                   0.9636696577072144,
                                   0.9291589260101318,
                                   0.9600671529769897,
                                   0.9847842454910278,
                                   0.9867461919784546,
                                   0.9989479184150696],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 32),
                              (192, 2, 32),
                              (32, 32, 2),
                              (32, 32, 2),
                              (32, 2, 32),
                              (32, 2, 32),
                              (32, 2, 32),
                              (256, 2, 32)],
               'lut_total_size': 40960}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999994
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0942, 0.132
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000562, 0.000338
--- total mse / var(X): 0.066
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00795, 0.00817
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00751, 0.0073
--- total mse / var(X): 0.00774
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00377, 0.00388
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00377, 0.00366
--- total mse / var(X): 0.00377
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00416, 0.00397
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00404, 0.00422
--- total mse / var(X): 0.00409
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00052, 0.000848
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00169, 0.000623
--- total mse / var(X): 0.000736
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0261, 0.0263
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0507, 0.0505
--- total mse / var(X): 0.0384
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00175, 0.000777
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000342, 0.000532
--- total mse / var(X): 0.000654
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00789, 0.00776
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00716, 0.00728
--- total mse / var(X): 0.00752
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00298, 0.00269
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00264, 0.0029
--- total mse / var(X): 0.00279
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 2.44e-05, 2.29e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 1.27e-05, 1.34e-05
--- total mse / var(X): 1.82e-05
start table evaluation...
Elapsed time: 162.4241235256195 seconds
Cosine similarity between AMM and exact (Train): 0.9999956
Cosine similarity between AMM and exact (Test): 0.9999868
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.9966230392456055,
                                      0.9963746666908264,
                                      0.9957687854766846,
                                      0.9999955892562866],
               'cossim_layer_test': [0.9874213337898254,
                                     0.9931040406227112,
                                     0.9921165108680725,
                                     0.9999868273735046],
               'cossim_amm_train': [0.9932043552398682,
                                    0.9967849850654602,
                                    0.9920564293861389,
                                    0.972030520439148,
                                    0.9845986366271973,
                                    0.9928820133209229,
                                    0.9929162859916687,
                                    0.9996947646141052],
               'cossim_amm_test': [0.9762237668037415,
                                   0.9931179285049438,
                                   0.9849885106086731,
                                   0.9615443348884583,
                                   0.972822368144989,
                                   0.988041877746582,
                                   0.9892340302467346,
                                   0.9991039633750916],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 64),
                              (192, 2, 64),
                              (64, 64, 2),
                              (64, 64, 2),
                              (32, 2, 64),
                              (32, 2, 64),
                              (32, 2, 64),
                              (256, 2, 64)],
               'lut_total_size': 90112}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999964
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0565, 0.0788
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00026, 0.000158
--- total mse / var(X): 0.0395
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00474, 0.00487
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00494, 0.0048
--- total mse / var(X): 0.00483
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00243, 0.0025
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00302, 0.00294
--- total mse / var(X): 0.00272
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00341, 0.00325
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00299, 0.00313
--- total mse / var(X): 0.00319
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000357, 0.000582
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00151, 0.000561
--- total mse / var(X): 0.000572
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00862, 0.00866
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00716, 0.00713
--- total mse / var(X): 0.0079
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0044, 0.00202
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0021, 0.00323
--- total mse / var(X): 0.00263
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00504, 0.00493
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00494, 0.00504
--- total mse / var(X): 0.00499
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00197, 0.00177
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00274, 0.00301
--- total mse / var(X): 0.00239
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000279, 0.000263
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000347, 0.000367
--- total mse / var(X): 0.000315
start table evaluation...
Elapsed time: 182.69580793380737 seconds
Cosine similarity between AMM and exact (Train): 0.99999803
Cosine similarity between AMM and exact (Test): 0.99998677
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9979287385940552,
                                      0.9981563091278076,
                                      0.9977830648422241,
                                      0.9999980330467224],
               'cossim_layer_test': [0.9887529015541077,
                                     0.9940768480300903,
                                     0.9931349754333496,
                                     0.9999867677688599],
               'cossim_amm_train': [0.9958229064941406,
                                    0.9980148077011108,
                                    0.9952735900878906,
                                    0.9879955649375916,
                                    0.9922624826431274,
                                    0.9958024621009827,
                                    0.9956238269805908,
                                    0.9998434782028198],
               'cossim_amm_test': [0.9788340330123901,
                                   0.9938243627548218,
                                   0.9862306118011475,
                                   0.97430020570755,
                                   0.9766174554824829,
                                   0.9893588423728943,
                                   0.9899947643280029,
                                   0.9991828203201294],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999998
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0293, 0.0409
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000264, 0.000159
--- total mse / var(X): 0.0205
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00322, 0.00331
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00288, 0.0028
--- total mse / var(X): 0.00305
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0019, 0.00195
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00238, 0.00231
--- total mse / var(X): 0.00213
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00238, 0.00227
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00238, 0.00249
--- total mse / var(X): 0.00238
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000275, 0.000449
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00109, 0.000402
--- total mse / var(X): 0.000425
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00233, 0.00234
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00475, 0.00473
--- total mse / var(X): 0.00353
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00805, 0.00379
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00308, 0.00471
--- total mse / var(X): 0.00425
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00363, 0.00356
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00305, 0.00311
--- total mse / var(X): 0.00333
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00151, 0.00134
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00209, 0.00232
--- total mse / var(X): 0.00183
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000169, 0.000158
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000167, 0.000178
--- total mse / var(X): 0.000168
start table evaluation...
Elapsed time: 299.71969652175903 seconds
Cosine similarity between AMM and exact (Train): 0.9999984
Cosine similarity between AMM and exact (Test): 0.99998426
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256],
               'cossim_layer_train': [0.998917281627655,
                                      0.9990776777267456,
                                      0.9988537430763245,
                                      0.9999983906745911],
               'cossim_layer_test': [0.9898186326026917,
                                     0.9944601655006409,
                                     0.99338299036026,
                                     0.9999842643737793],
               'cossim_amm_train': [0.9978249073028564,
                                    0.9987671375274658,
                                    0.9969315528869629,
                                    0.9950451850891113,
                                    0.996173083782196,
                                    0.9975742101669312,
                                    0.9974234104156494,
                                    0.9999099969863892],
               'cossim_amm_test': [0.9808626770973206,
                                   0.9941115379333496,
                                   0.9863381385803223,
                                   0.9800880551338196,
                                   0.977501630783081,
                                   0.9897416234016418,
                                   0.9904582500457764,
                                   0.9991240501403809],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (256, 2, 256)],
               'lut_total_size': 557056}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (23). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.016, 0.0223
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000493, 0.0003
--- total mse / var(X): 0.0113
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00178, 0.00183
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00164, 0.00159
--- total mse / var(X): 0.00171
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00146, 0.0015
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00164, 0.0016
--- total mse / var(X): 0.00155
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00162, 0.00155
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0017, 0.00178
--- total mse / var(X): 0.00166
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000212, 0.000346
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000839, 0.00031
--- total mse / var(X): 0.000328
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00111, 0.00111
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0017, 0.00169
--- total mse / var(X): 0.0014
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00716, 0.00343
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00296, 0.0045
--- total mse / var(X): 0.00396
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00227, 0.00222
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00186, 0.0019
--- total mse / var(X): 0.00206
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000991, 0.000882
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00112, 0.00124
--- total mse / var(X): 0.00106
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000233, 0.00022
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000133, 0.000141
--- total mse / var(X): 0.00018
start table evaluation...
Elapsed time: 443.189909696579 seconds
Cosine similarity between AMM and exact (Train): 0.9999989
Cosine similarity between AMM and exact (Test): 0.9999867
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512],
               'cossim_layer_train': [0.9993889927864075,
                                      0.9995294213294983,
                                      0.999414324760437,
                                      0.999998927116394],
               'cossim_layer_test': [0.9907905459403992,
                                     0.9951033592224121,
                                     0.9941887259483337,
                                     0.9999867081642151],
               'cossim_amm_train': [0.9987707734107971,
                                    0.9993090033531189,
                                    0.99811190366745,
                                    0.9980310797691345,
                                    0.9980743527412415,
                                    0.9986965656280518,
                                    0.9986307621002197,
                                    0.9999459385871887],
               'cossim_amm_test': [0.9827264547348022,
                                   0.9946155548095703,
                                   0.9873685836791992,
                                   0.9825495481491089,
                                   0.9801719188690186,
                                   0.9908111691474915,
                                   0.9915878772735596,
                                   0.9992597103118896],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 512),
                              (192, 2, 512),
                              (512, 512, 2),
                              (512, 512, 2),
                              (32, 2, 512),
                              (32, 2, 512),
                              (32, 2, 512),
                              (256, 2, 512)],
               'lut_total_size': 1638400}}
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (10) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999976
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0479, 0.0479
--- total mse / var(X): 0.0479
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00522, 0.00522
--- total mse / var(X): 0.00522
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0026, 0.0026
--- total mse / var(X): 0.0026
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00262, 0.00262
--- total mse / var(X): 0.00262
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00107, 0.00107
--- total mse / var(X): 0.00107
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00576, 0.00576
--- total mse / var(X): 0.00576
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00282, 0.00282
--- total mse / var(X): 0.00282
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00545, 0.00545
--- total mse / var(X): 0.00545
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00134, 0.00134
--- total mse / var(X): 0.00134
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 7.89e-08, 7.89e-08
--- total mse / var(X): 7.89e-08
start table evaluation...
Elapsed time: 166.227281332016 seconds
Cosine similarity between AMM and exact (Train): 0.99999696
Cosine similarity between AMM and exact (Test): 0.9999882
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9974948763847351,
                                      0.9978874325752258,
                                      0.9973790645599365,
                                      0.9999969601631165],
               'cossim_layer_test': [0.9789890646934509,
                                     0.9934054017066956,
                                     0.9926619529724121,
                                     0.9999881982803345],
               'cossim_amm_train': [0.994957447052002,
                                    0.9978591799736023,
                                    0.9947716593742371,
                                    0.9887332916259766,
                                    0.9913010001182556,
                                    0.9949901700019836,
                                    0.9950631260871887,
                                    0.9998005628585815],
               'cossim_amm_test': [0.9596615433692932,
                                   0.9943045377731323,
                                   0.9880992770195007,
                                   0.9788162708282471,
                                   0.9803008437156677,
                                   0.990430474281311,
                                   0.9906574487686157,
                                   0.9992502927780151],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 128),
                              (192, 1, 128),
                              (128, 128, 1),
                              (128, 128, 1),
                              (32, 1, 128),
                              (32, 1, 128),
                              (32, 1, 128),
                              (256, 1, 128)],
               'lut_total_size': 106496}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999994
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 3.42e-09, 4.98e-09
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 2.16e-05, 3.23e-05
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000131, 5.99e-05
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000105, 0.000122
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 4.2e-05, 4.37e-05
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000141, 0.000134
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000185, 0.000267
running kmeans in subspace 8/8... X.shape:  (100000, 2)
k:  128
nnz_rows:  0
mse / {var(X_subs), var(X)}: 0, 0
--- total mse / var(X): 8.24e-05
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00238, 0.00295
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00253, 0.00224
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00413, 0.00438
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00371, 0.00343
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00301, 0.00309
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00353, 0.00333
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0033, 0.0039
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0025, 0.00184
--- total mse / var(X): 0.00315
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00281, 0.00349
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00261, 0.00285
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00321, 0.00266
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00249, 0.00235
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0025, 0.00274
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00331, 0.00358
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00341, 0.00282
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00316, 0.00281
--- total mse / var(X): 0.00291
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00338, 0.00323
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00351, 0.00289
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00416, 0.00432
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00239, 0.00239
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00266, 0.00289
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00372, 0.00455
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00321, 0.00355
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00346, 0.00265
--- total mse / var(X): 0.00331
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000556, 0.000415
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00015, 1.96e-05
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000135, 7.5e-05
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 6.83e-05, 0.00034
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00023, 2.63e-05
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00186, 0.000275
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00149, 0.000292
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000766, 0.000863
--- total mse / var(X): 0.000288
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 6.69e-08, 7.15e-08
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000164, 0.000112
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000175, 9.76e-05
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000164, 0.000168
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000161, 0.00011
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00399, 0.00481
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00331, 0.00479
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00371, 0.00494
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000001
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00769, 0.0113
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 4.47e-05, 3.64e-05
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000771, 0.00132
running kmeans in subspace 4/4... X.shape:  (100000, 3)
k:  128
nnz_rows:  0
mse / {var(X_subs), var(X)}: 0, 0
--- total mse / var(X): 0.00317
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00342, 0.00364
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00559, 0.00554
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00435, 0.00429
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00474, 0.00454
--- total mse / var(X): 0.0045
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00286, 0.00333
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00298, 0.00265
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00309, 0.00336
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00316, 0.00271
--- total mse / var(X): 0.00301
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0036, 0.0032
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0032, 0.00326
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00295, 0.00341
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00294, 0.00275
--- total mse / var(X): 0.00315
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000928, 0.000662
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000164, 0.000416
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00228, 0.000226
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00113, 0.000722
--- total mse / var(X): 0.000507
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00376, 0.00434
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00296, 0.00254
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00635, 0.0062
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00621, 0.0063
--- total mse / var(X): 0.00484
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00747, 0.00421
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0112, 0.00399
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00411, 0.00717
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0048, 0.00642
--- total mse / var(X): 0.00545
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00411, 0.00395
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00553, 0.00551
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00432, 0.00465
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00472, 0.00456
--- total mse / var(X): 0.00467
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00205, 0.00202
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00265, 0.00212
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00374, 0.00485
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00198, 0.00182
--- total mse / var(X): 0.0027
running kmeans in subspace 1/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00164, 0.00123
running kmeans in subspace 2/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00116, 0.00132
running kmeans in subspace 3/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00131, 0.00146
running kmeans in subspace 4/4... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00158, 0.00156
--- total mse / var(X): 0.00139
start table evaluation...
Elapsed time: 363.0206997394562 seconds
Cosine similarity between AMM and exact (Train): 0.9999976
Cosine similarity between AMM and exact (Test): 0.9999921
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9998411536216736,
                                      0.998906135559082,
                                      0.9985977411270142,
                                      0.999997615814209],
               'cossim_layer_test': [0.9952194094657898,
                                     0.996548056602478,
                                     0.9960870742797852,
                                     0.9999920725822449],
               'cossim_amm_train': [0.9996813535690308,
                                    0.9984287023544312,
                                    0.9962292313575745,
                                    0.9938179850578308,
                                    0.9948105812072754,
                                    0.9969119429588318,
                                    0.9967387318611145,
                                    0.9998903274536133],
               'cossim_amm_test': [0.9908984303474426,
                                   0.9957408905029297,
                                   0.9907220602035522,
                                   0.9867417216300964,
                                   0.9870854616165161,
                                   0.9932657480239868,
                                   0.993508517742157,
                                   0.9995527267456055],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 4, 128),
                              (192, 4, 128),
                              (128, 128, 4),
                              (128, 128, 4),
                              (32, 4, 128),
                              (32, 4, 128),
                              (32, 4, 128),
                              (256, 4, 128)],
               'lut_total_size': 425984}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
--- total mse / var(X): 0.00188
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.01, 0.00768
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0241, 0.00901
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0173, 0.00806
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0226, 0.00593
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00512, 0.0145
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.015, 0.00975
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0115, 0.0105
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00577, 0.01
--- total mse / var(X): 0.00943
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00376, 0.00428
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00356, 0.0028
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00447, 0.00418
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00355, 0.00375
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00255, 0.00257
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00322, 0.00366
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00468, 0.00542
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00322, 0.00249
--- total mse / var(X): 0.00364
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00293, 0.00159
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00135, 0.00191
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00259, 0.00151
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00209, 0.00213
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00306, 0.00441
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00394, 0.00453
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00337, 0.00208
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00124, 0.00151
--- total mse / var(X): 0.00246
running kmeans in subspace 1/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00449, 0.00223
running kmeans in subspace 2/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00305, 0.00263
running kmeans in subspace 3/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00161, 0.00264
running kmeans in subspace 4/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00256, 0.00189
running kmeans in subspace 5/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00176, 0.00254
running kmeans in subspace 6/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00288, 0.00208
running kmeans in subspace 7/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00138, 0.00182
running kmeans in subspace 8/8... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00294, 0.0023
--- total mse / var(X): 0.00227
start table evaluation...
Elapsed time: 366.6495668888092 seconds
Cosine similarity between AMM and exact (Train): 0.999999
Cosine similarity between AMM and exact (Test): 0.99999285
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9999958276748657,
                                      0.9993611574172974,
                                      0.9991384148597717,
                                      0.9999989867210388],
               'cossim_layer_test': [0.9995825886726379,
                                     0.998192310333252,
                                     0.9976902604103088,
                                     0.999992847442627],
               'cossim_amm_train': [0.9999909996986389,
                                    0.9989096522331238,
                                    0.9970703125,
                                    0.997157633304596,
                                    0.996925413608551,
                                    0.9978160262107849,
                                    0.9976173639297485,
                                    0.9999174475669861],
               'cossim_amm_test': [0.9992114305496216,
                                   0.9974181652069092,
                                   0.9934091567993164,
                                   0.9926947355270386,
                                   0.9915512800216675,
                                   0.9946580529212952,
                                   0.994813859462738,
                                   0.9996370077133179],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 8, 128),
                              (192, 8, 128),
                              (128, 128, 8),
                              (128, 128, 8),
                              (32, 8, 128),
                              (32, 8, 128),
                              (32, 8, 128),
                              (256, 8, 128)],
               'lut_total_size': 851968}}
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (27) found smaller than n_clusters (32). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (32). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999999
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00974, 0.0136
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 1.6e-14, 9.68e-15
--- total mse / var(X): 0.0068
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.001, 0.00103
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000888, 0.000863
--- total mse / var(X): 0.000947
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000709, 0.000728
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000918, 0.000893
--- total mse / var(X): 0.00081
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000885, 0.000844
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00096, 0.001
--- total mse / var(X): 0.000924
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000148, 0.000242
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000661, 0.000245
--- total mse / var(X): 0.000243
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000606, 0.000609
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00104, 0.00104
--- total mse / var(X): 0.000822
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.005, 0.00241
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00201, 0.00306
--- total mse / var(X): 0.00273
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00129, 0.00127
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00105, 0.00107
--- total mse / var(X): 0.00117
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000632, 0.000563
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000756, 0.000839
--- total mse / var(X): 0.000701
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 7.78e-05, 7.26e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 9.18e-05, 9.79e-05
--- total mse / var(X): 8.52e-05
start table evaluation...
Elapsed time: 846.6376821994781 seconds
Cosine similarity between AMM and exact (Train): 0.99999964
Cosine similarity between AMM and exact (Test): 0.99998873
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024],
               'cossim_layer_train': [0.9996338486671448,
                                      0.9997299909591675,
                                      0.9996625781059265,
                                      0.9999996423721313],
               'cossim_layer_test': [0.9919432997703552,
                                     0.9957534074783325,
                                     0.9950011372566223,
                                     0.9999887347221375],
               'cossim_amm_train': [0.9992644786834717,
                                    0.9996080994606018,
                                    0.9989272356033325,
                                    0.9989166855812073,
                                    0.9989038705825806,
                                    0.9992522597312927,
                                    0.999193549156189,
                                    0.9999610781669617],
               'cossim_amm_test': [0.9849198460578918,
                                   0.9953240752220154,
                                   0.9891934990882874,
                                   0.9851311445236206,
                                   0.9830894470214844,
                                   0.9924800395965576,
                                   0.9928957223892212,
                                   0.9993346333503723],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 1024),
                              (192, 2, 1024),
                              (1024, 1024, 2),
                              (1024, 1024, 2),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (256, 2, 1024)],
               'lut_total_size': 5373952}}
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 1.0000006
start table training with fine tuning...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.055, 0.0766
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000184, 0.000112
--- total mse / var(X): 0.0384
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00492, 0.00506
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0049, 0.00476
--- total mse / var(X): 0.00491
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00271, 0.00278
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00305, 0.00297
--- total mse / var(X): 0.00287
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.003, 0.00286
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00316, 0.00331
--- total mse / var(X): 0.00308
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00033, 0.000538
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00133, 0.000494
--- total mse / var(X): 0.000516
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0078, 0.00783
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0105, 0.0104
--- total mse / var(X): 0.00913
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0047, 0.00209
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0021, 0.00326
--- total mse / var(X): 0.00268
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00514, 0.00503
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00486, 0.00497
--- total mse / var(X): 0.005
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00223, 0.002
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00289, 0.00319
--- total mse / var(X): 0.0026
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000435, 0.000439
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000317, 0.000315
--- total mse / var(X): 0.000377
start table evaluation...
Elapsed time: 186.67479753494263 seconds
Cosine similarity between AMM and exact (Train): 0.99999744
Cosine similarity between AMM and exact (Test): 0.9999858
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9979738593101501,
                                      0.9981684684753418,
                                      0.9977799654006958,
                                      0.9999974370002747],
               'cossim_layer_test': [0.9881309270858765,
                                     0.9941785931587219,
                                     0.993128776550293,
                                     0.9999858140945435],
               'cossim_amm_train': [0.9959275722503662,
                                    0.9980018138885498,
                                    0.9952071905136108,
                                    0.9876750707626343,
                                    0.9923351407051086,
                                    0.9958147406578064,
                                    0.9956077337265015,
                                    0.9998376965522766],
               'cossim_amm_test': [0.9775108695030212,
                                   0.9936317205429077,
                                   0.9863919615745544,
                                   0.9747844338417053,
                                   0.9771918058395386,
                                   0.9892910718917847,
                                   0.9897773265838623,
                                   0.9991751313209534],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000001
Manual and Torch results cosine similarity (Test): 1.0000006
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0552, 0.0769
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 9.41e-05, 5.7e-05
--- total mse / var(X): 0.0385
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:19,  1.24it/s]  2%|▏         | 2/100 [00:01<01:20,  1.22it/s]  3%|▎         | 3/100 [00:02<01:25,  1.13it/s]  4%|▍         | 4/100 [00:03<01:23,  1.14it/s]  5%|▌         | 5/100 [00:04<01:22,  1.15it/s]  6%|▌         | 6/100 [00:05<01:22,  1.13it/s]  7%|▋         | 7/100 [00:06<01:29,  1.04it/s]  8%|▊         | 8/100 [00:07<01:28,  1.04it/s]  9%|▉         | 9/100 [00:08<01:26,  1.05it/s] 10%|█         | 10/100 [00:09<01:23,  1.08it/s] 11%|█         | 11/100 [00:09<01:18,  1.14it/s] 12%|█▏        | 12/100 [00:10<01:13,  1.20it/s] 13%|█▎        | 13/100 [00:11<01:14,  1.17it/s] 14%|█▍        | 14/100 [00:12<01:12,  1.18it/s] 15%|█▌        | 15/100 [00:13<01:14,  1.15it/s] 16%|█▌        | 16/100 [00:14<01:11,  1.18it/s] 17%|█▋        | 17/100 [00:14<01:07,  1.23it/s] 18%|█▊        | 18/100 [00:15<01:04,  1.26it/s] 19%|█▉        | 19/100 [00:16<01:10,  1.15it/s] 20%|██        | 20/100 [00:17<01:09,  1.14it/s] 21%|██        | 21/100 [00:18<01:18,  1.01it/s] 22%|██▏       | 22/100 [00:19<01:18,  1.01s/it] 23%|██▎       | 23/100 [00:20<01:12,  1.07it/s] 24%|██▍       | 24/100 [00:21<01:09,  1.09it/s] 25%|██▌       | 25/100 [00:22<01:07,  1.11it/s] 26%|██▌       | 26/100 [00:23<01:09,  1.06it/s] 27%|██▋       | 27/100 [00:24<01:05,  1.11it/s] 28%|██▊       | 28/100 [00:24<01:02,  1.16it/s] 29%|██▉       | 29/100 [00:25<01:01,  1.16it/s] 30%|███       | 30/100 [00:26<00:58,  1.20it/s] 31%|███       | 31/100 [00:27<00:57,  1.20it/s] 32%|███▏      | 32/100 [00:28<00:57,  1.18it/s] 33%|███▎      | 33/100 [00:29<00:57,  1.16it/s] 34%|███▍      | 34/100 [00:30<00:57,  1.15it/s] 35%|███▌      | 35/100 [00:30<00:55,  1.17it/s] 36%|███▌      | 36/100 [00:31<00:55,  1.16it/s] 37%|███▋      | 37/100 [00:32<00:53,  1.18it/s] 38%|███▊      | 38/100 [00:33<00:51,  1.20it/s] 39%|███▉      | 39/100 [00:34<00:50,  1.22it/s] 40%|████      | 40/100 [00:34<00:49,  1.22it/s] 41%|████      | 41/100 [00:35<00:51,  1.14it/s] 42%|████▏     | 42/100 [00:36<00:52,  1.11it/s] 43%|████▎     | 43/100 [00:37<00:51,  1.11it/s] 44%|████▍     | 44/100 [00:38<00:47,  1.17it/s] 45%|████▌     | 45/100 [00:39<00:47,  1.17it/s] 46%|████▌     | 46/100 [00:40<00:45,  1.18it/s] 47%|████▋     | 47/100 [00:40<00:42,  1.26it/s] 48%|████▊     | 48/100 [00:41<00:41,  1.27it/s] 49%|████▉     | 49/100 [00:42<00:38,  1.32it/s] 50%|█████     | 50/100 [00:43<00:36,  1.37it/s] 51%|█████     | 51/100 [00:43<00:35,  1.37it/s] 52%|█████▏    | 52/100 [00:44<00:34,  1.40it/s] 53%|█████▎    | 53/100 [00:45<00:33,  1.40it/s] 54%|█████▍    | 54/100 [00:46<00:35,  1.30it/s] 55%|█████▌    | 55/100 [00:46<00:33,  1.36it/s] 56%|█████▌    | 56/100 [00:47<00:32,  1.35it/s] 57%|█████▋    | 57/100 [00:48<00:31,  1.37it/s] 58%|█████▊    | 58/100 [00:49<00:32,  1.27it/s] 59%|█████▉    | 59/100 [00:50<00:34,  1.19it/s] 60%|██████    | 60/100 [00:50<00:33,  1.19it/s] 61%|██████    | 61/100 [00:51<00:33,  1.17it/s] 62%|██████▏   | 62/100 [00:52<00:32,  1.17it/s] 63%|██████▎   | 63/100 [00:53<00:32,  1.14it/s] 64%|██████▍   | 64/100 [00:54<00:32,  1.11it/s] 65%|██████▌   | 65/100 [00:55<00:32,  1.09it/s] 66%|██████▌   | 66/100 [00:56<00:30,  1.10it/s] 67%|██████▋   | 67/100 [00:57<00:29,  1.10it/s] 68%|██████▊   | 68/100 [00:58<00:29,  1.07it/s] 69%|██████▉   | 69/100 [00:59<00:28,  1.08it/s] 70%|███████   | 70/100 [00:59<00:26,  1.13it/s] 71%|███████   | 71/100 [01:00<00:25,  1.14it/s] 72%|███████▏  | 72/100 [01:01<00:23,  1.18it/s] 73%|███████▎  | 73/100 [01:02<00:22,  1.19it/s] 74%|███████▍  | 74/100 [01:03<00:22,  1.17it/s] 75%|███████▌  | 75/100 [01:04<00:21,  1.17it/s] 76%|███████▌  | 76/100 [01:04<00:20,  1.19it/s] 77%|███████▋  | 77/100 [01:05<00:19,  1.19it/s] 78%|███████▊  | 78/100 [01:06<00:18,  1.22it/s] 79%|███████▉  | 79/100 [01:07<00:17,  1.20it/s] 80%|████████  | 80/100 [01:08<00:16,  1.19it/s] 81%|████████  | 81/100 [01:09<00:16,  1.17it/s] 82%|████████▏ | 82/100 [01:10<00:15,  1.18it/s] 83%|████████▎ | 83/100 [01:10<00:13,  1.22it/s] 84%|████████▍ | 84/100 [01:11<00:14,  1.14it/s] 85%|████████▌ | 85/100 [01:12<00:13,  1.14it/s] 86%|████████▌ | 86/100 [01:13<00:11,  1.17it/s] 87%|████████▋ | 87/100 [01:14<00:11,  1.17it/s] 88%|████████▊ | 88/100 [01:15<00:09,  1.24it/s] 89%|████████▉ | 89/100 [01:15<00:08,  1.26it/s] 90%|█████████ | 90/100 [01:16<00:08,  1.25it/s] 91%|█████████ | 91/100 [01:17<00:07,  1.22it/s] 92%|█████████▏| 92/100 [01:18<00:06,  1.24it/s] 93%|█████████▎| 93/100 [01:18<00:05,  1.28it/s] 94%|█████████▍| 94/100 [01:19<00:04,  1.28it/s] 95%|█████████▌| 95/100 [01:20<00:04,  1.24it/s] 96%|█████████▌| 96/100 [01:21<00:03,  1.22it/s] 97%|█████████▋| 97/100 [01:22<00:02,  1.21it/s] 98%|█████████▊| 98/100 [01:23<00:01,  1.25it/s] 99%|█████████▉| 99/100 [01:23<00:00,  1.27it/s]100%|██████████| 100/100 [01:24<00:00,  1.25it/s]100%|██████████| 100/100 [01:24<00:00,  1.18it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00484, 0.00497
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00497, 0.00483
--- total mse / var(X): 0.0049
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00292, 0.003
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00316, 0.00307
--- total mse / var(X): 0.00304
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00301, 0.00287
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00308, 0.00322
--- total mse / var(X): 0.00305
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000355, 0.000579
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00137, 0.000505
--- total mse / var(X): 0.000542
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00481, 0.00483
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00709, 0.00706
--- total mse / var(X): 0.00595
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:08, 12.12it/s]  4%|▍         | 4/100 [00:00<00:07, 12.98it/s]  6%|▌         | 6/100 [00:00<00:07, 12.06it/s]  8%|▊         | 8/100 [00:00<00:07, 12.57it/s] 10%|█         | 10/100 [00:00<00:06, 13.13it/s] 12%|█▏        | 12/100 [00:00<00:06, 12.66it/s] 14%|█▍        | 14/100 [00:01<00:06, 12.61it/s] 16%|█▌        | 16/100 [00:01<00:06, 13.16it/s] 18%|█▊        | 18/100 [00:01<00:05, 13.69it/s] 20%|██        | 20/100 [00:01<00:06, 12.87it/s] 22%|██▏       | 22/100 [00:01<00:06, 12.33it/s] 24%|██▍       | 24/100 [00:01<00:06, 12.06it/s] 26%|██▌       | 26/100 [00:02<00:06, 11.66it/s] 28%|██▊       | 28/100 [00:02<00:05, 12.62it/s] 30%|███       | 30/100 [00:02<00:05, 13.16it/s] 32%|███▏      | 32/100 [00:02<00:05, 13.53it/s] 34%|███▍      | 34/100 [00:02<00:04, 14.96it/s] 37%|███▋      | 37/100 [00:02<00:03, 17.16it/s] 39%|███▉      | 39/100 [00:02<00:03, 17.41it/s] 41%|████      | 41/100 [00:02<00:03, 16.63it/s] 43%|████▎     | 43/100 [00:03<00:03, 17.04it/s] 46%|████▌     | 46/100 [00:03<00:03, 17.54it/s] 48%|████▊     | 48/100 [00:03<00:03, 14.23it/s] 50%|█████     | 50/100 [00:03<00:04, 11.59it/s] 52%|█████▏    | 52/100 [00:03<00:03, 13.07it/s] 54%|█████▍    | 54/100 [00:03<00:03, 14.10it/s] 56%|█████▌    | 56/100 [00:04<00:03, 14.47it/s] 58%|█████▊    | 58/100 [00:04<00:02, 15.00it/s] 60%|██████    | 60/100 [00:04<00:02, 15.17it/s] 62%|██████▏   | 62/100 [00:04<00:02, 15.52it/s] 64%|██████▍   | 64/100 [00:04<00:02, 14.54it/s] 66%|██████▌   | 66/100 [00:04<00:02, 15.27it/s] 68%|██████▊   | 68/100 [00:04<00:02, 15.96it/s] 70%|███████   | 70/100 [00:05<00:02, 13.29it/s] 72%|███████▏  | 72/100 [00:05<00:02, 10.95it/s] 74%|███████▍  | 74/100 [00:05<00:02, 12.07it/s] 76%|███████▌  | 76/100 [00:05<00:01, 12.81it/s] 78%|███████▊  | 78/100 [00:05<00:01, 13.18it/s] 80%|████████  | 80/100 [00:05<00:01, 14.23it/s] 82%|████████▏ | 82/100 [00:05<00:01, 14.77it/s] 84%|████████▍ | 84/100 [00:06<00:01, 15.05it/s] 86%|████████▌ | 86/100 [00:06<00:00, 15.10it/s] 88%|████████▊ | 88/100 [00:06<00:00, 14.63it/s] 90%|█████████ | 90/100 [00:06<00:00, 12.00it/s] 92%|█████████▏| 92/100 [00:06<00:00, 12.48it/s] 94%|█████████▍| 94/100 [00:06<00:00, 13.19it/s] 96%|█████████▌| 96/100 [00:07<00:00, 12.67it/s] 98%|█████████▊| 98/100 [00:07<00:00, 12.08it/s]100%|██████████| 100/100 [00:07<00:00, 11.28it/s]100%|██████████| 100/100 [00:07<00:00, 13.49it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00456, 0.00209
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00215, 0.00332
--- total mse / var(X): 0.0027
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:17,  5.60it/s]  4%|▍         | 4/100 [00:00<00:07, 13.45it/s]  6%|▌         | 6/100 [00:00<00:06, 15.64it/s]  8%|▊         | 8/100 [00:00<00:05, 15.61it/s] 10%|█         | 10/100 [00:00<00:05, 15.80it/s] 13%|█▎        | 13/100 [00:00<00:04, 17.48it/s] 15%|█▌        | 15/100 [00:00<00:04, 17.89it/s] 17%|█▋        | 17/100 [00:01<00:04, 18.05it/s] 19%|█▉        | 19/100 [00:01<00:04, 17.20it/s] 21%|██        | 21/100 [00:01<00:05, 15.28it/s] 23%|██▎       | 23/100 [00:01<00:04, 15.72it/s] 25%|██▌       | 25/100 [00:01<00:04, 15.47it/s] 28%|██▊       | 28/100 [00:01<00:04, 15.86it/s] 30%|███       | 30/100 [00:01<00:04, 16.38it/s] 33%|███▎      | 33/100 [00:01<00:03, 18.96it/s] 35%|███▌      | 35/100 [00:02<00:04, 15.28it/s] 38%|███▊      | 38/100 [00:02<00:03, 16.25it/s] 40%|████      | 40/100 [00:02<00:03, 15.63it/s] 42%|████▏     | 42/100 [00:02<00:03, 16.45it/s] 44%|████▍     | 44/100 [00:02<00:04, 13.96it/s] 47%|████▋     | 47/100 [00:03<00:03, 14.51it/s] 49%|████▉     | 49/100 [00:03<00:03, 15.15it/s] 51%|█████     | 51/100 [00:03<00:03, 16.03it/s] 53%|█████▎    | 53/100 [00:03<00:03, 14.26it/s] 55%|█████▌    | 55/100 [00:03<00:03, 14.33it/s] 57%|█████▋    | 57/100 [00:03<00:03, 12.80it/s] 59%|█████▉    | 59/100 [00:03<00:02, 13.94it/s] 61%|██████    | 61/100 [00:04<00:03, 12.80it/s] 63%|██████▎   | 63/100 [00:04<00:02, 13.13it/s] 66%|██████▌   | 66/100 [00:04<00:02, 13.71it/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.50it/s] 70%|███████   | 70/100 [00:04<00:02, 13.46it/s] 72%|███████▏  | 72/100 [00:04<00:01, 14.10it/s] 74%|███████▍  | 74/100 [00:05<00:02, 12.63it/s] 76%|███████▌  | 76/100 [00:05<00:01, 13.80it/s] 78%|███████▊  | 78/100 [00:05<00:01, 12.60it/s] 80%|████████  | 80/100 [00:05<00:01, 12.99it/s] 82%|████████▏ | 82/100 [00:05<00:01, 13.80it/s] 84%|████████▍ | 84/100 [00:05<00:01, 15.08it/s] 87%|████████▋ | 87/100 [00:05<00:00, 16.71it/s] 89%|████████▉ | 89/100 [00:05<00:00, 17.48it/s] 91%|█████████ | 91/100 [00:06<00:00, 17.54it/s] 94%|█████████▍| 94/100 [00:06<00:00, 18.62it/s] 96%|█████████▌| 96/100 [00:06<00:00, 16.36it/s] 98%|█████████▊| 98/100 [00:06<00:00, 17.12it/s]100%|██████████| 100/100 [00:06<00:00, 15.28it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00543, 0.00531
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00495, 0.00506
--- total mse / var(X): 0.00518
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:07, 13.42it/s]  5%|▌         | 5/100 [00:00<00:04, 19.30it/s]  8%|▊         | 8/100 [00:00<00:04, 22.70it/s] 12%|█▏        | 12/100 [00:00<00:03, 26.45it/s] 15%|█▌        | 15/100 [00:00<00:03, 27.49it/s] 18%|█▊        | 18/100 [00:00<00:03, 23.68it/s] 21%|██        | 21/100 [00:00<00:03, 21.65it/s] 24%|██▍       | 24/100 [00:01<00:03, 22.94it/s] 27%|██▋       | 27/100 [00:01<00:03, 23.11it/s] 30%|███       | 30/100 [00:01<00:02, 24.35it/s] 33%|███▎      | 33/100 [00:01<00:02, 25.61it/s] 36%|███▌      | 36/100 [00:01<00:02, 25.74it/s] 39%|███▉      | 39/100 [00:01<00:02, 24.94it/s] 42%|████▏     | 42/100 [00:01<00:02, 22.82it/s] 45%|████▌     | 45/100 [00:01<00:02, 23.78it/s] 48%|████▊     | 48/100 [00:02<00:02, 25.06it/s] 51%|█████     | 51/100 [00:02<00:02, 24.10it/s] 54%|█████▍    | 54/100 [00:02<00:02, 21.85it/s] 57%|█████▋    | 57/100 [00:02<00:01, 22.98it/s] 61%|██████    | 61/100 [00:02<00:01, 25.79it/s] 66%|██████▌   | 66/100 [00:02<00:01, 30.06it/s] 70%|███████   | 70/100 [00:02<00:00, 30.63it/s] 74%|███████▍  | 74/100 [00:02<00:00, 32.15it/s] 78%|███████▊  | 78/100 [00:03<00:00, 32.86it/s] 82%|████████▏ | 82/100 [00:03<00:00, 32.65it/s] 86%|████████▌ | 86/100 [00:03<00:00, 33.73it/s] 90%|█████████ | 90/100 [00:03<00:00, 34.03it/s] 94%|█████████▍| 94/100 [00:03<00:00, 33.69it/s] 98%|█████████▊| 98/100 [00:03<00:00, 32.57it/s]100%|██████████| 100/100 [00:03<00:00, 27.11it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00278, 0.00247
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00338, 0.00375
--- total mse / var(X): 0.00311
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:08, 11.44it/s]  5%|▌         | 5/100 [00:00<00:04, 19.10it/s]  9%|▉         | 9/100 [00:00<00:03, 24.95it/s] 13%|█▎        | 13/100 [00:00<00:03, 28.07it/s] 16%|█▌        | 16/100 [00:00<00:03, 24.54it/s] 19%|█▉        | 19/100 [00:00<00:03, 25.21it/s] 23%|██▎       | 23/100 [00:00<00:02, 27.06it/s] 27%|██▋       | 27/100 [00:01<00:02, 29.42it/s] 30%|███       | 30/100 [00:01<00:02, 28.37it/s] 34%|███▍      | 34/100 [00:01<00:02, 29.29it/s] 38%|███▊      | 38/100 [00:01<00:02, 29.87it/s] 42%|████▏     | 42/100 [00:01<00:01, 29.84it/s] 45%|████▌     | 45/100 [00:01<00:01, 28.21it/s] 48%|████▊     | 48/100 [00:01<00:01, 27.14it/s] 51%|█████     | 51/100 [00:01<00:01, 26.93it/s] 55%|█████▌    | 55/100 [00:02<00:01, 28.45it/s] 58%|█████▊    | 58/100 [00:02<00:01, 28.79it/s] 62%|██████▏   | 62/100 [00:02<00:01, 28.84it/s] 66%|██████▌   | 66/100 [00:02<00:01, 29.81it/s] 70%|███████   | 70/100 [00:02<00:01, 29.86it/s] 74%|███████▍  | 74/100 [00:02<00:00, 29.55it/s] 78%|███████▊  | 78/100 [00:02<00:00, 30.46it/s] 82%|████████▏ | 82/100 [00:02<00:00, 31.77it/s] 86%|████████▌ | 86/100 [00:03<00:00, 31.64it/s] 90%|█████████ | 90/100 [00:03<00:00, 30.39it/s] 94%|█████████▍| 94/100 [00:03<00:00, 29.77it/s] 98%|█████████▊| 98/100 [00:03<00:00, 30.24it/s]100%|██████████| 100/100 [00:03<00:00, 28.66it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000225, 0.000212
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000124, 0.000131
--- total mse / var(X): 0.000171
start table evaluation...
Elapsed time: 256.2427144050598 seconds
Cosine similarity between AMM and exact (Train): 0.9999983
Cosine similarity between AMM and exact (Test): 0.99998415
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9979591369628906,
                                      0.9986770153045654,
                                      0.9983903765678406,
                                      0.9999982714653015],
               'cossim_layer_test': [0.9890332221984863,
                                     0.9935365319252014,
                                     0.9923895597457886,
                                     0.9999841451644897],
               'cossim_amm_train': [0.9959006309509277,
                                    0.9979987740516663,
                                    0.9952080845832825,
                                    0.9898624420166016,
                                    0.9948101043701172,
                                    0.9968013167381287,
                                    0.9964684247970581,
                                    0.9998757839202881],
               'cossim_amm_test': [0.979345440864563,
                                   0.9937266707420349,
                                   0.985720694065094,
                                   0.9771589636802673,
                                   0.9735104441642761,
                                   0.9877245426177979,
                                   0.9892944693565369,
                                   0.9990460276603699],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.4777552522 - test_loss: 0.3367076411
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.2406126341 - test_loss: 0.1843416862
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.1424291321 - test_loss: 0.1135868906
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0990428996 - test_loss: 0.0805923462
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0801362043 - test_loss: 0.0646354729
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0720048154 - test_loss: 0.0566308594
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0686398094 - test_loss: 0.0525335239
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0673413037 - test_loss: 0.0504552070
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0668759396 - test_loss: 0.0494304395
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0667119800 - test_loss: 0.0489245568
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0665478138 - test_loss: 0.0487477600
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0659298687 - test_loss: 0.0523835769
Early Stop Left: 4
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0653069182 - test_loss: 0.0531719777
Early Stop Left: 3
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0651051448 - test_loss: 0.0506074744
Early Stop Left: 2
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0649772185 - test_loss: 0.0504151038
Early Stop Left: 1
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0648568564 - test_loss: 0.0504480102
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  7%|▋         | 15/205 [00:00<00:01, 141.38it/s] 15%|█▍        | 30/205 [00:00<00:01, 141.18it/s] 22%|██▏       | 45/205 [00:00<00:01, 138.62it/s] 29%|██▉       | 60/205 [00:00<00:01, 138.93it/s] 36%|███▌      | 74/205 [00:00<00:00, 139.06it/s] 43%|████▎     | 88/205 [00:00<00:00, 137.36it/s] 50%|█████     | 103/205 [00:00<00:00, 139.30it/s] 58%|█████▊    | 118/205 [00:00<00:00, 140.95it/s] 65%|██████▍   | 133/205 [00:00<00:00, 142.06it/s] 72%|███████▏  | 148/205 [00:01<00:00, 141.51it/s] 80%|███████▉  | 163/205 [00:01<00:00, 142.01it/s] 87%|████████▋ | 178/205 [00:01<00:00, 141.41it/s] 94%|█████████▍| 193/205 [00:01<00:00, 141.66it/s]100%|██████████| 205/205 [00:01<00:00, 140.83it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5880846257 - test_loss: 0.4886183723
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3734036814 - test_loss: 0.3168124965
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2527123539 - test_loss: 0.2185086598
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1793026190 - test_loss: 0.1556119872
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1333149749 - test_loss: 0.1153927431
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1049720076 - test_loss: 0.0898513506
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0879096554 - test_loss: 0.0737461780
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0779507848 - test_loss: 0.0636868932
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0723667091 - test_loss: 0.0574450442
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0693913565 - test_loss: 0.0536607186
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0679027034 - test_loss: 0.0513900223
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0672035813 - test_loss: 0.0500870987
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0668957407 - test_loss: 0.0493849661
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0667691841 - test_loss: 0.0490347505
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0667170240 - test_loss: 0.0489078980
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0666921562 - test_loss: 0.0488401009
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0666741524 - test_loss: 0.0488144834
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0666544573 - test_loss: 0.0488255095
Early Stop Left: 4
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0666244401 - test_loss: 0.0489683352
Early Stop Left: 3
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0665837988 - test_loss: 0.0489267036
Early Stop Left: 2
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.0665365938 - test_loss: 0.0491489387
Early Stop Left: 1
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.0664783591 - test_loss: 0.0489838344
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  8%|▊         | 17/205 [00:00<00:01, 163.12it/s] 17%|█▋        | 34/205 [00:00<00:01, 160.46it/s] 25%|██▌       | 52/205 [00:00<00:00, 166.20it/s] 34%|███▍      | 70/205 [00:00<00:00, 169.52it/s] 43%|████▎     | 88/205 [00:00<00:00, 168.02it/s] 51%|█████     | 105/205 [00:00<00:00, 167.57it/s] 60%|██████    | 123/205 [00:00<00:00, 169.16it/s] 68%|██████▊   | 140/205 [00:00<00:00, 169.32it/s] 77%|███████▋  | 158/205 [00:00<00:00, 170.77it/s] 86%|████████▌ | 176/205 [00:01<00:00, 171.84it/s] 95%|█████████▍| 194/205 [00:01<00:00, 172.35it/s]100%|██████████| 205/205 [00:01<00:00, 169.88it/s]
Best micro threshold=0.934017, fscore=0.991
p,r,f1: 0.983091431134236 0.999964535481493 0.9914561997437327
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit_large',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9340168237686157,
                 'p': 0.983091431134236,
                 'r': 0.999964535481493,
                 'f1': 0.9914561997437327},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm

Best micro threshold=0.959097, fscore=0.991
p,r,f1: 0.9830554560629908 0.9999943923624582 0.9914525791924556
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit_min',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9590970277786255,
                 'p': 0.9830554560629908,
                 'r': 0.9999943923624582,
                 'f1': 0.9914525791924556},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 1.0000006
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0842, 0.0842
--- total mse / var(X): 0.0842
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:58,  1.20s/it]  2%|▏         | 2/100 [00:02<01:51,  1.14s/it]  3%|▎         | 3/100 [00:03<01:51,  1.15s/it]  4%|▍         | 4/100 [00:04<01:50,  1.15s/it]  5%|▌         | 5/100 [00:05<01:55,  1.22s/it]  6%|▌         | 6/100 [00:07<01:51,  1.18s/it]  7%|▋         | 7/100 [00:08<01:45,  1.13s/it]  8%|▊         | 8/100 [00:09<01:42,  1.11s/it]  9%|▉         | 9/100 [00:10<01:34,  1.04s/it] 10%|█         | 10/100 [00:11<01:37,  1.08s/it] 11%|█         | 11/100 [00:12<01:36,  1.08s/it] 12%|█▏        | 12/100 [00:13<01:33,  1.06s/it] 13%|█▎        | 13/100 [00:14<01:31,  1.06s/it] 14%|█▍        | 14/100 [00:15<01:30,  1.05s/it] 15%|█▌        | 15/100 [00:16<01:29,  1.05s/it] 16%|█▌        | 16/100 [00:17<01:24,  1.00s/it] 17%|█▋        | 17/100 [00:18<01:20,  1.03it/s] 18%|█▊        | 18/100 [00:18<01:14,  1.10it/s] 19%|█▉        | 19/100 [00:19<01:10,  1.15it/s] 20%|██        | 20/100 [00:20<01:08,  1.17it/s] 21%|██        | 21/100 [00:21<01:10,  1.12it/s] 22%|██▏       | 22/100 [00:22<01:12,  1.07it/s] 23%|██▎       | 23/100 [00:23<01:14,  1.03it/s] 24%|██▍       | 24/100 [00:24<01:16,  1.00s/it] 25%|██▌       | 25/100 [00:25<01:16,  1.02s/it] 26%|██▌       | 26/100 [00:26<01:17,  1.05s/it] 27%|██▋       | 27/100 [00:27<01:14,  1.02s/it] 28%|██▊       | 28/100 [00:28<01:13,  1.02s/it] 29%|██▉       | 29/100 [00:29<01:09,  1.02it/s] 30%|███       | 30/100 [00:30<01:05,  1.07it/s] 31%|███       | 31/100 [00:31<01:07,  1.02it/s] 32%|███▏      | 32/100 [00:32<01:10,  1.04s/it] 33%|███▎      | 33/100 [00:33<01:10,  1.06s/it] 34%|███▍      | 34/100 [00:35<01:11,  1.08s/it] 35%|███▌      | 35/100 [00:36<01:11,  1.11s/it] 36%|███▌      | 36/100 [00:37<01:13,  1.15s/it] 37%|███▋      | 37/100 [00:38<01:13,  1.17s/it] 38%|███▊      | 38/100 [00:40<01:15,  1.23s/it] 39%|███▉      | 39/100 [00:41<01:17,  1.27s/it] 40%|████      | 40/100 [00:42<01:18,  1.32s/it] 41%|████      | 41/100 [00:44<01:19,  1.35s/it] 42%|████▏     | 42/100 [00:45<01:18,  1.36s/it] 43%|████▎     | 43/100 [00:47<01:17,  1.36s/it] 44%|████▍     | 44/100 [00:48<01:17,  1.39s/it] 45%|████▌     | 45/100 [00:49<01:16,  1.38s/it] 46%|████▌     | 46/100 [00:51<01:12,  1.34s/it] 47%|████▋     | 47/100 [00:52<01:08,  1.28s/it] 48%|████▊     | 48/100 [00:53<01:05,  1.26s/it] 49%|████▉     | 49/100 [00:54<01:04,  1.27s/it] 50%|█████     | 50/100 [00:55<01:01,  1.23s/it] 51%|█████     | 51/100 [00:57<00:59,  1.21s/it] 52%|█████▏    | 52/100 [00:58<00:57,  1.21s/it] 53%|█████▎    | 53/100 [00:59<00:56,  1.21s/it] 54%|█████▍    | 54/100 [01:00<00:55,  1.20s/it] 55%|█████▌    | 55/100 [01:01<00:52,  1.17s/it] 56%|█████▌    | 56/100 [01:02<00:49,  1.12s/it] 57%|█████▋    | 57/100 [01:05<01:05,  1.52s/it] 58%|█████▊    | 58/100 [01:06<01:01,  1.46s/it] 59%|█████▉    | 59/100 [01:07<00:56,  1.38s/it] 60%|██████    | 60/100 [01:09<00:54,  1.37s/it] 61%|██████    | 61/100 [01:10<00:54,  1.39s/it] 62%|██████▏   | 62/100 [01:11<00:51,  1.37s/it] 63%|██████▎   | 63/100 [01:13<00:49,  1.33s/it] 64%|██████▍   | 64/100 [01:14<00:45,  1.27s/it] 65%|██████▌   | 65/100 [01:15<00:40,  1.16s/it] 66%|██████▌   | 66/100 [01:16<00:37,  1.11s/it] 67%|██████▋   | 67/100 [01:17<00:35,  1.09s/it] 68%|██████▊   | 68/100 [01:18<00:34,  1.07s/it] 69%|██████▉   | 69/100 [01:19<00:33,  1.07s/it] 70%|███████   | 70/100 [01:20<00:34,  1.15s/it] 71%|███████   | 71/100 [01:21<00:34,  1.19s/it] 72%|███████▏  | 72/100 [01:23<00:36,  1.29s/it] 73%|███████▎  | 73/100 [01:24<00:35,  1.31s/it] 74%|███████▍  | 74/100 [01:26<00:33,  1.30s/it] 75%|███████▌  | 75/100 [01:27<00:33,  1.36s/it] 76%|███████▌  | 76/100 [01:28<00:32,  1.36s/it] 77%|███████▋  | 77/100 [01:30<00:30,  1.33s/it] 78%|███████▊  | 78/100 [01:31<00:29,  1.34s/it] 79%|███████▉  | 79/100 [01:32<00:27,  1.32s/it] 80%|████████  | 80/100 [01:34<00:25,  1.30s/it] 81%|████████  | 81/100 [01:35<00:23,  1.24s/it] 82%|████████▏ | 82/100 [01:36<00:21,  1.21s/it] 83%|████████▎ | 83/100 [01:37<00:19,  1.18s/it] 84%|████████▍ | 84/100 [01:38<00:19,  1.22s/it] 85%|████████▌ | 85/100 [01:40<00:18,  1.25s/it] 86%|████████▌ | 86/100 [01:41<00:16,  1.20s/it] 87%|████████▋ | 87/100 [01:42<00:15,  1.16s/it] 88%|████████▊ | 88/100 [01:43<00:14,  1.20s/it] 89%|████████▉ | 89/100 [01:44<00:13,  1.23s/it] 90%|█████████ | 90/100 [01:46<00:13,  1.30s/it] 91%|█████████ | 91/100 [01:47<00:12,  1.34s/it] 92%|█████████▏| 92/100 [01:49<00:10,  1.35s/it] 93%|█████████▎| 93/100 [01:50<00:09,  1.38s/it] 94%|█████████▍| 94/100 [01:52<00:08,  1.43s/it] 95%|█████████▌| 95/100 [01:53<00:07,  1.40s/it] 96%|█████████▌| 96/100 [01:54<00:05,  1.36s/it] 97%|█████████▋| 97/100 [01:55<00:04,  1.35s/it] 98%|█████████▊| 98/100 [01:57<00:02,  1.37s/it] 99%|█████████▉| 99/100 [01:58<00:01,  1.37s/it]100%|██████████| 100/100 [01:59<00:00,  1.32s/it]100%|██████████| 100/100 [01:59<00:00,  1.20s/it]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0068, 0.0068
--- total mse / var(X): 0.0068
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00345, 0.00345
--- total mse / var(X): 0.00345
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0046, 0.0046
--- total mse / var(X): 0.0046
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00117, 0.00117
--- total mse / var(X): 0.00117
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0503, 0.0503
--- total mse / var(X): 0.0503
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.38it/s]  3%|▎         | 3/100 [00:00<00:09, 10.23it/s]  5%|▌         | 5/100 [00:00<00:08, 11.65it/s]  7%|▋         | 7/100 [00:00<00:08, 11.29it/s]  9%|▉         | 9/100 [00:00<00:07, 12.24it/s] 11%|█         | 11/100 [00:00<00:07, 12.12it/s] 13%|█▎        | 13/100 [00:01<00:07, 11.85it/s] 15%|█▌        | 15/100 [00:01<00:07, 11.79it/s] 17%|█▋        | 17/100 [00:01<00:06, 12.05it/s] 19%|█▉        | 19/100 [00:01<00:06, 12.19it/s] 21%|██        | 21/100 [00:01<00:06, 11.82it/s] 23%|██▎       | 23/100 [00:01<00:06, 12.34it/s] 25%|██▌       | 25/100 [00:02<00:06, 12.12it/s] 27%|██▋       | 27/100 [00:02<00:06, 11.12it/s] 29%|██▉       | 29/100 [00:02<00:06, 11.44it/s] 31%|███       | 31/100 [00:02<00:07,  9.49it/s] 33%|███▎      | 33/100 [00:03<00:07,  9.18it/s] 34%|███▍      | 34/100 [00:03<00:07,  8.86it/s] 37%|███▋      | 37/100 [00:03<00:05, 11.94it/s] 40%|████      | 40/100 [00:03<00:04, 14.32it/s] 42%|████▏     | 42/100 [00:03<00:03, 14.79it/s] 44%|████▍     | 44/100 [00:03<00:03, 15.13it/s] 46%|████▌     | 46/100 [00:03<00:03, 15.51it/s] 49%|████▉     | 49/100 [00:03<00:02, 17.20it/s] 52%|█████▏    | 52/100 [00:04<00:02, 18.60it/s] 54%|█████▍    | 54/100 [00:04<00:02, 18.66it/s] 56%|█████▌    | 56/100 [00:04<00:02, 17.84it/s] 58%|█████▊    | 58/100 [00:04<00:02, 17.32it/s] 60%|██████    | 60/100 [00:04<00:02, 17.68it/s] 63%|██████▎   | 63/100 [00:04<00:02, 18.05it/s] 65%|██████▌   | 65/100 [00:04<00:01, 18.36it/s] 68%|██████▊   | 68/100 [00:04<00:01, 19.89it/s] 71%|███████   | 71/100 [00:05<00:01, 20.80it/s] 74%|███████▍  | 74/100 [00:05<00:01, 21.52it/s] 77%|███████▋  | 77/100 [00:05<00:01, 19.27it/s] 79%|███████▉  | 79/100 [00:05<00:01, 17.53it/s] 81%|████████  | 81/100 [00:05<00:01, 13.65it/s] 83%|████████▎ | 83/100 [00:06<00:01, 11.19it/s] 85%|████████▌ | 85/100 [00:06<00:01, 11.94it/s] 87%|████████▋ | 87/100 [00:06<00:01, 11.01it/s] 89%|████████▉ | 89/100 [00:06<00:00, 11.51it/s] 91%|█████████ | 91/100 [00:06<00:00, 10.67it/s] 93%|█████████▎| 93/100 [00:06<00:00, 10.88it/s] 95%|█████████▌| 95/100 [00:07<00:00, 11.25it/s] 97%|█████████▋| 97/100 [00:07<00:00, 11.73it/s] 99%|█████████▉| 99/100 [00:07<00:00, 10.39it/s]100%|██████████| 100/100 [00:07<00:00, 13.13it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00141, 0.00141
--- total mse / var(X): 0.00141
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.85it/s]  3%|▎         | 3/100 [00:00<00:06, 15.01it/s]  5%|▌         | 5/100 [00:00<00:06, 15.01it/s]  7%|▋         | 7/100 [00:00<00:07, 12.86it/s]  9%|▉         | 9/100 [00:00<00:07, 12.28it/s] 11%|█         | 11/100 [00:00<00:06, 12.85it/s] 13%|█▎        | 13/100 [00:00<00:06, 13.66it/s] 15%|█▌        | 15/100 [00:01<00:06, 13.43it/s] 17%|█▋        | 17/100 [00:01<00:05, 14.49it/s] 19%|█▉        | 19/100 [00:01<00:05, 14.46it/s] 21%|██        | 21/100 [00:01<00:05, 15.35it/s] 23%|██▎       | 23/100 [00:01<00:04, 16.01it/s] 25%|██▌       | 25/100 [00:01<00:04, 16.89it/s] 27%|██▋       | 27/100 [00:01<00:04, 17.07it/s] 29%|██▉       | 29/100 [00:01<00:04, 17.01it/s] 31%|███       | 31/100 [00:02<00:04, 16.82it/s] 33%|███▎      | 33/100 [00:02<00:04, 16.52it/s] 35%|███▌      | 35/100 [00:02<00:04, 15.96it/s] 37%|███▋      | 37/100 [00:02<00:03, 16.77it/s] 39%|███▉      | 39/100 [00:02<00:03, 16.81it/s] 41%|████      | 41/100 [00:02<00:04, 13.12it/s] 43%|████▎     | 43/100 [00:02<00:03, 14.26it/s] 45%|████▌     | 45/100 [00:02<00:03, 15.53it/s] 47%|████▋     | 47/100 [00:03<00:03, 15.70it/s] 49%|████▉     | 49/100 [00:03<00:03, 16.00it/s] 51%|█████     | 51/100 [00:03<00:03, 14.80it/s] 53%|█████▎    | 53/100 [00:03<00:02, 15.83it/s] 55%|█████▌    | 55/100 [00:03<00:02, 15.68it/s] 57%|█████▋    | 57/100 [00:03<00:02, 15.95it/s] 59%|█████▉    | 59/100 [00:03<00:02, 15.37it/s] 61%|██████    | 61/100 [00:04<00:02, 16.16it/s] 64%|██████▍   | 64/100 [00:04<00:02, 17.52it/s] 66%|██████▌   | 66/100 [00:04<00:02, 16.92it/s] 68%|██████▊   | 68/100 [00:04<00:02, 15.92it/s] 70%|███████   | 70/100 [00:04<00:01, 15.93it/s] 72%|███████▏  | 72/100 [00:04<00:02, 12.91it/s] 75%|███████▌  | 75/100 [00:04<00:01, 13.95it/s] 77%|███████▋  | 77/100 [00:05<00:01, 14.77it/s] 80%|████████  | 80/100 [00:05<00:01, 16.51it/s] 82%|████████▏ | 82/100 [00:05<00:01, 16.88it/s] 84%|████████▍ | 84/100 [00:05<00:01, 15.35it/s] 86%|████████▌ | 86/100 [00:05<00:00, 15.60it/s] 88%|████████▊ | 88/100 [00:05<00:00, 15.99it/s] 90%|█████████ | 90/100 [00:05<00:00, 16.64it/s] 92%|█████████▏| 92/100 [00:06<00:00, 13.95it/s] 94%|█████████▍| 94/100 [00:06<00:00, 15.04it/s] 96%|█████████▌| 96/100 [00:06<00:00, 15.83it/s] 98%|█████████▊| 98/100 [00:06<00:00, 16.08it/s]100%|██████████| 100/100 [00:06<00:00, 16.78it/s]100%|██████████| 100/100 [00:06<00:00, 15.39it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00719, 0.00719
--- total mse / var(X): 0.00719
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  3%|▎         | 3/100 [00:00<00:04, 22.84it/s]  6%|▌         | 6/100 [00:00<00:04, 22.40it/s] 11%|█         | 11/100 [00:00<00:02, 31.40it/s] 16%|█▌        | 16/100 [00:00<00:02, 36.27it/s] 21%|██        | 21/100 [00:00<00:02, 36.03it/s] 25%|██▌       | 25/100 [00:00<00:02, 37.15it/s] 30%|███       | 30/100 [00:00<00:01, 38.55it/s] 35%|███▌      | 35/100 [00:00<00:01, 41.13it/s] 41%|████      | 41/100 [00:01<00:01, 42.15it/s] 46%|████▌     | 46/100 [00:01<00:01, 43.93it/s] 51%|█████     | 51/100 [00:01<00:01, 43.19it/s] 56%|█████▌    | 56/100 [00:01<00:00, 44.31it/s] 61%|██████    | 61/100 [00:01<00:00, 44.52it/s] 66%|██████▌   | 66/100 [00:01<00:00, 42.89it/s] 71%|███████   | 71/100 [00:01<00:00, 43.77it/s] 76%|███████▌  | 76/100 [00:02<00:00, 32.15it/s] 80%|████████  | 80/100 [00:02<00:00, 33.14it/s] 84%|████████▍ | 84/100 [00:02<00:00, 34.66it/s] 88%|████████▊ | 88/100 [00:02<00:00, 33.90it/s] 92%|█████████▏| 92/100 [00:02<00:00, 32.73it/s] 96%|█████████▌| 96/100 [00:02<00:00, 34.26it/s]100%|██████████| 100/100 [00:02<00:00, 34.50it/s]100%|██████████| 100/100 [00:02<00:00, 36.91it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00386, 0.00386
--- total mse / var(X): 0.00386
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:10,  9.36it/s]  3%|▎         | 3/100 [00:00<00:07, 12.51it/s]  5%|▌         | 5/100 [00:00<00:07, 13.23it/s]  7%|▋         | 7/100 [00:00<00:08, 11.20it/s]  9%|▉         | 9/100 [00:00<00:07, 12.20it/s] 11%|█         | 11/100 [00:00<00:06, 13.86it/s] 14%|█▍        | 14/100 [00:00<00:05, 16.39it/s] 16%|█▌        | 16/100 [00:01<00:05, 16.62it/s] 18%|█▊        | 18/100 [00:01<00:04, 17.43it/s] 20%|██        | 20/100 [00:01<00:04, 17.54it/s] 22%|██▏       | 22/100 [00:01<00:04, 16.55it/s] 25%|██▌       | 25/100 [00:01<00:04, 18.70it/s] 27%|██▋       | 27/100 [00:01<00:04, 18.10it/s] 30%|███       | 30/100 [00:01<00:03, 19.21it/s] 32%|███▏      | 32/100 [00:01<00:03, 18.95it/s] 34%|███▍      | 34/100 [00:02<00:03, 18.07it/s] 37%|███▋      | 37/100 [00:02<00:03, 17.68it/s] 39%|███▉      | 39/100 [00:02<00:03, 17.01it/s] 42%|████▏     | 42/100 [00:02<00:03, 18.42it/s] 44%|████▍     | 44/100 [00:02<00:03, 17.56it/s] 47%|████▋     | 47/100 [00:02<00:02, 19.67it/s] 51%|█████     | 51/100 [00:02<00:02, 23.86it/s] 54%|█████▍    | 54/100 [00:03<00:02, 21.94it/s] 58%|█████▊    | 58/100 [00:03<00:01, 24.49it/s] 61%|██████    | 61/100 [00:03<00:01, 25.28it/s] 64%|██████▍   | 64/100 [00:03<00:01, 24.92it/s] 67%|██████▋   | 67/100 [00:03<00:01, 23.94it/s] 70%|███████   | 70/100 [00:03<00:01, 25.24it/s] 73%|███████▎  | 73/100 [00:03<00:01, 25.46it/s] 76%|███████▌  | 76/100 [00:03<00:00, 26.64it/s] 79%|███████▉  | 79/100 [00:04<00:00, 24.80it/s] 82%|████████▏ | 82/100 [00:04<00:00, 25.64it/s] 85%|████████▌ | 85/100 [00:04<00:00, 25.79it/s] 88%|████████▊ | 88/100 [00:04<00:00, 14.76it/s] 91%|█████████ | 91/100 [00:04<00:00, 16.34it/s] 94%|█████████▍| 94/100 [00:05<00:00, 13.55it/s] 96%|█████████▌| 96/100 [00:05<00:00, 13.95it/s] 99%|█████████▉| 99/100 [00:05<00:00, 15.85it/s]100%|██████████| 100/100 [00:05<00:00, 18.57it/s]
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (6) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 2.65e-08, 2.65e-08
--- total mse / var(X): 2.65e-08
start table evaluation...
Elapsed time: 227.214022397995 seconds
Cosine similarity between AMM and exact (Train): 0.9999975
Cosine similarity between AMM and exact (Test): 0.99999225
p,r,f1: 0.9830605092068085 0.9999899971870878 0.9914529888843776
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830605092068085, 0.9999899971870878, 0.9914529888843776],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.995661199092865,
                                      0.9974856376647949,
                                      0.9970260262489319,
                                      0.9999974966049194],
               'cossim_layer_test': [0.9749162793159485,
                                     0.9932835698127747,
                                     0.9927663207054138,
                                     0.9999922513961792],
               'cossim_amm_train': [0.991267740726471,
                                    0.9970795512199402,
                                    0.9914891123771667,
                                    0.9726642966270447,
                                    0.9905324578285217,
                                    0.9948425889015198,
                                    0.9943435192108154,
                                    0.9998421669006348],
               'cossim_amm_test': [0.9517139792442322,
                                   0.993352472782135,
                                   0.9864184856414795,
                                   0.9649707674980164,
                                   0.9811541438102722,
                                   0.9900352358818054,
                                   0.9911146759986877,
                                   0.9994975924491882],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 64),
                              (192, 1, 64),
                              (64, 64, 1),
                              (64, 64, 1),
                              (32, 1, 64),
                              (32, 1, 64),
                              (32, 1, 64),
                              (256, 1, 64)],
               'lut_total_size': 45056}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        1,376
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 6,128
Trainable params: 6,128
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5880846257 - test_loss: 0.4886183723
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3734036814 - test_loss: 0.3168124965
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2527123539 - test_loss: 0.2185086598
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1793026190 - test_loss: 0.1556119872
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1333149749 - test_loss: 0.1153927431
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1049720076 - test_loss: 0.0898513506
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0879096554 - test_loss: 0.0737461780
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0779507848 - test_loss: 0.0636868932
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0723667091 - test_loss: 0.0574450442
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0693913565 - test_loss: 0.0536607186
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0679027034 - test_loss: 0.0513900223
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0672035813 - test_loss: 0.0500870987
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0668957407 - test_loss: 0.0493849661
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0667691841 - test_loss: 0.0490347505
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0667170240 - test_loss: 0.0489078980
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0666921562 - test_loss: 0.0488401009
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0666741524 - test_loss: 0.0488144834
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0666544573 - test_loss: 0.0488255095
Early Stop Left: 4
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0666244401 - test_loss: 0.0489683352
Early Stop Left: 3
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0665837988 - test_loss: 0.0489267036
Early Stop Left: 2
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.0665365938 - test_loss: 0.0491489387
Early Stop Left: 1
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.0664783591 - test_loss: 0.0489838344
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  9%|▉         | 19/205 [00:00<00:01, 185.89it/s] 19%|█▉        | 39/205 [00:00<00:00, 189.51it/s] 28%|██▊       | 58/205 [00:00<00:00, 188.66it/s] 38%|███▊      | 77/205 [00:00<00:00, 186.92it/s] 47%|████▋     | 96/205 [00:00<00:00, 186.03it/s] 57%|█████▋    | 116/205 [00:00<00:00, 188.45it/s] 66%|██████▋   | 136/205 [00:00<00:00, 189.61it/s] 76%|███████▌  | 156/205 [00:00<00:00, 190.66it/s] 86%|████████▌ | 176/205 [00:00<00:00, 188.79it/s] 95%|█████████▌| 195/205 [00:01<00:00, 186.39it/s]100%|██████████| 205/205 [00:01<00:00, 187.53it/s]
Best micro threshold=0.959097, fscore=0.991
p,r,f1: 0.9830554560629908 0.9999943923624582 0.9914525791924556
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit_min',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9590970277786255,
                 'p': 0.9830554560629908,
                 'r': 0.9999943923624582,
                 'f1': 0.9914525791924556},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999997
Manual and Torch results cosine similarity (Test): 1.0000005
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 1 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0288, 0.0402
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 8.27e-05, 4.98e-05
--- total mse / var(X): 0.0201
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:01<01:52,  1.14s/it]  2%|▏         | 2/100 [00:02<01:52,  1.15s/it]  3%|▎         | 3/100 [00:03<01:47,  1.10s/it]  4%|▍         | 4/100 [00:04<01:41,  1.06s/it]  5%|▌         | 5/100 [00:05<01:39,  1.05s/it]  6%|▌         | 6/100 [00:06<01:37,  1.04s/it]  7%|▋         | 7/100 [00:07<01:36,  1.04s/it]  8%|▊         | 8/100 [00:08<01:35,  1.04s/it]  9%|▉         | 9/100 [00:09<01:39,  1.09s/it] 10%|█         | 10/100 [00:10<01:35,  1.07s/it] 11%|█         | 11/100 [00:11<01:30,  1.02s/it] 12%|█▏        | 12/100 [00:12<01:34,  1.07s/it] 13%|█▎        | 13/100 [00:14<01:37,  1.12s/it] 14%|█▍        | 14/100 [00:15<01:34,  1.10s/it] 15%|█▌        | 15/100 [00:16<01:35,  1.12s/it] 16%|█▌        | 16/100 [00:17<01:34,  1.13s/it] 17%|█▋        | 17/100 [00:18<01:29,  1.08s/it] 18%|█▊        | 18/100 [00:19<01:29,  1.09s/it] 19%|█▉        | 19/100 [00:20<01:26,  1.06s/it] 20%|██        | 20/100 [00:21<01:20,  1.01s/it] 21%|██        | 21/100 [00:22<01:20,  1.02s/it] 22%|██▏       | 22/100 [00:23<01:20,  1.03s/it] 23%|██▎       | 23/100 [00:24<01:19,  1.04s/it] 24%|██▍       | 24/100 [00:25<01:14,  1.02it/s] 25%|██▌       | 25/100 [00:26<01:07,  1.12it/s] 26%|██▌       | 26/100 [00:26<01:01,  1.21it/s] 27%|██▋       | 27/100 [00:27<01:00,  1.21it/s] 28%|██▊       | 28/100 [00:28<00:58,  1.22it/s] 29%|██▉       | 29/100 [00:29<00:57,  1.24it/s] 30%|███       | 30/100 [00:29<00:55,  1.27it/s] 31%|███       | 31/100 [00:30<00:54,  1.26it/s] 32%|███▏      | 32/100 [00:31<00:55,  1.22it/s] 33%|███▎      | 33/100 [00:32<00:56,  1.20it/s] 34%|███▍      | 34/100 [00:33<00:56,  1.17it/s] 35%|███▌      | 35/100 [00:34<00:54,  1.19it/s] 36%|███▌      | 36/100 [00:34<00:52,  1.23it/s] 37%|███▋      | 37/100 [00:35<00:50,  1.24it/s] 38%|███▊      | 38/100 [00:36<00:50,  1.22it/s] 39%|███▉      | 39/100 [00:37<00:49,  1.24it/s] 40%|████      | 40/100 [00:37<00:46,  1.29it/s] 41%|████      | 41/100 [00:38<00:43,  1.36it/s] 42%|████▏     | 42/100 [00:39<00:40,  1.43it/s] 43%|████▎     | 43/100 [00:40<00:42,  1.35it/s] 44%|████▍     | 44/100 [00:40<00:40,  1.38it/s] 45%|████▌     | 45/100 [00:41<00:37,  1.45it/s] 46%|████▌     | 46/100 [00:41<00:35,  1.54it/s] 47%|████▋     | 47/100 [00:42<00:32,  1.64it/s] 48%|████▊     | 48/100 [00:43<00:31,  1.65it/s] 49%|████▉     | 49/100 [00:44<00:37,  1.34it/s] 50%|█████     | 50/100 [00:45<00:45,  1.10it/s] 51%|█████     | 51/100 [00:46<00:46,  1.06it/s] 52%|█████▏    | 52/100 [00:47<00:44,  1.09it/s] 53%|█████▎    | 53/100 [00:48<00:41,  1.13it/s] 54%|█████▍    | 54/100 [00:49<00:41,  1.11it/s] 55%|█████▌    | 55/100 [00:50<00:41,  1.09it/s] 56%|█████▌    | 56/100 [00:50<00:40,  1.09it/s] 57%|█████▋    | 57/100 [00:51<00:39,  1.09it/s] 58%|█████▊    | 58/100 [00:53<00:42,  1.00s/it] 59%|█████▉    | 59/100 [00:54<00:42,  1.03s/it] 60%|██████    | 60/100 [00:55<00:40,  1.02s/it] 61%|██████    | 61/100 [00:56<00:42,  1.08s/it] 62%|██████▏   | 62/100 [00:57<00:42,  1.11s/it] 63%|██████▎   | 63/100 [00:58<00:41,  1.13s/it] 64%|██████▍   | 64/100 [00:59<00:37,  1.05s/it] 65%|██████▌   | 65/100 [01:00<00:36,  1.04s/it] 66%|██████▌   | 66/100 [01:01<00:34,  1.01s/it] 67%|██████▋   | 67/100 [01:02<00:32,  1.01it/s] 68%|██████▊   | 68/100 [01:03<00:31,  1.02it/s] 69%|██████▉   | 69/100 [01:04<00:30,  1.01it/s] 70%|███████   | 70/100 [01:05<00:30,  1.02s/it] 71%|███████   | 71/100 [01:06<00:29,  1.03s/it] 72%|███████▏  | 72/100 [01:07<00:29,  1.05s/it] 73%|███████▎  | 73/100 [01:08<00:28,  1.04s/it] 74%|███████▍  | 74/100 [01:09<00:26,  1.02s/it] 75%|███████▌  | 75/100 [01:10<00:25,  1.00s/it] 76%|███████▌  | 76/100 [01:11<00:24,  1.01s/it] 77%|███████▋  | 77/100 [01:12<00:23,  1.02s/it] 78%|███████▊  | 78/100 [01:13<00:22,  1.02s/it] 79%|███████▉  | 79/100 [01:15<00:23,  1.10s/it] 80%|████████  | 80/100 [01:16<00:21,  1.09s/it] 81%|████████  | 81/100 [01:16<00:19,  1.01s/it] 82%|████████▏ | 82/100 [01:17<00:17,  1.03it/s] 83%|████████▎ | 83/100 [01:18<00:15,  1.06it/s] 84%|████████▍ | 84/100 [01:19<00:14,  1.13it/s] 85%|████████▌ | 85/100 [01:20<00:12,  1.19it/s] 86%|████████▌ | 86/100 [01:20<00:11,  1.23it/s] 87%|████████▋ | 87/100 [01:21<00:10,  1.28it/s] 88%|████████▊ | 88/100 [01:22<00:09,  1.28it/s] 89%|████████▉ | 89/100 [01:22<00:07,  1.40it/s] 90%|█████████ | 90/100 [01:23<00:06,  1.47it/s] 91%|█████████ | 91/100 [01:24<00:05,  1.60it/s] 92%|█████████▏| 92/100 [01:24<00:04,  1.75it/s] 93%|█████████▎| 93/100 [01:24<00:03,  1.86it/s] 94%|█████████▍| 94/100 [01:25<00:03,  1.87it/s] 95%|█████████▌| 95/100 [01:25<00:02,  1.99it/s] 96%|█████████▌| 96/100 [01:26<00:01,  2.08it/s] 97%|█████████▋| 97/100 [01:26<00:01,  2.15it/s] 98%|█████████▊| 98/100 [01:27<00:00,  2.13it/s] 99%|█████████▉| 99/100 [01:27<00:00,  2.19it/s]100%|██████████| 100/100 [01:28<00:00,  2.21it/s]100%|██████████| 100/100 [01:28<00:00,  1.13it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 7,424
Trainable params: 7,424
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 7,424
Trainable params: 7,424
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5781485132 - test_loss: 0.4846979976
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3749914562 - test_loss: 0.3191600260
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2541406726 - test_loss: 0.2193960462
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.1796740571 - test_loss: 0.1557752311
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.1332385158 - test_loss: 0.1152693856
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.1047740326 - test_loss: 0.0896656325
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0877409720 - test_loss: 0.0735859289
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0778633589 - test_loss: 0.0635707757
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0723437956 - test_loss: 0.0573649510
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0694009194 - test_loss: 0.0535852515
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0679114552 - test_loss: 0.0513302897
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0672067870 - test_loss: 0.0500430754
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0668936702 - test_loss: 0.0493483560
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0667651496 - test_loss: 0.0490050774
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.0667122083 - test_loss: 0.0487894774
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.0666849159 - test_loss: 0.0487806957
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.0666589243 - test_loss: 0.0487924996
Early Stop Left: 4
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.0666196717 - test_loss: 0.0488794975
Early Stop Left: 3
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.0665548819 - test_loss: 0.0489116025
Early Stop Left: 2
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.0664695141 - test_loss: 0.0489160252
Early Stop Left: 1
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.0663648728 - test_loss: 0.0493075997
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  6%|▌         | 12/205 [00:00<00:01, 116.68it/s] 12%|█▏        | 24/205 [00:00<00:01, 116.72it/s] 18%|█▊        | 36/205 [00:00<00:01, 114.86it/s] 23%|██▎       | 48/205 [00:00<00:01, 116.22it/s] 29%|██▉       | 60/205 [00:00<00:01, 88.59it/s]  35%|███▌      | 72/205 [00:00<00:01, 95.88it/s] 41%|████      | 84/205 [00:00<00:01, 101.71it/s] 47%|████▋     | 96/205 [00:00<00:01, 106.50it/s] 53%|█████▎    | 108/205 [00:01<00:00, 109.38it/s] 59%|█████▊    | 120/205 [00:01<00:00, 111.72it/s] 64%|██████▍   | 132/205 [00:01<00:00, 113.10it/s] 70%|███████   | 144/205 [00:01<00:00, 114.92it/s] 76%|███████▌  | 156/205 [00:01<00:00, 116.41it/s] 82%|████████▏ | 168/205 [00:01<00:00, 99.33it/s]  88%|████████▊ | 180/205 [00:01<00:00, 104.72it/s] 94%|█████████▎| 192/205 [00:01<00:00, 108.88it/s]100%|██████████| 205/205 [00:01<00:00, 112.63it/s]100%|██████████| 205/205 [00:01<00:00, 108.23it/s]
Best micro threshold=0.959458, fscore=0.991
p,r,f1: 0.9830537893682311 0.9999998484422286 0.9914544131687777
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit_min',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9594577550888062,
                 'p': 0.9830537893682311,
                 'r': 0.9999998484422286,
                 'f1': 0.9914544131687777},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 7,424
Trainable params: 7,424
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000001
Manual and Torch results cosine similarity (Test): 0.9999994
start table training with fine tuning...
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  0%|          | 0/100 [00:00<?, ?it/s]
Retrain for 1 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.29, 0.29
--- total mse / var(X): 0.29
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:23,  4.23it/s]  2%|▏         | 2/100 [00:00<00:35,  2.75it/s]  3%|▎         | 3/100 [00:01<00:38,  2.50it/s]  4%|▍         | 4/100 [00:01<00:35,  2.72it/s]  5%|▌         | 5/100 [00:01<00:31,  2.98it/s]  6%|▌         | 6/100 [00:01<00:27,  3.41it/s]  7%|▋         | 7/100 [00:02<00:22,  4.10it/s]  8%|▊         | 8/100 [00:02<00:23,  3.99it/s]  9%|▉         | 9/100 [00:02<00:22,  4.08it/s] 10%|█         | 10/100 [00:03<00:32,  2.78it/s] 11%|█         | 11/100 [00:03<00:34,  2.60it/s] 12%|█▏        | 12/100 [00:04<00:33,  2.61it/s] 13%|█▎        | 13/100 [00:04<00:31,  2.76it/s] 14%|█▍        | 14/100 [00:04<00:31,  2.77it/s] 15%|█▌        | 15/100 [00:05<00:30,  2.80it/s] 16%|█▌        | 16/100 [00:05<00:27,  3.06it/s] 17%|█▋        | 17/100 [00:05<00:28,  2.95it/s] 18%|█▊        | 18/100 [00:05<00:27,  2.96it/s] 19%|█▉        | 19/100 [00:06<00:26,  3.07it/s] 20%|██        | 20/100 [00:06<00:24,  3.28it/s] 21%|██        | 21/100 [00:06<00:22,  3.58it/s] 22%|██▏       | 22/100 [00:06<00:20,  3.88it/s] 23%|██▎       | 23/100 [00:07<00:20,  3.71it/s] 24%|██▍       | 24/100 [00:07<00:20,  3.78it/s] 25%|██▌       | 25/100 [00:07<00:18,  4.04it/s] 26%|██▌       | 26/100 [00:08<00:20,  3.64it/s] 27%|██▋       | 27/100 [00:08<00:21,  3.33it/s] 28%|██▊       | 28/100 [00:08<00:23,  3.11it/s] 29%|██▉       | 29/100 [00:09<00:21,  3.36it/s] 30%|███       | 30/100 [00:09<00:20,  3.34it/s] 31%|███       | 31/100 [00:09<00:21,  3.17it/s] 32%|███▏      | 32/100 [00:09<00:20,  3.25it/s] 33%|███▎      | 33/100 [00:10<00:22,  2.93it/s] 34%|███▍      | 34/100 [00:10<00:25,  2.57it/s] 35%|███▌      | 35/100 [00:11<00:22,  2.90it/s] 36%|███▌      | 36/100 [00:11<00:23,  2.71it/s] 37%|███▋      | 37/100 [00:11<00:20,  3.10it/s] 38%|███▊      | 38/100 [00:12<00:18,  3.41it/s] 39%|███▉      | 39/100 [00:12<00:19,  3.14it/s] 40%|████      | 40/100 [00:12<00:17,  3.41it/s] 41%|████      | 41/100 [00:12<00:16,  3.60it/s] 42%|████▏     | 42/100 [00:13<00:14,  3.87it/s] 43%|████▎     | 43/100 [00:13<00:15,  3.70it/s] 44%|████▍     | 44/100 [00:13<00:17,  3.22it/s] 45%|████▌     | 45/100 [00:14<00:17,  3.19it/s] 46%|████▌     | 46/100 [00:14<00:15,  3.44it/s] 47%|████▋     | 47/100 [00:14<00:15,  3.38it/s] 48%|████▊     | 48/100 [00:14<00:14,  3.51it/s] 49%|████▉     | 49/100 [00:15<00:15,  3.36it/s] 50%|█████     | 50/100 [00:15<00:14,  3.55it/s] 51%|█████     | 51/100 [00:15<00:14,  3.32it/s] 52%|█████▏    | 52/100 [00:16<00:13,  3.44it/s] 53%|█████▎    | 53/100 [00:16<00:13,  3.38it/s] 54%|█████▍    | 54/100 [00:16<00:12,  3.73it/s] 55%|█████▌    | 55/100 [00:16<00:12,  3.59it/s] 56%|█████▌    | 56/100 [00:17<00:13,  3.32it/s] 57%|█████▋    | 57/100 [00:17<00:12,  3.34it/s] 58%|█████▊    | 58/100 [00:18<00:14,  2.91it/s] 59%|█████▉    | 59/100 [00:18<00:13,  2.96it/s] 60%|██████    | 60/100 [00:18<00:13,  2.90it/s] 61%|██████    | 61/100 [00:19<00:13,  2.99it/s] 62%|██████▏   | 62/100 [00:19<00:13,  2.92it/s] 63%|██████▎   | 63/100 [00:19<00:11,  3.09it/s] 64%|██████▍   | 64/100 [00:19<00:11,  3.03it/s] 65%|██████▌   | 65/100 [00:20<00:12,  2.91it/s] 66%|██████▌   | 66/100 [00:20<00:10,  3.24it/s] 67%|██████▋   | 67/100 [00:20<00:09,  3.53it/s] 68%|██████▊   | 68/100 [00:21<00:08,  3.64it/s] 69%|██████▉   | 69/100 [00:21<00:09,  3.33it/s] 70%|███████   | 70/100 [00:21<00:10,  2.98it/s] 71%|███████   | 71/100 [00:22<00:08,  3.30it/s] 72%|███████▏  | 72/100 [00:22<00:08,  3.45it/s] 73%|███████▎  | 73/100 [00:22<00:09,  2.99it/s] 74%|███████▍  | 74/100 [00:23<00:09,  2.65it/s] 75%|███████▌  | 75/100 [00:23<00:10,  2.45it/s] 76%|███████▌  | 76/100 [00:23<00:08,  2.84it/s] 77%|███████▋  | 77/100 [00:24<00:07,  2.97it/s] 78%|███████▊  | 78/100 [00:24<00:06,  3.21it/s] 79%|███████▉  | 79/100 [00:24<00:05,  3.66it/s] 80%|████████  | 80/100 [00:25<00:05,  3.48it/s] 81%|████████  | 81/100 [00:25<00:05,  3.61it/s] 82%|████████▏ | 82/100 [00:25<00:04,  3.81it/s] 83%|████████▎ | 83/100 [00:25<00:04,  3.48it/s] 84%|████████▍ | 84/100 [00:26<00:04,  3.64it/s] 85%|████████▌ | 85/100 [00:26<00:03,  3.83it/s] 86%|████████▌ | 86/100 [00:26<00:03,  3.62it/s] 87%|████████▋ | 87/100 [00:26<00:03,  4.20it/s] 88%|████████▊ | 88/100 [00:26<00:02,  4.81it/s] 89%|████████▉ | 89/100 [00:27<00:02,  4.57it/s] 90%|█████████ | 90/100 [00:27<00:01,  5.18it/s] 91%|█████████ | 91/100 [00:27<00:02,  4.29it/s] 92%|█████████▏| 92/100 [00:28<00:02,  3.58it/s] 93%|█████████▎| 93/100 [00:28<00:02,  3.27it/s] 94%|█████████▍| 94/100 [00:28<00:01,  3.56it/s] 95%|█████████▌| 95/100 [00:28<00:01,  3.31it/s] 96%|█████████▌| 96/100 [00:29<00:01,  3.60it/s] 97%|█████████▋| 97/100 [00:29<00:00,  3.69it/s] 98%|█████████▊| 98/100 [00:29<00:00,  3.64it/s] 99%|█████████▉| 99/100 [00:29<00:00,  3.73it/s]100%|██████████| 100/100 [00:30<00:00,  3.79it/s]100%|██████████| 100/100 [00:30<00:00,  3.31it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00777, 0.00777
--- total mse / var(X): 0.00777
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.225, 0.225
--- total mse / var(X): 0.225
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.162, 0.162
--- total mse / var(X): 0.162
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0442, 0.0442
--- total mse / var(X): 0.0442
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.193, 0.193
--- total mse / var(X): 0.193
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:07, 12.76it/s]  4%|▍         | 4/100 [00:00<00:07, 13.58it/s]  7%|▋         | 7/100 [00:00<00:06, 14.60it/s]  9%|▉         | 9/100 [00:00<00:08, 11.04it/s] 11%|█         | 11/100 [00:00<00:08, 11.12it/s] 13%|█▎        | 13/100 [00:01<00:07, 11.18it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.24it/s] 17%|█▋        | 17/100 [00:01<00:11,  7.19it/s] 19%|█▉        | 19/100 [00:01<00:09,  8.85it/s] 22%|██▏       | 22/100 [00:02<00:06, 11.75it/s] 24%|██▍       | 24/100 [00:02<00:06, 11.31it/s] 26%|██▌       | 26/100 [00:02<00:07,  9.81it/s] 28%|██▊       | 28/100 [00:02<00:06, 10.34it/s] 30%|███       | 30/100 [00:03<00:08,  8.31it/s] 31%|███       | 31/100 [00:03<00:08,  8.09it/s] 32%|███▏      | 32/100 [00:03<00:08,  7.86it/s] 34%|███▍      | 34/100 [00:03<00:06, 10.05it/s] 37%|███▋      | 37/100 [00:03<00:04, 13.66it/s] 40%|████      | 40/100 [00:03<00:03, 17.25it/s] 43%|████▎     | 43/100 [00:04<00:04, 13.07it/s] 45%|████▌     | 45/100 [00:04<00:06,  8.85it/s] 47%|████▋     | 47/100 [00:04<00:06,  8.81it/s] 49%|████▉     | 49/100 [00:04<00:06,  8.34it/s] 51%|█████     | 51/100 [00:05<00:05,  8.75it/s] 54%|█████▍    | 54/100 [00:05<00:03, 11.85it/s] 58%|█████▊    | 58/100 [00:05<00:03, 13.89it/s] 60%|██████    | 60/100 [00:05<00:02, 14.56it/s] 64%|██████▍   | 64/100 [00:05<00:01, 18.40it/s] 68%|██████▊   | 68/100 [00:05<00:01, 21.60it/s] 71%|███████   | 71/100 [00:05<00:01, 23.43it/s] 75%|███████▌  | 75/100 [00:06<00:00, 25.62it/s] 79%|███████▉  | 79/100 [00:06<00:00, 27.04it/s] 83%|████████▎ | 83/100 [00:06<00:00, 28.29it/s] 86%|████████▌ | 86/100 [00:06<00:00, 25.22it/s] 90%|█████████ | 90/100 [00:06<00:00, 27.94it/s] 94%|█████████▍| 94/100 [00:06<00:00, 29.98it/s] 98%|█████████▊| 98/100 [00:06<00:00, 31.59it/s]100%|██████████| 100/100 [00:06<00:00, 14.51it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 5.93e-05, 5.93e-05
--- total mse / var(X): 5.93e-05
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.99it/s]  3%|▎         | 3/100 [00:00<00:09,  9.88it/s]  5%|▌         | 5/100 [00:00<00:07, 11.90it/s]  7%|▋         | 7/100 [00:00<00:08, 10.85it/s]  9%|▉         | 9/100 [00:00<00:07, 12.54it/s] 11%|█         | 11/100 [00:00<00:07, 11.79it/s] 13%|█▎        | 13/100 [00:01<00:07, 11.10it/s] 15%|█▌        | 15/100 [00:01<00:07, 10.89it/s] 17%|█▋        | 17/100 [00:01<00:07, 11.74it/s] 19%|█▉        | 19/100 [00:01<00:08,  9.24it/s] 22%|██▏       | 22/100 [00:01<00:06, 12.20it/s] 25%|██▌       | 25/100 [00:02<00:04, 15.35it/s] 29%|██▉       | 29/100 [00:02<00:03, 19.27it/s] 32%|███▏      | 32/100 [00:02<00:03, 19.99it/s] 35%|███▌      | 35/100 [00:02<00:05, 12.84it/s] 37%|███▋      | 37/100 [00:02<00:05, 11.83it/s] 39%|███▉      | 39/100 [00:03<00:04, 12.74it/s] 41%|████      | 41/100 [00:03<00:07,  8.37it/s] 43%|████▎     | 43/100 [00:03<00:06,  8.67it/s] 45%|████▌     | 45/100 [00:03<00:06,  9.11it/s] 47%|████▋     | 47/100 [00:04<00:05,  9.81it/s] 49%|████▉     | 49/100 [00:04<00:05,  9.97it/s] 51%|█████     | 51/100 [00:04<00:04, 11.57it/s] 54%|█████▍    | 54/100 [00:04<00:03, 15.08it/s] 56%|█████▌    | 56/100 [00:04<00:02, 16.05it/s] 58%|█████▊    | 58/100 [00:04<00:02, 16.10it/s] 60%|██████    | 60/100 [00:04<00:02, 16.63it/s] 64%|██████▍   | 64/100 [00:04<00:01, 21.38it/s] 67%|██████▋   | 67/100 [00:05<00:01, 22.01it/s] 71%|███████   | 71/100 [00:05<00:01, 26.18it/s] 74%|███████▍  | 74/100 [00:05<00:00, 26.24it/s] 77%|███████▋  | 77/100 [00:05<00:00, 23.28it/s] 81%|████████  | 81/100 [00:05<00:00, 26.30it/s] 86%|████████▌ | 86/100 [00:05<00:00, 30.47it/s] 90%|█████████ | 90/100 [00:05<00:00, 30.27it/s] 94%|█████████▍| 94/100 [00:05<00:00, 31.65it/s] 98%|█████████▊| 98/100 [00:06<00:00, 33.55it/s]100%|██████████| 100/100 [00:06<00:00, 16.34it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00825, 0.00825
--- total mse / var(X): 0.00825
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  2%|▏         | 2/100 [00:00<00:06, 16.20it/s]  5%|▌         | 5/100 [00:00<00:04, 21.88it/s]  9%|▉         | 9/100 [00:00<00:03, 27.92it/s] 13%|█▎        | 13/100 [00:00<00:02, 30.87it/s] 17%|█▋        | 17/100 [00:00<00:02, 32.82it/s] 21%|██        | 21/100 [00:00<00:02, 34.01it/s] 25%|██▌       | 25/100 [00:00<00:02, 34.69it/s] 29%|██▉       | 29/100 [00:00<00:02, 35.07it/s] 33%|███▎      | 33/100 [00:01<00:01, 35.84it/s] 37%|███▋      | 37/100 [00:01<00:01, 36.34it/s] 41%|████      | 41/100 [00:01<00:01, 32.10it/s] 45%|████▌     | 45/100 [00:01<00:01, 32.40it/s] 49%|████▉     | 49/100 [00:01<00:01, 32.22it/s] 53%|█████▎    | 53/100 [00:01<00:02, 21.91it/s] 56%|█████▌    | 56/100 [00:02<00:02, 17.09it/s] 59%|█████▉    | 59/100 [00:02<00:02, 14.41it/s] 63%|██████▎   | 63/100 [00:02<00:02, 17.69it/s] 67%|██████▋   | 67/100 [00:02<00:01, 20.90it/s] 70%|███████   | 70/100 [00:02<00:01, 22.61it/s] 73%|███████▎  | 73/100 [00:02<00:01, 20.78it/s] 77%|███████▋  | 77/100 [00:03<00:01, 21.89it/s] 80%|████████  | 80/100 [00:03<00:01, 16.26it/s] 82%|████████▏ | 82/100 [00:03<00:01, 15.40it/s] 85%|████████▌ | 85/100 [00:03<00:01, 12.51it/s] 87%|████████▋ | 87/100 [00:04<00:01, 12.93it/s] 93%|█████████▎| 93/100 [00:04<00:00, 20.28it/s] 98%|█████████▊| 98/100 [00:04<00:00, 25.81it/s]100%|██████████| 100/100 [00:04<00:00, 22.79it/s]
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.000653, 0.000653
--- total mse / var(X): 0.000653
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:11,  8.66it/s]  3%|▎         | 3/100 [00:00<00:08, 11.89it/s]  5%|▌         | 5/100 [00:00<00:06, 14.07it/s]  7%|▋         | 7/100 [00:00<00:06, 14.84it/s]  9%|▉         | 9/100 [00:00<00:05, 15.72it/s] 11%|█         | 11/100 [00:00<00:07, 12.32it/s] 13%|█▎        | 13/100 [00:01<00:07, 12.22it/s] 15%|█▌        | 15/100 [00:01<00:06, 13.22it/s] 17%|█▋        | 17/100 [00:01<00:05, 14.51it/s] 20%|██        | 20/100 [00:01<00:05, 14.40it/s] 23%|██▎       | 23/100 [00:01<00:04, 16.29it/s] 26%|██▌       | 26/100 [00:01<00:04, 17.34it/s] 28%|██▊       | 28/100 [00:02<00:06, 11.56it/s] 31%|███       | 31/100 [00:02<00:04, 13.95it/s] 34%|███▍      | 34/100 [00:02<00:04, 16.28it/s] 36%|███▌      | 36/100 [00:02<00:04, 15.22it/s] 38%|███▊      | 38/100 [00:02<00:04, 14.05it/s] 40%|████      | 40/100 [00:02<00:04, 14.25it/s] 42%|████▏     | 42/100 [00:03<00:04, 12.00it/s] 44%|████▍     | 44/100 [00:03<00:04, 13.48it/s] 47%|████▋     | 47/100 [00:03<00:03, 16.42it/s] 50%|█████     | 50/100 [00:03<00:02, 19.14it/s] 53%|█████▎    | 53/100 [00:03<00:02, 20.56it/s] 56%|█████▌    | 56/100 [00:03<00:02, 17.32it/s] 59%|█████▉    | 59/100 [00:03<00:02, 19.73it/s] 62%|██████▏   | 62/100 [00:04<00:03, 10.91it/s] 65%|██████▌   | 65/100 [00:04<00:02, 13.52it/s] 68%|██████▊   | 68/100 [00:04<00:02, 13.80it/s] 72%|███████▏  | 72/100 [00:04<00:01, 17.66it/s] 75%|███████▌  | 75/100 [00:04<00:01, 18.72it/s] 78%|███████▊  | 78/100 [00:05<00:01, 20.14it/s] 81%|████████  | 81/100 [00:05<00:01, 15.11it/s] 84%|████████▍ | 84/100 [00:05<00:01, 14.27it/s] 86%|████████▌ | 86/100 [00:05<00:01, 11.76it/s] 88%|████████▊ | 88/100 [00:06<00:01,  9.91it/s] 91%|█████████ | 91/100 [00:06<00:00, 10.60it/s] 93%|█████████▎| 93/100 [00:06<00:00, 11.54it/s] 97%|█████████▋| 97/100 [00:06<00:00, 15.65it/s]100%|██████████| 100/100 [00:06<00:00, 14.70it/s]
/data/neelesh/DART_by_app/462/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/462/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
Retrain for 100 epochs
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0904, 0.0904
--- total mse / var(X): 0.0904
start table evaluation...
Elapsed time: 300.00700330734253 seconds
Cosine similarity between AMM and exact (Train): 0.99999976
Cosine similarity between AMM and exact (Test): 1.0000007
p,r,f1: 0.9830537893682311 0.9999998484422286 0.9914544131687777
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.9830537893682311, 0.9999998484422286, 0.9914544131687777],
           'num_param': 7424},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16],
               'cossim_layer_train': [0.990034818649292,
                                      0.9968215823173523,
                                      0.9969795346260071,
                                      0.9999997615814209],
               'cossim_layer_test': [0.9739752411842346,
                                     0.9931226968765259,
                                     0.9938768744468689,
                                     1.0000007152557373],
               'cossim_amm_train': [0.97807776927948,
                                    0.9957431554794312,
                                    0.8766328692436218,
                                    0.913790225982666,
                                    0.9869794845581055,
                                    0.9938945174217224,
                                    0.9954649806022644,
                                    0.9999867081642151],
               'cossim_amm_test': [0.9429786801338196,
                                   0.9940813183784485,
                                   0.8748698830604553,
                                   0.9102275967597961,
                                   0.9822789430618286,
                                   0.9903310537338257,
                                   0.9918966889381409,
                                   0.9999694228172302],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 8,
               'lut_shapes': [(16, 1, 16),
                              (96, 1, 16),
                              (16, 16, 1),
                              (16, 16, 1),
                              (16, 1, 16),
                              (16, 1, 16),
                              (16, 1, 16),
                              (256, 1, 16)],
               'lut_total_size': 7168}}

Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00291, 0.00296
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00289, 0.00284
--- total mse / var(X): 0.0029
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00246, 0.00255
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00254, 0.00245
--- total mse / var(X): 0.0025
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00279, 0.0027
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00247, 0.00255
--- total mse / var(X): 0.00263
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00062, 0.00101
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00269, 0.000991
--- total mse / var(X): 0.001
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00203, 0.002
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00348, 0.00352
--- total mse / var(X): 0.00276
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:20,  4.86it/s]  2%|▏         | 2/100 [00:00<00:24,  3.97it/s]  3%|▎         | 3/100 [00:00<00:22,  4.40it/s]  4%|▍         | 4/100 [00:00<00:23,  4.11it/s]  5%|▌         | 5/100 [00:01<00:21,  4.48it/s]  6%|▌         | 6/100 [00:01<00:19,  4.77it/s]  7%|▋         | 7/100 [00:01<00:21,  4.32it/s]  8%|▊         | 8/100 [00:01<00:20,  4.43it/s]  9%|▉         | 9/100 [00:02<00:20,  4.50it/s] 10%|█         | 10/100 [00:02<00:17,  5.04it/s] 11%|█         | 11/100 [00:02<00:20,  4.27it/s] 12%|█▏        | 12/100 [00:02<00:23,  3.73it/s] 13%|█▎        | 13/100 [00:03<00:22,  3.87it/s] 14%|█▍        | 14/100 [00:03<00:20,  4.17it/s] 15%|█▌        | 15/100 [00:03<00:19,  4.30it/s] 16%|█▌        | 16/100 [00:03<00:18,  4.60it/s] 17%|█▋        | 17/100 [00:03<00:17,  4.88it/s] 18%|█▊        | 18/100 [00:04<00:19,  4.17it/s] 19%|█▉        | 19/100 [00:04<00:18,  4.28it/s] 20%|██        | 20/100 [00:04<00:17,  4.65it/s] 21%|██        | 21/100 [00:04<00:20,  3.90it/s] 22%|██▏       | 22/100 [00:05<00:18,  4.28it/s] 23%|██▎       | 23/100 [00:05<00:17,  4.53it/s] 24%|██▍       | 24/100 [00:05<00:20,  3.70it/s] 25%|██▌       | 25/100 [00:05<00:20,  3.63it/s] 26%|██▌       | 26/100 [00:06<00:18,  4.03it/s] 27%|██▋       | 27/100 [00:06<00:17,  4.16it/s] 28%|██▊       | 28/100 [00:06<00:19,  3.65it/s] 29%|██▉       | 29/100 [00:06<00:17,  3.99it/s] 30%|███       | 30/100 [00:07<00:18,  3.76it/s] 31%|███       | 31/100 [00:07<00:18,  3.83it/s] 32%|███▏      | 32/100 [00:07<00:18,  3.67it/s] 33%|███▎      | 33/100 [00:07<00:15,  4.19it/s] 34%|███▍      | 34/100 [00:08<00:14,  4.50it/s] 35%|███▌      | 35/100 [00:08<00:13,  4.71it/s] 36%|███▌      | 36/100 [00:08<00:13,  4.69it/s] 37%|███▋      | 37/100 [00:08<00:12,  4.94it/s] 38%|███▊      | 38/100 [00:08<00:12,  4.81it/s] 39%|███▉      | 39/100 [00:09<00:11,  5.09it/s] 40%|████      | 40/100 [00:09<00:12,  4.67it/s] 41%|████      | 41/100 [00:09<00:13,  4.45it/s] 42%|████▏     | 42/100 [00:09<00:13,  4.25it/s] 43%|████▎     | 43/100 [00:10<00:13,  4.23it/s] 44%|████▍     | 44/100 [00:10<00:13,  4.07it/s] 45%|████▌     | 45/100 [00:10<00:14,  3.90it/s] 46%|████▌     | 46/100 [00:10<00:12,  4.22it/s] 47%|████▋     | 47/100 [00:11<00:12,  4.29it/s] 48%|████▊     | 48/100 [00:11<00:12,  4.25it/s] 49%|████▉     | 49/100 [00:11<00:10,  4.73it/s] 50%|█████     | 50/100 [00:11<00:10,  4.95it/s] 51%|█████     | 51/100 [00:11<00:11,  4.29it/s] 52%|█████▏    | 52/100 [00:12<00:11,  4.34it/s] 53%|█████▎    | 53/100 [00:12<00:10,  4.40it/s] 54%|█████▍    | 54/100 [00:12<00:09,  4.77it/s] 55%|█████▌    | 55/100 [00:12<00:09,  4.82it/s] 56%|█████▌    | 56/100 [00:12<00:08,  4.90it/s] 57%|█████▋    | 57/100 [00:13<00:08,  4.86it/s] 58%|█████▊    | 58/100 [00:13<00:08,  4.84it/s] 59%|█████▉    | 59/100 [00:13<00:09,  4.27it/s] 60%|██████    | 60/100 [00:13<00:09,  4.19it/s] 61%|██████    | 61/100 [00:14<00:09,  4.18it/s] 62%|██████▏   | 62/100 [00:14<00:08,  4.39it/s] 63%|██████▎   | 63/100 [00:14<00:08,  4.58it/s] 64%|██████▍   | 64/100 [00:14<00:07,  4.73it/s] 65%|██████▌   | 65/100 [00:14<00:06,  5.13it/s] 66%|██████▌   | 66/100 [00:15<00:06,  5.32it/s] 67%|██████▋   | 67/100 [00:15<00:06,  5.39it/s] 68%|██████▊   | 68/100 [00:15<00:05,  5.44it/s] 69%|██████▉   | 69/100 [00:15<00:05,  5.33it/s] 70%|███████   | 70/100 [00:15<00:06,  4.82it/s] 71%|███████   | 71/100 [00:16<00:05,  5.15it/s] 72%|███████▏  | 72/100 [00:16<00:05,  5.31it/s] 73%|███████▎  | 73/100 [00:16<00:05,  5.19it/s] 74%|███████▍  | 74/100 [00:16<00:04,  5.33it/s] 75%|███████▌  | 75/100 [00:16<00:04,  5.25it/s] 76%|███████▌  | 76/100 [00:17<00:04,  5.03it/s] 77%|███████▋  | 77/100 [00:17<00:04,  5.40it/s] 78%|███████▊  | 78/100 [00:17<00:04,  4.98it/s] 79%|███████▉  | 79/100 [00:17<00:04,  4.85it/s] 80%|████████  | 80/100 [00:17<00:03,  5.03it/s] 81%|████████  | 81/100 [00:18<00:04,  4.29it/s] 82%|████████▏ | 82/100 [00:18<00:04,  4.18it/s] 83%|████████▎ | 83/100 [00:18<00:04,  4.04it/s] 84%|████████▍ | 84/100 [00:18<00:04,  3.82it/s] 85%|████████▌ | 85/100 [00:19<00:03,  4.34it/s] 86%|████████▌ | 86/100 [00:19<00:03,  4.44it/s] 87%|████████▋ | 87/100 [00:19<00:02,  4.45it/s] 88%|████████▊ | 88/100 [00:19<00:02,  4.88it/s] 89%|████████▉ | 89/100 [00:19<00:02,  5.43it/s] 90%|█████████ | 90/100 [00:20<00:02,  4.70it/s] 91%|█████████ | 91/100 [00:20<00:01,  4.89it/s] 92%|█████████▏| 92/100 [00:20<00:01,  5.06it/s] 93%|█████████▎| 93/100 [00:20<00:01,  5.21it/s] 94%|█████████▍| 94/100 [00:20<00:01,  4.63it/s] 95%|█████████▌| 95/100 [00:21<00:01,  4.68it/s] 96%|█████████▌| 96/100 [00:21<00:00,  4.98it/s] 97%|█████████▋| 97/100 [00:21<00:00,  5.03it/s] 98%|█████████▊| 98/100 [00:21<00:00,  4.62it/s] 99%|█████████▉| 99/100 [00:21<00:00,  4.58it/s]100%|██████████| 100/100 [00:22<00:00,  4.71it/s]100%|██████████| 100/100 [00:22<00:00,  4.51it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0146, 0.0155
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0166, 0.0157
--- total mse / var(X): 0.0156
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.17it/s]  2%|▏         | 2/100 [00:00<00:13,  7.28it/s]  4%|▍         | 4/100 [00:00<00:12,  7.79it/s]  5%|▌         | 5/100 [00:00<00:13,  6.94it/s]  6%|▌         | 6/100 [00:00<00:13,  7.18it/s]  7%|▋         | 7/100 [00:00<00:12,  7.72it/s]  8%|▊         | 8/100 [00:01<00:12,  7.67it/s]  9%|▉         | 9/100 [00:01<00:12,  7.45it/s] 10%|█         | 10/100 [00:01<00:11,  7.85it/s] 11%|█         | 11/100 [00:01<00:11,  7.70it/s] 12%|█▏        | 12/100 [00:01<00:11,  7.94it/s] 14%|█▍        | 14/100 [00:01<00:10,  8.48it/s] 16%|█▌        | 16/100 [00:01<00:08,  9.90it/s] 17%|█▋        | 17/100 [00:02<00:08,  9.60it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.52it/s] 20%|██        | 20/100 [00:02<00:08,  9.42it/s] 22%|██▏       | 22/100 [00:02<00:07, 10.18it/s] 24%|██▍       | 24/100 [00:02<00:07, 10.14it/s] 26%|██▌       | 26/100 [00:02<00:07, 10.42it/s] 28%|██▊       | 28/100 [00:03<00:06, 10.37it/s] 30%|███       | 30/100 [00:03<00:06, 10.21it/s] 32%|███▏      | 32/100 [00:03<00:06,  9.83it/s] 33%|███▎      | 33/100 [00:03<00:06,  9.59it/s] 34%|███▍      | 34/100 [00:03<00:06,  9.61it/s] 35%|███▌      | 35/100 [00:03<00:07,  8.44it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.56it/s] 37%|███▋      | 37/100 [00:04<00:10,  5.97it/s] 38%|███▊      | 38/100 [00:04<00:09,  6.35it/s] 39%|███▉      | 39/100 [00:04<00:08,  6.78it/s] 41%|████      | 41/100 [00:04<00:07,  7.44it/s] 42%|████▏     | 42/100 [00:05<00:08,  7.02it/s] 43%|████▎     | 43/100 [00:05<00:08,  7.10it/s] 44%|████▍     | 44/100 [00:05<00:07,  7.63it/s] 45%|████▌     | 45/100 [00:05<00:07,  7.34it/s] 46%|████▌     | 46/100 [00:05<00:06,  7.82it/s] 48%|████▊     | 48/100 [00:05<00:05,  9.26it/s] 49%|████▉     | 49/100 [00:05<00:05,  9.14it/s] 51%|█████     | 51/100 [00:05<00:05,  9.76it/s] 52%|█████▏    | 52/100 [00:06<00:05,  8.69it/s] 54%|█████▍    | 54/100 [00:06<00:05,  8.91it/s] 55%|█████▌    | 55/100 [00:06<00:06,  7.01it/s] 56%|█████▌    | 56/100 [00:06<00:05,  7.45it/s] 57%|█████▋    | 57/100 [00:06<00:05,  7.91it/s] 58%|█████▊    | 58/100 [00:06<00:05,  7.93it/s] 59%|█████▉    | 59/100 [00:07<00:05,  7.71it/s] 60%|██████    | 60/100 [00:07<00:05,  7.30it/s] 61%|██████    | 61/100 [00:07<00:05,  7.68it/s] 63%|██████▎   | 63/100 [00:07<00:04,  8.69it/s] 64%|██████▍   | 64/100 [00:07<00:04,  8.60it/s] 65%|██████▌   | 65/100 [00:07<00:03,  8.92it/s] 66%|██████▌   | 66/100 [00:07<00:03,  9.06it/s] 67%|██████▋   | 67/100 [00:07<00:03,  8.91it/s] 69%|██████▉   | 69/100 [00:08<00:02, 10.68it/s] 71%|███████   | 71/100 [00:08<00:03,  8.94it/s] 72%|███████▏  | 72/100 [00:08<00:03,  8.74it/s] 73%|███████▎  | 73/100 [00:08<00:03,  8.81it/s] 74%|███████▍  | 74/100 [00:08<00:03,  8.38it/s] 76%|███████▌  | 76/100 [00:08<00:02,  8.88it/s] 77%|███████▋  | 77/100 [00:09<00:02,  8.74it/s] 78%|███████▊  | 78/100 [00:09<00:02,  7.92it/s] 79%|███████▉  | 79/100 [00:09<00:02,  8.17it/s] 80%|████████  | 80/100 [00:09<00:02,  8.49it/s] 81%|████████  | 81/100 [00:09<00:02,  8.80it/s] 82%|████████▏ | 82/100 [00:09<00:02,  8.85it/s] 83%|████████▎ | 83/100 [00:09<00:01,  8.51it/s] 84%|████████▍ | 84/100 [00:09<00:01,  8.53it/s] 85%|████████▌ | 85/100 [00:10<00:01,  8.05it/s] 86%|████████▌ | 86/100 [00:10<00:01,  8.02it/s] 87%|████████▋ | 87/100 [00:10<00:01,  8.08it/s] 88%|████████▊ | 88/100 [00:10<00:01,  8.07it/s] 89%|████████▉ | 89/100 [00:10<00:01,  8.17it/s] 90%|█████████ | 90/100 [00:10<00:01,  8.25it/s] 91%|█████████ | 91/100 [00:10<00:01,  8.38it/s] 92%|█████████▏| 92/100 [00:10<00:00,  8.23it/s] 93%|█████████▎| 93/100 [00:11<00:00,  7.70it/s] 94%|█████████▍| 94/100 [00:11<00:00,  7.57it/s] 95%|█████████▌| 95/100 [00:11<00:00,  7.28it/s] 96%|█████████▌| 96/100 [00:11<00:00,  6.89it/s] 97%|█████████▋| 97/100 [00:11<00:00,  6.34it/s] 98%|█████████▊| 98/100 [00:11<00:00,  6.46it/s] 99%|█████████▉| 99/100 [00:11<00:00,  6.98it/s]100%|██████████| 100/100 [00:12<00:00,  8.28it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0038, 0.00378
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00317, 0.00318
--- total mse / var(X): 0.00348
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:23,  4.24it/s]  2%|▏         | 2/100 [00:00<00:19,  5.13it/s]  3%|▎         | 3/100 [00:00<00:16,  5.92it/s]  4%|▍         | 4/100 [00:00<00:15,  6.32it/s]  5%|▌         | 5/100 [00:00<00:13,  6.84it/s]  6%|▌         | 6/100 [00:00<00:13,  7.23it/s]  8%|▊         | 8/100 [00:01<00:12,  7.27it/s]  9%|▉         | 9/100 [00:01<00:15,  5.77it/s] 10%|█         | 10/100 [00:01<00:16,  5.34it/s] 11%|█         | 11/100 [00:01<00:15,  5.92it/s] 12%|█▏        | 12/100 [00:02<00:15,  5.82it/s] 13%|█▎        | 13/100 [00:02<00:13,  6.27it/s] 15%|█▌        | 15/100 [00:02<00:11,  7.24it/s] 16%|█▌        | 16/100 [00:02<00:12,  6.73it/s] 17%|█▋        | 17/100 [00:02<00:12,  6.66it/s] 19%|█▉        | 19/100 [00:02<00:09,  8.39it/s] 21%|██        | 21/100 [00:03<00:08,  9.18it/s] 22%|██▏       | 22/100 [00:03<00:09,  8.56it/s] 23%|██▎       | 23/100 [00:03<00:08,  8.63it/s] 24%|██▍       | 24/100 [00:03<00:08,  8.62it/s] 25%|██▌       | 25/100 [00:03<00:09,  8.27it/s] 26%|██▌       | 26/100 [00:03<00:09,  8.14it/s] 28%|██▊       | 28/100 [00:03<00:07,  9.45it/s] 30%|███       | 30/100 [00:04<00:06, 10.34it/s] 32%|███▏      | 32/100 [00:04<00:08,  8.11it/s] 34%|███▍      | 34/100 [00:04<00:07,  9.14it/s] 35%|███▌      | 35/100 [00:04<00:07,  8.47it/s] 36%|███▌      | 36/100 [00:04<00:07,  8.67it/s] 38%|███▊      | 38/100 [00:04<00:06,  9.14it/s] 39%|███▉      | 39/100 [00:05<00:07,  8.36it/s] 40%|████      | 40/100 [00:05<00:07,  7.84it/s] 41%|████      | 41/100 [00:05<00:07,  7.78it/s] 43%|████▎     | 43/100 [00:05<00:05,  9.65it/s] 45%|████▌     | 45/100 [00:05<00:04, 11.48it/s] 47%|████▋     | 47/100 [00:05<00:04, 12.26it/s] 49%|████▉     | 49/100 [00:05<00:03, 13.70it/s] 51%|█████     | 51/100 [00:06<00:03, 12.54it/s] 53%|█████▎    | 53/100 [00:06<00:03, 13.54it/s] 55%|█████▌    | 55/100 [00:06<00:04, 10.66it/s] 57%|█████▋    | 57/100 [00:06<00:04, 10.72it/s] 59%|█████▉    | 59/100 [00:06<00:04,  9.06it/s] 61%|██████    | 61/100 [00:07<00:04,  8.93it/s] 62%|██████▏   | 62/100 [00:07<00:04,  7.62it/s] 63%|██████▎   | 63/100 [00:07<00:05,  7.17it/s] 64%|██████▍   | 64/100 [00:07<00:05,  6.83it/s] 65%|██████▌   | 65/100 [00:07<00:05,  6.49it/s] 66%|██████▌   | 66/100 [00:08<00:04,  6.89it/s] 67%|██████▋   | 67/100 [00:08<00:04,  7.45it/s] 68%|██████▊   | 68/100 [00:08<00:04,  7.55it/s] 69%|██████▉   | 69/100 [00:08<00:04,  7.59it/s] 70%|███████   | 70/100 [00:08<00:03,  7.62it/s] 71%|███████   | 71/100 [00:08<00:03,  7.47it/s] 72%|███████▏  | 72/100 [00:08<00:03,  7.28it/s] 73%|███████▎  | 73/100 [00:09<00:03,  7.09it/s] 74%|███████▍  | 74/100 [00:09<00:03,  7.15it/s] 75%|███████▌  | 75/100 [00:09<00:03,  6.98it/s] 76%|███████▌  | 76/100 [00:09<00:03,  6.86it/s] 77%|███████▋  | 77/100 [00:09<00:03,  6.81it/s] 78%|███████▊  | 78/100 [00:09<00:03,  6.75it/s] 79%|███████▉  | 79/100 [00:09<00:03,  6.34it/s] 80%|████████  | 80/100 [00:10<00:03,  5.79it/s] 81%|████████  | 81/100 [00:10<00:03,  6.20it/s] 83%|████████▎ | 83/100 [00:10<00:02,  7.67it/s] 84%|████████▍ | 84/100 [00:10<00:02,  7.75it/s] 86%|████████▌ | 86/100 [00:10<00:01,  9.11it/s] 88%|████████▊ | 88/100 [00:10<00:01, 10.59it/s] 90%|█████████ | 90/100 [00:11<00:00, 12.11it/s] 92%|█████████▏| 92/100 [00:11<00:00, 13.72it/s] 94%|█████████▍| 94/100 [00:11<00:00, 14.87it/s] 96%|█████████▌| 96/100 [00:11<00:00, 15.41it/s] 99%|█████████▉| 99/100 [00:11<00:00, 17.38it/s]100%|██████████| 100/100 [00:11<00:00,  8.65it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00214, 0.00167
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00184, 0.00224
--- total mse / var(X): 0.00196
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<01:13,  1.34it/s]  2%|▏         | 2/100 [00:01<01:18,  1.25it/s]  3%|▎         | 3/100 [00:02<01:12,  1.33it/s]  4%|▍         | 4/100 [00:02<01:09,  1.38it/s]  5%|▌         | 5/100 [00:03<01:07,  1.40it/s]  6%|▌         | 6/100 [00:04<01:05,  1.44it/s]  7%|▋         | 7/100 [00:04<01:03,  1.46it/s]  8%|▊         | 8/100 [00:05<01:01,  1.49it/s]  9%|▉         | 9/100 [00:06<00:58,  1.55it/s] 10%|█         | 10/100 [00:06<00:56,  1.61it/s] 11%|█         | 11/100 [00:07<00:54,  1.62it/s] 12%|█▏        | 12/100 [00:07<00:53,  1.63it/s] 13%|█▎        | 13/100 [00:08<00:54,  1.60it/s] 14%|█▍        | 14/100 [00:09<00:54,  1.59it/s] 15%|█▌        | 15/100 [00:09<00:54,  1.56it/s] 16%|█▌        | 16/100 [00:10<00:53,  1.56it/s] 17%|█▋        | 17/100 [00:11<00:52,  1.57it/s] 18%|█▊        | 18/100 [00:11<00:54,  1.51it/s] 19%|█▉        | 19/100 [00:12<00:51,  1.56it/s] 20%|██        | 20/100 [00:13<00:48,  1.66it/s] 21%|██        | 21/100 [00:13<00:46,  1.69it/s] 22%|██▏       | 22/100 [00:14<00:46,  1.68it/s] 23%|██▎       | 23/100 [00:14<00:46,  1.66it/s] 24%|██▍       | 24/100 [00:15<00:46,  1.64it/s] 25%|██▌       | 25/100 [00:16<00:44,  1.67it/s] 26%|██▌       | 26/100 [00:16<00:44,  1.68it/s] 27%|██▋       | 27/100 [00:17<00:42,  1.71it/s] 28%|██▊       | 28/100 [00:17<00:43,  1.67it/s] 29%|██▉       | 29/100 [00:18<00:42,  1.67it/s] 30%|███       | 30/100 [00:19<00:42,  1.65it/s] 31%|███       | 31/100 [00:19<00:41,  1.66it/s] 32%|███▏      | 32/100 [00:20<00:42,  1.61it/s] 33%|███▎      | 33/100 [00:20<00:41,  1.62it/s] 34%|███▍      | 34/100 [00:21<00:42,  1.54it/s] 35%|███▌      | 35/100 [00:22<00:40,  1.62it/s] 36%|███▌      | 36/100 [00:22<00:37,  1.69it/s] 37%|███▋      | 37/100 [00:23<00:36,  1.74it/s] 38%|███▊      | 38/100 [00:23<00:34,  1.80it/s] 39%|███▉      | 39/100 [00:24<00:32,  1.88it/s] 40%|████      | 40/100 [00:24<00:32,  1.86it/s] 41%|████      | 41/100 [00:25<00:32,  1.84it/s] 42%|████▏     | 42/100 [00:25<00:31,  1.86it/s] 43%|████▎     | 43/100 [00:26<00:30,  1.88it/s] 44%|████▍     | 44/100 [00:26<00:29,  1.91it/s] 45%|████▌     | 45/100 [00:27<00:28,  1.90it/s] 46%|████▌     | 46/100 [00:27<00:29,  1.85it/s] 47%|████▋     | 47/100 [00:28<00:34,  1.54it/s] 48%|████▊     | 48/100 [00:29<00:33,  1.56it/s] 49%|████▉     | 49/100 [00:30<00:33,  1.51it/s] 50%|█████     | 50/100 [00:30<00:32,  1.52it/s] 51%|█████     | 51/100 [00:31<00:32,  1.52it/s] 52%|█████▏    | 52/100 [00:32<00:31,  1.52it/s] 53%|█████▎    | 53/100 [00:32<00:32,  1.46it/s] 54%|█████▍    | 54/100 [00:33<00:29,  1.55it/s] 55%|█████▌    | 55/100 [00:34<00:28,  1.59it/s] 56%|█████▌    | 56/100 [00:34<00:27,  1.60it/s] 57%|█████▋    | 57/100 [00:35<00:29,  1.47it/s] 58%|█████▊    | 58/100 [00:36<00:27,  1.51it/s] 59%|█████▉    | 59/100 [00:36<00:26,  1.54it/s] 60%|██████    | 60/100 [00:37<00:24,  1.60it/s] 61%|██████    | 61/100 [00:37<00:25,  1.54it/s] 62%|██████▏   | 62/100 [00:38<00:23,  1.61it/s] 63%|██████▎   | 63/100 [00:39<00:22,  1.61it/s] 64%|██████▍   | 64/100 [00:39<00:23,  1.50it/s] 65%|██████▌   | 65/100 [00:40<00:22,  1.55it/s] 66%|██████▌   | 66/100 [00:41<00:20,  1.63it/s] 67%|██████▋   | 67/100 [00:41<00:20,  1.60it/s] 68%|██████▊   | 68/100 [00:42<00:21,  1.52it/s] 69%|██████▉   | 69/100 [00:43<00:19,  1.58it/s] 70%|███████   | 70/100 [00:43<00:18,  1.64it/s] 71%|███████   | 71/100 [00:44<00:17,  1.69it/s] 72%|███████▏  | 72/100 [00:44<00:15,  1.75it/s] 73%|███████▎  | 73/100 [00:45<00:14,  1.80it/s] 74%|███████▍  | 74/100 [00:45<00:14,  1.82it/s] 75%|███████▌  | 75/100 [00:46<00:13,  1.84it/s] 76%|███████▌  | 76/100 [00:46<00:13,  1.74it/s] 77%|███████▋  | 77/100 [00:47<00:13,  1.71it/s] 78%|███████▊  | 78/100 [00:48<00:13,  1.60it/s] 79%|███████▉  | 79/100 [00:49<00:14,  1.45it/s] 80%|████████  | 80/100 [00:49<00:13,  1.48it/s] 81%|████████  | 81/100 [00:50<00:11,  1.59it/s] 82%|████████▏ | 82/100 [00:50<00:11,  1.59it/s] 83%|████████▎ | 83/100 [00:51<00:10,  1.69it/s] 84%|████████▍ | 84/100 [00:51<00:08,  1.86it/s] 85%|████████▌ | 85/100 [00:52<00:07,  1.97it/s] 86%|████████▌ | 86/100 [00:52<00:06,  2.05it/s] 87%|████████▋ | 87/100 [00:53<00:06,  2.14it/s] 88%|████████▊ | 88/100 [00:53<00:05,  2.18it/s] 89%|████████▉ | 89/100 [00:53<00:04,  2.21it/s] 90%|█████████ | 90/100 [00:54<00:04,  2.19it/s] 91%|█████████ | 91/100 [00:54<00:04,  2.12it/s] 92%|█████████▏| 92/100 [00:55<00:04,  1.95it/s] 93%|█████████▎| 93/100 [00:55<00:03,  2.02it/s] 94%|█████████▍| 94/100 [00:56<00:02,  2.01it/s] 95%|█████████▌| 95/100 [00:56<00:02,  2.10it/s] 96%|█████████▌| 96/100 [00:57<00:01,  2.10it/s] 97%|█████████▋| 97/100 [00:57<00:01,  2.09it/s] 98%|█████████▊| 98/100 [00:58<00:00,  2.11it/s] 99%|█████████▉| 99/100 [00:58<00:00,  2.17it/s]100%|██████████| 100/100 [00:59<00:00,  2.15it/s]100%|██████████| 100/100 [00:59<00:00,  1.69it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00376, 0.00352
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00318, 0.00338
--- total mse / var(X): 0.00345
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00317, 0.00351
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0036, 0.00321
--- total mse / var(X): 0.00336
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00303, 0.00326
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0035, 0.00324
--- total mse / var(X): 0.00325
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00193, 0.00085
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000903, 0.00141
--- total mse / var(X): 0.00113
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00265, 0.00244
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00381, 0.00411
--- total mse / var(X): 0.00328
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.38it/s]  2%|▏         | 2/100 [00:00<00:11,  8.29it/s]  3%|▎         | 3/100 [00:00<00:11,  8.78it/s]  5%|▌         | 5/100 [00:00<00:09, 10.21it/s]  6%|▌         | 6/100 [00:00<00:10,  8.69it/s]  7%|▋         | 7/100 [00:00<00:11,  8.27it/s]  8%|▊         | 8/100 [00:00<00:12,  7.62it/s]  9%|▉         | 9/100 [00:01<00:12,  7.42it/s] 10%|█         | 10/100 [00:01<00:12,  7.30it/s] 11%|█         | 11/100 [00:01<00:12,  6.98it/s] 12%|█▏        | 12/100 [00:01<00:14,  6.21it/s] 13%|█▎        | 13/100 [00:01<00:13,  6.59it/s] 15%|█▌        | 15/100 [00:01<00:11,  7.69it/s] 16%|█▌        | 16/100 [00:02<00:10,  8.06it/s] 18%|█▊        | 18/100 [00:02<00:08,  9.22it/s] 20%|██        | 20/100 [00:02<00:08,  9.82it/s] 21%|██        | 21/100 [00:02<00:08,  9.80it/s] 23%|██▎       | 23/100 [00:02<00:07,  9.92it/s] 25%|██▌       | 25/100 [00:02<00:07, 10.51it/s] 27%|██▋       | 27/100 [00:03<00:11,  6.17it/s] 29%|██▉       | 29/100 [00:03<00:09,  7.14it/s] 31%|███       | 31/100 [00:03<00:08,  8.02it/s] 33%|███▎      | 33/100 [00:04<00:10,  6.66it/s] 34%|███▍      | 34/100 [00:04<00:10,  6.48it/s] 35%|███▌      | 35/100 [00:04<00:10,  6.40it/s] 36%|███▌      | 36/100 [00:04<00:09,  6.51it/s] 37%|███▋      | 37/100 [00:04<00:10,  6.16it/s] 38%|███▊      | 38/100 [00:05<00:10,  5.73it/s] 39%|███▉      | 39/100 [00:05<00:10,  5.65it/s] 40%|████      | 40/100 [00:05<00:10,  5.95it/s] 41%|████      | 41/100 [00:05<00:09,  6.15it/s] 42%|████▏     | 42/100 [00:05<00:09,  6.42it/s] 43%|████▎     | 43/100 [00:05<00:08,  6.85it/s] 44%|████▍     | 44/100 [00:06<00:07,  7.02it/s] 45%|████▌     | 45/100 [00:06<00:07,  7.10it/s] 46%|████▌     | 46/100 [00:06<00:07,  7.18it/s] 48%|████▊     | 48/100 [00:06<00:07,  6.96it/s] 49%|████▉     | 49/100 [00:06<00:08,  6.29it/s] 50%|█████     | 50/100 [00:06<00:07,  6.44it/s] 51%|█████     | 51/100 [00:07<00:07,  6.85it/s] 52%|█████▏    | 52/100 [00:07<00:07,  6.02it/s] 54%|█████▍    | 54/100 [00:07<00:06,  7.19it/s] 55%|█████▌    | 55/100 [00:07<00:06,  7.48it/s] 56%|█████▌    | 56/100 [00:07<00:06,  6.82it/s] 57%|█████▋    | 57/100 [00:07<00:06,  6.89it/s] 58%|█████▊    | 58/100 [00:08<00:06,  6.38it/s] 59%|█████▉    | 59/100 [00:08<00:06,  6.57it/s] 60%|██████    | 60/100 [00:08<00:05,  6.93it/s] 61%|██████    | 61/100 [00:08<00:07,  5.02it/s] 62%|██████▏   | 62/100 [00:08<00:07,  4.95it/s] 63%|██████▎   | 63/100 [00:09<00:07,  4.77it/s] 65%|██████▌   | 65/100 [00:09<00:06,  5.57it/s] 66%|██████▌   | 66/100 [00:09<00:05,  6.16it/s] 67%|██████▋   | 67/100 [00:09<00:05,  6.24it/s] 68%|██████▊   | 68/100 [00:09<00:04,  6.89it/s] 70%|███████   | 70/100 [00:10<00:03,  7.66it/s] 71%|███████   | 71/100 [00:10<00:04,  6.03it/s] 72%|███████▏  | 72/100 [00:10<00:04,  6.10it/s] 74%|███████▍  | 74/100 [00:10<00:03,  7.42it/s] 75%|███████▌  | 75/100 [00:10<00:03,  7.72it/s] 76%|███████▌  | 76/100 [00:10<00:03,  7.79it/s] 77%|███████▋  | 77/100 [00:11<00:03,  7.61it/s] 78%|███████▊  | 78/100 [00:11<00:03,  7.09it/s] 80%|████████  | 80/100 [00:11<00:03,  6.62it/s] 81%|████████  | 81/100 [00:11<00:03,  6.27it/s] 82%|████████▏ | 82/100 [00:11<00:02,  6.50it/s] 83%|████████▎ | 83/100 [00:11<00:02,  6.72it/s] 84%|████████▍ | 84/100 [00:12<00:02,  6.20it/s] 86%|████████▌ | 86/100 [00:12<00:01,  7.04it/s] 87%|████████▋ | 87/100 [00:12<00:01,  7.44it/s] 89%|████████▉ | 89/100 [00:12<00:01,  9.35it/s] 91%|█████████ | 91/100 [00:12<00:00, 10.80it/s] 93%|█████████▎| 93/100 [00:12<00:00, 11.71it/s] 95%|█████████▌| 95/100 [00:13<00:00, 12.29it/s] 97%|█████████▋| 97/100 [00:13<00:00, 12.24it/s] 99%|█████████▉| 99/100 [00:13<00:00, 11.78it/s]100%|██████████| 100/100 [00:13<00:00,  7.39it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.021, 0.0156
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0122, 0.0154
--- total mse / var(X): 0.0155
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.30it/s]  3%|▎         | 3/100 [00:00<00:09, 10.53it/s]  5%|▌         | 5/100 [00:00<00:09,  9.87it/s]  7%|▋         | 7/100 [00:00<00:09,  9.88it/s]  8%|▊         | 8/100 [00:00<00:10,  8.97it/s] 10%|█         | 10/100 [00:01<00:10,  8.34it/s] 11%|█         | 11/100 [00:01<00:10,  8.43it/s] 12%|█▏        | 12/100 [00:01<00:11,  7.77it/s] 13%|█▎        | 13/100 [00:01<00:12,  6.73it/s] 15%|█▌        | 15/100 [00:01<00:10,  8.15it/s] 17%|█▋        | 17/100 [00:02<00:09,  8.42it/s] 19%|█▉        | 19/100 [00:02<00:08,  9.25it/s] 20%|██        | 20/100 [00:02<00:08,  9.03it/s] 22%|██▏       | 22/100 [00:02<00:07, 10.34it/s] 24%|██▍       | 24/100 [00:02<00:06, 11.53it/s] 26%|██▌       | 26/100 [00:02<00:06, 11.29it/s] 28%|██▊       | 28/100 [00:02<00:06, 11.16it/s] 30%|███       | 30/100 [00:03<00:06, 10.23it/s] 32%|███▏      | 32/100 [00:03<00:06, 10.17it/s] 34%|███▍      | 34/100 [00:03<00:06, 10.46it/s] 36%|███▌      | 36/100 [00:03<00:06, 10.18it/s] 38%|███▊      | 38/100 [00:03<00:05, 10.86it/s] 40%|████      | 40/100 [00:04<00:05, 11.12it/s] 42%|████▏     | 42/100 [00:04<00:05, 11.27it/s] 44%|████▍     | 44/100 [00:04<00:05, 11.13it/s] 46%|████▌     | 46/100 [00:04<00:04, 10.96it/s] 48%|████▊     | 48/100 [00:04<00:04, 12.28it/s] 50%|█████     | 50/100 [00:04<00:04, 12.30it/s] 52%|█████▏    | 52/100 [00:05<00:03, 13.11it/s] 54%|█████▍    | 54/100 [00:05<00:03, 12.99it/s] 56%|█████▌    | 56/100 [00:05<00:03, 13.41it/s] 58%|█████▊    | 58/100 [00:05<00:03, 13.36it/s] 60%|██████    | 60/100 [00:05<00:02, 14.02it/s] 62%|██████▏   | 62/100 [00:05<00:02, 14.41it/s] 64%|██████▍   | 64/100 [00:05<00:02, 13.73it/s] 66%|██████▌   | 66/100 [00:06<00:02, 12.69it/s] 68%|██████▊   | 68/100 [00:06<00:02, 13.81it/s] 70%|███████   | 70/100 [00:06<00:02, 13.69it/s] 72%|███████▏  | 72/100 [00:06<00:02, 12.58it/s] 74%|███████▍  | 74/100 [00:06<00:01, 13.21it/s] 76%|███████▌  | 76/100 [00:06<00:02, 11.59it/s] 78%|███████▊  | 78/100 [00:07<00:01, 11.87it/s] 80%|████████  | 80/100 [00:07<00:01, 11.68it/s] 82%|████████▏ | 82/100 [00:07<00:01, 11.61it/s] 84%|████████▍ | 84/100 [00:07<00:01, 11.03it/s] 86%|████████▌ | 86/100 [00:07<00:01, 11.12it/s] 88%|████████▊ | 88/100 [00:07<00:01, 11.60it/s] 90%|█████████ | 90/100 [00:08<00:00, 12.31it/s] 92%|█████████▏| 92/100 [00:08<00:00, 13.11it/s] 94%|█████████▍| 94/100 [00:08<00:00, 12.91it/s] 96%|█████████▌| 96/100 [00:08<00:00, 13.83it/s] 98%|█████████▊| 98/100 [00:08<00:00, 14.62it/s]100%|██████████| 100/100 [00:08<00:00, 14.88it/s]100%|██████████| 100/100 [00:08<00:00, 11.43it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0041, 0.00378
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00318, 0.00342
--- total mse / var(X): 0.0036
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:13,  7.14it/s]  3%|▎         | 3/100 [00:00<00:07, 12.64it/s]  5%|▌         | 5/100 [00:00<00:06, 15.36it/s]  7%|▋         | 7/100 [00:00<00:06, 14.97it/s]  9%|▉         | 9/100 [00:00<00:06, 13.22it/s] 11%|█         | 11/100 [00:00<00:06, 13.51it/s] 13%|█▎        | 13/100 [00:00<00:06, 12.77it/s] 16%|█▌        | 16/100 [00:01<00:05, 15.75it/s] 18%|█▊        | 18/100 [00:01<00:04, 16.55it/s] 21%|██        | 21/100 [00:01<00:04, 18.82it/s] 24%|██▍       | 24/100 [00:01<00:03, 19.82it/s] 27%|██▋       | 27/100 [00:01<00:03, 20.36it/s] 30%|███       | 30/100 [00:01<00:03, 20.69it/s] 33%|███▎      | 33/100 [00:01<00:03, 17.46it/s] 35%|███▌      | 35/100 [00:02<00:03, 16.64it/s] 37%|███▋      | 37/100 [00:02<00:03, 17.31it/s] 39%|███▉      | 39/100 [00:02<00:03, 17.75it/s] 41%|████      | 41/100 [00:02<00:03, 17.89it/s] 44%|████▍     | 44/100 [00:02<00:02, 19.74it/s] 47%|████▋     | 47/100 [00:02<00:02, 18.71it/s] 49%|████▉     | 49/100 [00:02<00:02, 18.64it/s] 51%|█████     | 51/100 [00:02<00:02, 18.80it/s] 53%|█████▎    | 53/100 [00:03<00:02, 19.04it/s] 55%|█████▌    | 55/100 [00:03<00:02, 16.99it/s] 57%|█████▋    | 57/100 [00:03<00:02, 14.56it/s] 59%|█████▉    | 59/100 [00:03<00:02, 13.76it/s] 61%|██████    | 61/100 [00:03<00:02, 13.35it/s] 63%|██████▎   | 63/100 [00:03<00:02, 13.93it/s] 66%|██████▌   | 66/100 [00:03<00:02, 16.04it/s] 68%|██████▊   | 68/100 [00:04<00:02, 15.63it/s] 70%|███████   | 70/100 [00:04<00:01, 15.65it/s] 72%|███████▏  | 72/100 [00:04<00:01, 16.09it/s] 74%|███████▍  | 74/100 [00:04<00:01, 15.34it/s] 76%|███████▌  | 76/100 [00:04<00:01, 14.04it/s] 78%|███████▊  | 78/100 [00:04<00:01, 13.80it/s] 80%|████████  | 80/100 [00:05<00:01, 12.77it/s] 82%|████████▏ | 82/100 [00:05<00:01, 13.64it/s] 85%|████████▌ | 85/100 [00:05<00:00, 15.96it/s] 87%|████████▋ | 87/100 [00:05<00:00, 16.81it/s] 89%|████████▉ | 89/100 [00:05<00:00, 16.54it/s] 91%|█████████ | 91/100 [00:05<00:00, 15.23it/s] 93%|█████████▎| 93/100 [00:05<00:00, 15.81it/s] 95%|█████████▌| 95/100 [00:05<00:00, 16.06it/s] 97%|█████████▋| 97/100 [00:06<00:00, 14.50it/s] 99%|█████████▉| 99/100 [00:06<00:00, 15.03it/s]100%|██████████| 100/100 [00:06<00:00, 15.99it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0016, 0.00138
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0016, 0.00181
--- total mse / var(X): 0.0016
Retrain weight
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:00<00:12,  8.06it/s]  3%|▎         | 3/100 [00:00<00:08, 11.26it/s]  5%|▌         | 5/100 [00:00<00:06, 13.85it/s]  7%|▋         | 7/100 [00:00<00:06, 15.18it/s]  9%|▉         | 9/100 [00:00<00:05, 16.67it/s] 11%|█         | 11/100 [00:00<00:05, 17.29it/s] 14%|█▍        | 14/100 [00:00<00:04, 19.03it/s] 16%|█▌        | 16/100 [00:00<00:04, 18.60it/s] 19%|█▉        | 19/100 [00:01<00:03, 20.26it/s] 22%|██▏       | 22/100 [00:01<00:03, 20.22it/s] 25%|██▌       | 25/100 [00:01<00:03, 19.50it/s] 28%|██▊       | 28/100 [00:01<00:03, 20.37it/s] 31%|███       | 31/100 [00:01<00:03, 18.81it/s] 33%|███▎      | 33/100 [00:01<00:03, 17.58it/s] 35%|███▌      | 35/100 [00:01<00:03, 16.89it/s] 38%|███▊      | 38/100 [00:02<00:03, 17.70it/s] 41%|████      | 41/100 [00:02<00:03, 18.43it/s] 44%|████▍     | 44/100 [00:02<00:02, 19.20it/s] 46%|████▌     | 46/100 [00:02<00:03, 17.95it/s] 48%|████▊     | 48/100 [00:02<00:02, 17.38it/s] 50%|█████     | 50/100 [00:02<00:02, 17.32it/s] 52%|█████▏    | 52/100 [00:02<00:02, 17.06it/s] 54%|█████▍    | 54/100 [00:03<00:02, 16.18it/s] 57%|█████▋    | 57/100 [00:03<00:02, 17.75it/s] 59%|█████▉    | 59/100 [00:03<00:02, 17.35it/s] 61%|██████    | 61/100 [00:03<00:02, 14.76it/s] 63%|██████▎   | 63/100 [00:03<00:02, 15.86it/s] 66%|██████▌   | 66/100 [00:03<00:01, 17.86it/s] 68%|██████▊   | 68/100 [00:03<00:01, 17.96it/s] 71%|███████   | 71/100 [00:04<00:01, 19.20it/s] 74%|███████▍  | 74/100 [00:04<00:01, 19.66it/s] 77%|███████▋  | 77/100 [00:04<00:01, 20.04it/s] 80%|████████  | 80/100 [00:04<00:00, 20.76it/s] 83%|████████▎ | 83/100 [00:04<00:00, 21.28it/s] 86%|████████▌ | 86/100 [00:04<00:00, 21.48it/s] 89%|████████▉ | 89/100 [00:04<00:00, 20.85it/s] 92%|█████████▏| 92/100 [00:05<00:00, 17.10it/s] 95%|█████████▌| 95/100 [00:05<00:00, 17.25it/s] 97%|█████████▋| 97/100 [00:05<00:00, 16.78it/s]100%|██████████| 100/100 [00:05<00:00, 18.66it/s]100%|██████████| 100/100 [00:05<00:00, 18.08it/s]
Retrain for 100 epochs
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.000587, 0.000497
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00044, 0.000508
--- total mse / var(X): 0.000502
start table evaluation...
Elapsed time: 687.637375831604 seconds
Cosine similarity between AMM and exact (Train): 0.9999986
Cosine similarity between AMM and exact (Test): 0.99998295
p,r,f1: 0.9830911406916567 0.9999646870392643 0.9914561265354309
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
done
{'model': {'name': 'ViT',
           'layer': 6,
           'dim': 32,
           'f1': [0.9830911406916567, 0.9999646870392643, 0.9914561265354309],
           'num_param': 30176},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256],
               'cossim_layer_train': [0.9990398287773132,
                                      0.9994966387748718,
                                      0.9994045495986938,
                                      0.9984933137893677,
                                      0.9983404278755188,
                                      0.9999986290931702],
               'cossim_layer_test': [0.9910812377929688,
                                     0.9954779148101807,
                                     0.9945116639137268,
                                     0.9790322780609131,
                                     0.9761354923248291,
                                     0.9999829530715942],
               'cossim_amm_train': [0.9982346892356873,
                                    0.9987258315086365,
                                    0.9955452680587769,
                                    0.9941689372062683,
                                    0.9957242012023926,
                                    0.9982702732086182,
                                    0.9982419610023499,
                                    0.9983230829238892,
                                    0.9961211681365967,
                                    0.9953585863113403,
                                    0.9955888390541077,
                                    0.997657299041748,
                                    0.9980846643447876,
                                    0.999920129776001],
               'cossim_amm_test': [0.9843717813491821,
                                   0.9944041967391968,
                                   0.9903161525726318,
                                   0.9753112196922302,
                                   0.9629161953926086,
                                   0.9918403625488281,
                                   0.9913782477378845,
                                   0.987748920917511,
                                   0.9859690070152283,
                                   0.965538740158081,
                                   0.9296243786811829,
                                   0.9709581732749939,
                                   0.9782529473304749,
                                   0.9989123940467834],
               'f1': [0.9830463222533707, 1.0, 0.9914506900033658],
               'lut_num': 14,
               'lut_shapes': [(32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (256, 2, 256)],
               'lut_total_size': 966656}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
│    │    └─ModuleList: 3-2                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 30,176
Trainable params: 30,176
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.2353843405 - test_loss: 0.0723218368
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.0408340178 - test_loss: 0.0477372175
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0288442493 - test_loss: 0.0445990841
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0264138013 - test_loss: 0.0437180653
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0242975119 - test_loss: 0.0452843764
Early Stop Left: 4
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0218000194 - test_loss: 0.0566055695
Early Stop Left: 3
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0200632558 - test_loss: 0.0614857462
Early Stop Left: 2
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0187275860 - test_loss: 0.0597900425
Early Stop Left: 1
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0177190426 - test_loss: 0.0599148939
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  8%|▊         | 17/205 [00:00<00:01, 167.08it/s] 17%|█▋        | 34/205 [00:00<00:01, 168.70it/s] 25%|██▌       | 52/205 [00:00<00:00, 169.42it/s] 34%|███▎      | 69/205 [00:00<00:00, 169.14it/s] 42%|████▏     | 86/205 [00:00<00:00, 168.62it/s] 50%|█████     | 103/205 [00:00<00:00, 168.76it/s] 59%|█████▊    | 120/205 [00:00<00:00, 160.61it/s] 67%|██████▋   | 137/205 [00:00<00:00, 159.37it/s] 75%|███████▌  | 154/205 [00:00<00:00, 161.74it/s] 83%|████████▎ | 171/205 [00:01<00:00, 163.71it/s] 92%|█████████▏| 188/205 [00:01<00:00, 165.13it/s]100%|██████████| 205/205 [00:01<00:00, 165.48it/s]===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 7,424
Trainable params: 7,424
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               192
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 176
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,672
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              32
│    └─Linear: 2-5                                 4,352
===========================================================================
Total params: 7,424
Trainable params: 7,424
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.3539703245 - test_loss: 0.1394841370
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.0778518727 - test_loss: 0.0623656938
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.0393013137 - test_loss: 0.0491568837
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.0304430437 - test_loss: 0.0458411259
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.0275284218 - test_loss: 0.0445734893
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.0262896529 - test_loss: 0.0437049626
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.0248745316 - test_loss: 0.0442428503
Early Stop Left: 4
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.0230033774 - test_loss: 0.0410713717
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.0220129256 - test_loss: 0.0410655834
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.0212302031 - test_loss: 0.0442485653
Early Stop Left: 4
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.0207748093 - test_loss: 0.0487049389
Early Stop Left: 3
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.0204085428 - test_loss: 0.0465106658
Early Stop Left: 2
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.0201482539 - test_loss: 0.0517113068
Early Stop Left: 1
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.0199276955 - test_loss: 0.0511637653
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/205 [00:00<?, ?it/s]  9%|▉         | 18/205 [00:00<00:01, 177.15it/s] 18%|█▊        | 37/205 [00:00<00:00, 179.61it/s] 27%|██▋       | 56/205 [00:00<00:00, 183.09it/s] 37%|███▋      | 75/205 [00:00<00:00, 184.70it/s] 46%|████▌     | 94/205 [00:00<00:00, 184.18it/s] 55%|█████▌    | 113/205 [00:00<00:00, 185.00it/s] 64%|██████▍   | 132/205 [00:00<00:00, 183.49it/s] 74%|███████▎  | 151/205 [00:00<00:00, 182.76it/s] 83%|████████▎ | 170/205 [00:00<00:00, 183.91it/s] 92%|█████████▏| 189/205 [00:01<00:00, 185.57it/s]100%|██████████| 205/205 [00:01<00:00, 184.55it/s]
Best micro threshold=0.979860, fscore=0.991
p,r,f1: 0.9830789471331639 0.999980145931947 0.991457523837459
throttleing by fixed threshold: 0.5
p,r,f1: 0.9830463222533707 1.0 0.9914506900033658
{'model': 'vit_large',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.9798598885536194,
                 'p': 0.9830789471331639,
                 'r': 0.999980145931947,
                 'f1': 0.991457523837459},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.9830463222533707,
                 'r': 1.0,
                 'f1': 0.9914506900033658}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm

Best micro threshold=0.645779, fscore=0.991
p,r,f1: 0.9835125912300648 0.998852101439435 0.9911229978772402
throttleing by fixed threshold: 0.5
p,r,f1: 0.982699843703989 0.9994104402692636 0.9909847008916415
{'model': 'vit_min',
 'app': '462.libquantum-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.6457787752151489,
                 'p': 0.9835125912300648,
                 'r': 0.998852101439435,
                 'f1': 0.9911229978772402},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.982699843703989,
                 'r': 0.9994104402692636,
                 'f1': 0.9909847008916415}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
