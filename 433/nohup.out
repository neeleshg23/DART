===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               3,072
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 2,816
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        2,230,016
│    │    └─ModuleList: 3-2                        2,230,016
│    │    └─ModuleList: 3-3                        2,230,016
│    │    └─ModuleList: 3-4                        2,230,016
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              512
│    └─Linear: 2-5                                 65,792
===========================================================================
Total params: 8,992,256
Trainable params: 8,992,256
Non-trainable params: 0
===========================================================================
Loading data for model
Traceback (most recent call last):
  File "src/train.py", line 189, in <module>
    main()
  File "src/train.py", line 172, in main
    test_df = torch.load(os.path.join(processed_dir, f"{app_name}.df.pt"))
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'processed/619.lbm-s0.df.pt'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Traceback (most recent call last):
  File "src/train_kd.py", line 209, in <module>
    main()
  File "src/train_kd.py", line 190, in main
    test_df = torch.load(os.path.join(processed_dir, f"{app_name}.df.pt"))
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 699, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 231, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/neelesh/miniconda3/envs/comp/lib/python3.8/site-packages/torch/serialization.py", line 212, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'processed/433.milc-s0.df.pt'
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6287616639 - test_loss: 0.6512961811
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.5174079063 - test_loss: 0.5232031828
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.4272791757 - test_loss: 0.4431728465
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3729598800 - test_loss: 0.3892825206
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3346242512 - test_loss: 0.3484262740
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3059219560 - test_loss: 0.3166210132
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2842508589 - test_loss: 0.2916125488
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2677432788 - test_loss: 0.2718859647
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2553470218 - test_loss: 0.2562608252
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2460370562 - test_loss: 0.2439465935
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2391736648 - test_loss: 0.2342415483
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2341625617 - test_loss: 0.2266142902
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2306826108 - test_loss: 0.2206937779
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2282552724 - test_loss: 0.2160753493
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2265017270 - test_loss: 0.2125511081
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2254815224 - test_loss: 0.2098657235
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2246840451 - test_loss: 0.2078243536
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2242002991 - test_loss: 0.2063968955
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2239011187 - test_loss: 0.2053425970
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2236810517 - test_loss: 0.2046075987
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2233822491 - test_loss: 0.2039029391
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2230943805 - test_loss: 0.2033493188
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2225726089 - test_loss: 0.2023783313
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2215420600 - test_loss: 0.2007350542
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2200069265 - test_loss: 0.1989687313
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2189748399 - test_loss: 0.1973969864
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2183534364 - test_loss: 0.1965424197
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2178553336 - test_loss: 0.1961026027
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2175224051 - test_loss: 0.1959673733
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2172417429 - test_loss: 0.1952259999
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2169930675 - test_loss: 0.1953448286
Early Stop Left: 4
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2168223058 - test_loss: 0.1950860206
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2166037431 - test_loss: 0.1945372264
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2162425202 - test_loss: 0.1944483232
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2159527237 - test_loss: 0.1939718812
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2157581185 - test_loss: 0.1939765141
Early Stop Left: 4
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2154100046 - test_loss: 0.1931943688
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2151492993 - test_loss: 0.1926868081
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2150290049 - test_loss: 0.1923717863
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2147547855 - test_loss: 0.1921128260
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2146356703 - test_loss: 0.1920831896
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2144539355 - test_loss: 0.1918250141
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2141896792 - test_loss: 0.1914716822
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2137958428 - test_loss: 0.1909091342
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2133856534 - test_loss: 0.1903733550
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2130021553 - test_loss: 0.1899714487
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2126117222 - test_loss: 0.1895327005
-------- Save Best Model! --------
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.2122843984 - test_loss: 0.1888534220
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2119051721 - test_loss: 0.1886327198
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2115733907 - test_loss: 0.1880988942
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2112460240 - test_loss: 0.1877668541
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2109442220 - test_loss: 0.1872550706
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2106111798 - test_loss: 0.1867621196
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2101850393 - test_loss: 0.1861773485
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2097313795 - test_loss: 0.1856090164
-------- Save Best Model! --------
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2093208415 - test_loss: 0.1850166054
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2088438093 - test_loss: 0.1842813335
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2082294195 - test_loss: 0.1832097479
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2076374753 - test_loss: 0.1828362957
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2069075308 - test_loss: 0.1814782208
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2058749079 - test_loss: 0.1803335518
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2046107012 - test_loss: 0.1784458357
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2031132339 - test_loss: 0.1762485810
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2014127418 - test_loss: 0.1738525001
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.1992190532 - test_loss: 0.1716003319
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.1968802792 - test_loss: 0.1675214008
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.1946289004 - test_loss: 0.1648608005
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.1927305599 - test_loss: 0.1629415981
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.1910483227 - test_loss: 0.1609012225
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.1892906438 - test_loss: 0.1581516282
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.1877304914 - test_loss: 0.1561634161
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.1863300640 - test_loss: 0.1545391184
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.1850248714 - test_loss: 0.1528598180
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.1838027393 - test_loss: 0.1505754105
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.1827827313 - test_loss: 0.1503500878
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.1818753527 - test_loss: 0.1493128689
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.1810849725 - test_loss: 0.1478762827
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.1802877496 - test_loss: 0.1464399023
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.1794946306 - test_loss: 0.1460899234
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.1789056925 - test_loss: 0.1445416125
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.1781805997 - test_loss: 0.1441387949
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.1776666136 - test_loss: 0.1434495756
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1771096114 - test_loss: 0.1422739388
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1766514050 - test_loss: 0.1424517946
Early Stop Left: 4
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1762184055 - test_loss: 0.1413761210
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1758101350 - test_loss: 0.1408727045
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1753563178 - test_loss: 0.1407945460
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1750706556 - test_loss: 0.1399804845
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1747399689 - test_loss: 0.1393812790
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1743606447 - test_loss: 0.1390083673
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1741513128 - test_loss: 0.1384395193
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.1738726501 - test_loss: 0.1382298074
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.1735403707 - test_loss: 0.1374595034
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.1733360836 - test_loss: 0.1376596232
Early Stop Left: 4
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.1731758522 - test_loss: 0.1375073246
Early Stop Left: 3
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.1728839212 - test_loss: 0.1374249534
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.1726649293 - test_loss: 0.1365774832
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.1725088974 - test_loss: 0.1364080429
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.1722256591 - test_loss: 0.1355357336
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.1720676831 - test_loss: 0.1357701121
Early Stop Left: 4
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.1719054014 - test_loss: 0.1359459716
Early Stop Left: 3
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.1718016488 - test_loss: 0.1350262819
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.1716209702 - test_loss: 0.1348415238
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.1714876378 - test_loss: 0.1351421618
Early Stop Left: 4
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.1713375718 - test_loss: 0.1345826325
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.1710395128 - test_loss: 0.1338221121
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.1710092752 - test_loss: 0.1345101028
Early Stop Left: 4
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.1708825695 - test_loss: 0.1342085642
Early Stop Left: 3
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.1706766207 - test_loss: 0.1344867922
Early Stop Left: 2
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.1705313626 - test_loss: 0.1343111241
Early Stop Left: 1
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1703411553 - test_loss: 0.1333490693
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.1701915897 - test_loss: 0.1333638056
Early Stop Left: 4
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.1701026631 - test_loss: 0.1329070985
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 114 - loss: 0.1699425258 - test_loss: 0.1327695020
-------- Save Best Model! --------
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.1698207152 - test_loss: 0.1326730258
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.1697219833 - test_loss: 0.1336058229
Early Stop Left: 4
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.1695629038 - test_loss: 0.1327874430
Early Stop Left: 3
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.1694615238 - test_loss: 0.1319981788
-------- Save Best Model! --------
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.1693830221 - test_loss: 0.1325061666
Early Stop Left: 4
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.1693142918 - test_loss: 0.1322761971
Early Stop Left: 3
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.1691218715 - test_loss: 0.1318780645
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.1689965876 - test_loss: 0.1320640131
Early Stop Left: 4
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.1688526890 - test_loss: 0.1326691732
Early Stop Left: 3
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.1687390296 - test_loss: 0.1312264611
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.1686654113 - test_loss: 0.1311545131
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.1684709045 - test_loss: 0.1306596658
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.1684360398 - test_loss: 0.1309893794
Early Stop Left: 4
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.1683236529 - test_loss: 0.1319983550
Early Stop Left: 3
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.1681698994 - test_loss: 0.1306801839
Early Stop Left: 2
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.1681256741 - test_loss: 0.1310801061
Early Stop Left: 1
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.1679701842 - test_loss: 0.1309843100
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 16%|█▌        | 19/121 [00:00<00:00, 186.20it/s] 32%|███▏      | 39/121 [00:00<00:00, 190.44it/s] 49%|████▉     | 59/121 [00:00<00:00, 192.54it/s] 65%|██████▌   | 79/121 [00:00<00:00, 193.77it/s] 82%|████████▏ | 99/121 [00:00<00:00, 193.12it/s] 98%|█████████▊| 119/121 [00:00<00:00, 192.95it/s]100%|██████████| 121/121 [00:00<00:00, 193.38it/s]
Best micro threshold=0.351270, fscore=0.717
p,r,f1: 0.6723834199699708 0.7690092603355418 0.7174576137619805
throttleing by fixed threshold: 0.5
p,r,f1: 0.779113262448416 0.619156108334302 0.6899854142684553
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3512699007987976,
                 'p': 0.6723834199699708,
                 'r': 0.7690092603355418,
                 'f1': 0.7174576137619805},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.779113262448416,
                 'r': 0.619156108334302,
                 'f1': 0.6899854142684553}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
Traceback (most recent call last):
  File "src/train_kd.py", line 209, in <module>
    main()
  File "src/train_kd.py", line 163, in main
    gpu_id = sys.argv[4]
IndexError: list index out of range
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5398671101 - test_loss: 0.4420080249
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3415066090 - test_loss: 0.3127396764
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2705932272 - test_loss: 0.2568343946
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2414662101 - test_loss: 0.2301207639
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2289126252 - test_loss: 0.2162931766
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2233756468 - test_loss: 0.2087469762
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2210436394 - test_loss: 0.2045495663
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2199086436 - test_loss: 0.2022206140
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2193805785 - test_loss: 0.2006286811
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2188034218 - test_loss: 0.1994712151
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2171414481 - test_loss: 0.1959373036
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2140912755 - test_loss: 0.1926343068
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2126305446 - test_loss: 0.1909767645
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2111636787 - test_loss: 0.1892446485
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2094471098 - test_loss: 0.1871457308
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2081086493 - test_loss: 0.1862075863
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2070585297 - test_loss: 0.1843460515
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2059840723 - test_loss: 0.1828282366
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2043110572 - test_loss: 0.1803077681
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2018819748 - test_loss: 0.1765351957
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.1979784983 - test_loss: 0.1705655993
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.1934109825 - test_loss: 0.1650512714
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.1888676824 - test_loss: 0.1591487337
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.1850453374 - test_loss: 0.1559539229
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.1820095787 - test_loss: 0.1520716150
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.1791777336 - test_loss: 0.1488777155
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.1769406042 - test_loss: 0.1452788901
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.1750309474 - test_loss: 0.1422392360
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.1733617869 - test_loss: 0.1423679788
Early Stop Left: 4
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.1718473273 - test_loss: 0.1390506627
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.1705072577 - test_loss: 0.1370628128
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.1692960726 - test_loss: 0.1365275062
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.1679190442 - test_loss: 0.1354029394
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.1665682757 - test_loss: 0.1322537238
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.1653886471 - test_loss: 0.1305530327
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.1644230708 - test_loss: 0.1302268260
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.1632051109 - test_loss: 0.1270530228
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.1621098427 - test_loss: 0.1278696359
Early Stop Left: 4
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.1609891654 - test_loss: 0.1245448267
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.1599469437 - test_loss: 0.1222416710
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.1589169630 - test_loss: 0.1226107694
Early Stop Left: 4
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.1579110577 - test_loss: 0.1215172240
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.1569667025 - test_loss: 0.1205663909
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.1559838188 - test_loss: 0.1202467512
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.1553148616 - test_loss: 0.1180200542
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.1545420031 - test_loss: 0.1168850795
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.1539244198 - test_loss: 0.1149741775
-------- Save Best Model! --------
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.1532997734 - test_loss: 0.1143375615
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.1528367120 - test_loss: 0.1141369545
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.1522854917 - test_loss: 0.1132535446
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.1518834583 - test_loss: 0.1125797867
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.1514372882 - test_loss: 0.1134472625
Early Stop Left: 4
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.1510738368 - test_loss: 0.1123670633
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.1506594403 - test_loss: 0.1106248650
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.1502797649 - test_loss: 0.1111406738
Early Stop Left: 4
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.1500503324 - test_loss: 0.1103446340
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.1496239029 - test_loss: 0.1107326862
Early Stop Left: 4
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.1492527457 - test_loss: 0.1102607678
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.1489294704 - test_loss: 0.1100438247
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.1485852465 - test_loss: 0.1092287681
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.1482443238 - test_loss: 0.1084532959
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.1478636906 - test_loss: 0.1072309222
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.1476587626 - test_loss: 0.1073412698
Early Stop Left: 4
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.1474260188 - test_loss: 0.1079082349
Early Stop Left: 3
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.1470517388 - test_loss: 0.1065316843
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.1468614367 - test_loss: 0.1069322893
Early Stop Left: 4
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.1464990749 - test_loss: 0.1063520219
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.1463990308 - test_loss: 0.1062117797
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.1461778897 - test_loss: 0.1058899080
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.1458253385 - test_loss: 0.1062254758
Early Stop Left: 4
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.1456884491 - test_loss: 0.1058767302
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.1455433535 - test_loss: 0.1045482294
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.1452022390 - test_loss: 0.1043969489
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.1449866513 - test_loss: 0.1046296859
Early Stop Left: 4
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.1447549679 - test_loss: 0.1051220531
Early Stop Left: 3
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.1445361664 - test_loss: 0.1032611816
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.1444194846 - test_loss: 0.1041881629
Early Stop Left: 4
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.1442286996 - test_loss: 0.1033063452
Early Stop Left: 3
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.1438802728 - test_loss: 0.1023672017
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.1437458977 - test_loss: 0.1035503073
Early Stop Left: 4
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.1435187466 - test_loss: 0.1023451133
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.1433078840 - test_loss: 0.1020157541
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1431094797 - test_loss: 0.1022018221
Early Stop Left: 4
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1429271382 - test_loss: 0.1014266443
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1427648379 - test_loss: 0.1024385163
Early Stop Left: 4
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1426930468 - test_loss: 0.1018895052
Early Stop Left: 3
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1423267600 - test_loss: 0.1007271709
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1422400280 - test_loss: 0.1003625308
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1419542824 - test_loss: 0.1000731605
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1417116961 - test_loss: 0.1014166179
Early Stop Left: 4
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1415919857 - test_loss: 0.1002524366
Early Stop Left: 3
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.1414136309 - test_loss: 0.1000200015
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.1411640017 - test_loss: 0.0991183719
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.1410320090 - test_loss: 0.1019596519
Early Stop Left: 4
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.1408304554 - test_loss: 0.1009681019
Early Stop Left: 3
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.1406404083 - test_loss: 0.1003153612
Early Stop Left: 2
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.1404068049 - test_loss: 0.0983613130
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.1402865232 - test_loss: 0.0974082885
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.1399807273 - test_loss: 0.0967381962
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.1399149321 - test_loss: 0.0983953786
Early Stop Left: 4
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.1396036883 - test_loss: 0.0966109755
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.1395583444 - test_loss: 0.0974704904
Early Stop Left: 4
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.1393260202 - test_loss: 0.0957746922
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.1392479445 - test_loss: 0.0984702631
Early Stop Left: 4
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.1390420760 - test_loss: 0.0969372605
Early Stop Left: 3
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.1387267866 - test_loss: 0.0947981493
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.1387318700 - test_loss: 0.0969681911
Early Stop Left: 4
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.1385235207 - test_loss: 0.0969169078
Early Stop Left: 3
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.1383631189 - test_loss: 0.0966150511
Early Stop Left: 2
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.1381510877 - test_loss: 0.0956168353
Early Stop Left: 1
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1380225476 - test_loss: 0.0973192782
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 17%|█▋        | 20/121 [00:00<00:00, 194.28it/s] 33%|███▎      | 40/121 [00:00<00:00, 191.52it/s] 50%|████▉     | 60/121 [00:00<00:00, 191.17it/s] 66%|██████▌   | 80/121 [00:00<00:00, 191.53it/s] 83%|████████▎ | 100/121 [00:00<00:00, 191.44it/s] 99%|█████████▉| 120/121 [00:00<00:00, 191.36it/s]100%|██████████| 121/121 [00:00<00:00, 192.40it/s]
Best micro threshold=0.332581, fscore=0.789
p,r,f1: 0.7350960726888831 0.8503793250416521 0.7885464549355112
throttleing by fixed threshold: 0.5
p,r,f1: 0.8484761269995152 0.6944926188538881 0.7638008340201116
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.33258095383644104,
                 'p': 0.7350960726888831,
                 'r': 0.8503793250416521,
                 'f1': 0.7885464549355112},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8484761269995152,
                 'r': 0.6944926188538881,
                 'f1': 0.7638008340201116}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5671666559 - test_loss: 0.4423499775
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.3539368326 - test_loss: 0.3107631985
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.2736314265 - test_loss: 0.2536471741
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.2388358093 - test_loss: 0.2261758545
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.2225907432 - test_loss: 0.2117509604
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2146212149 - test_loss: 0.2036638001
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2107384758 - test_loss: 0.1989276303
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2086375898 - test_loss: 0.1960697154
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2075502965 - test_loss: 0.1940993451
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2066580033 - test_loss: 0.1924827414
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2047053739 - test_loss: 0.1884947875
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2010066177 - test_loss: 0.1852602540
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.1993316691 - test_loss: 0.1832242399
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.1977032536 - test_loss: 0.1813210352
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.1958072296 - test_loss: 0.1793343346
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.1943781056 - test_loss: 0.1783685774
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.1931888990 - test_loss: 0.1764960492
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.1919393737 - test_loss: 0.1748967855
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.1898865867 - test_loss: 0.1719403643
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.1868817632 - test_loss: 0.1677161951
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.1820470732 - test_loss: 0.1609697392
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.1761063406 - test_loss: 0.1539973681
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.1701172292 - test_loss: 0.1476668965
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.1656225475 - test_loss: 0.1439198752
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.1622303849 - test_loss: 0.1398279006
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.1595153806 - test_loss: 0.1379235052
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.1575863062 - test_loss: 0.1348664844
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.1560165517 - test_loss: 0.1327386111
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.1546780822 - test_loss: 0.1329696379
Early Stop Left: 4
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.1535228775 - test_loss: 0.1304219931
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.1524761357 - test_loss: 0.1291533565
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.1514777600 - test_loss: 0.1287573798
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.1504263028 - test_loss: 0.1281538483
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.1493672216 - test_loss: 0.1259949303
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.1482135148 - test_loss: 0.1239958476
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.1469880739 - test_loss: 0.1228661006
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.1454439483 - test_loss: 0.1204124746
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.1441324126 - test_loss: 0.1204130480
Early Stop Left: 4
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.1427857384 - test_loss: 0.1170329122
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.1414197277 - test_loss: 0.1154080116
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.1401570775 - test_loss: 0.1147640097
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.1389998660 - test_loss: 0.1134011968
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.1379728375 - test_loss: 0.1125123573
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.1369684655 - test_loss: 0.1120065677
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.1362109956 - test_loss: 0.1105103606
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.1353862132 - test_loss: 0.1094348324
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.1346523376 - test_loss: 0.1077181081
-------- Save Best Model! --------
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.1338853246 - test_loss: 0.1071776150
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.1332742894 - test_loss: 0.1072820033
Early Stop Left: 4
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.1325997010 - test_loss: 0.1056486303
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.1319875609 - test_loss: 0.1050599150
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.1313898643 - test_loss: 0.1054472878
Early Stop Left: 4
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.1308857938 - test_loss: 0.1042058874
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.1303118161 - test_loss: 0.1027399350
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.1297605089 - test_loss: 0.1027881548
Early Stop Left: 4
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.1294923357 - test_loss: 0.1018041750
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.1289262802 - test_loss: 0.1013232363
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.1284694731 - test_loss: 0.1018327010
Early Stop Left: 4
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.1280988243 - test_loss: 0.1008322078
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.1277814957 - test_loss: 0.1012558108
Early Stop Left: 4
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.1273218456 - test_loss: 0.0996763448
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.1268784786 - test_loss: 0.0989379374
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.1266063215 - test_loss: 0.0994579295
Early Stop Left: 4
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.1263435702 - test_loss: 0.0988291924
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.1258888270 - test_loss: 0.0978340922
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.1255997531 - test_loss: 0.0986118260
Early Stop Left: 4
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.1251693618 - test_loss: 0.0981195099
Early Stop Left: 3
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.1249763765 - test_loss: 0.0969689379
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.1246903586 - test_loss: 0.0971906735
Early Stop Left: 4
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.1243116927 - test_loss: 0.0971194281
Early Stop Left: 3
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.1241568300 - test_loss: 0.0957539779
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.1239104592 - test_loss: 0.0960418746
Early Stop Left: 4
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.1236325134 - test_loss: 0.0948437841
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.1233496771 - test_loss: 0.0946315747
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.1231379900 - test_loss: 0.0967897876
Early Stop Left: 4
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.1228904694 - test_loss: 0.0941099343
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.1226933774 - test_loss: 0.0946055702
Early Stop Left: 4
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.1225484289 - test_loss: 0.0941324105
Early Stop Left: 3
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.1221807184 - test_loss: 0.0938257645
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.1220984720 - test_loss: 0.0944978148
Early Stop Left: 4
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.1218047100 - test_loss: 0.0931144053
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.1216062824 - test_loss: 0.0954196569
Early Stop Left: 4
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1215000394 - test_loss: 0.0934091593
Early Stop Left: 3
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1212611335 - test_loss: 0.0925136189
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1211097663 - test_loss: 0.0932971046
Early Stop Left: 4
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1210472150 - test_loss: 0.0914350764
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1206103501 - test_loss: 0.0924683283
Early Stop Left: 4
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1206491658 - test_loss: 0.0918362550
Early Stop Left: 3
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1202984944 - test_loss: 0.0920781487
Early Stop Left: 2
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1200719991 - test_loss: 0.0917672655
Early Stop Left: 1
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1200086267 - test_loss: 0.0918426905
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 16%|█▌        | 19/121 [00:00<00:00, 187.16it/s] 31%|███▏      | 38/121 [00:00<00:00, 186.20it/s] 47%|████▋     | 57/121 [00:00<00:00, 186.01it/s] 63%|██████▎   | 76/121 [00:00<00:00, 186.29it/s] 79%|███████▊  | 95/121 [00:00<00:00, 186.45it/s] 94%|█████████▍| 114/121 [00:00<00:00, 185.92it/s]100%|██████████| 121/121 [00:00<00:00, 186.96it/s]
Best micro threshold=0.335948, fscore=0.774
p,r,f1: 0.7213171409970985 0.8345646867371848 0.7738194547731599
throttleing by fixed threshold: 0.5
p,r,f1: 0.8204301814311269 0.6845100546321051 0.7463322394546603
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.33594757318496704,
                 'p': 0.7213171409970985,
                 'r': 0.8345646867371848,
                 'f1': 0.7738194547731599},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.8204301814311269,
                 'r': 0.6845100546321051,
                 'f1': 0.7463322394546603}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6152160513 - test_loss: 0.6181722278
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.4794932400 - test_loss: 0.4775367832
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.3905821515 - test_loss: 0.4002859221
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.3382764381 - test_loss: 0.3475915750
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3025876685 - test_loss: 0.3095608031
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.2776284403 - test_loss: 0.2816267156
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.2602126920 - test_loss: 0.2609453996
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.2479803125 - test_loss: 0.2455883231
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2395887057 - test_loss: 0.2340799894
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2338232810 - test_loss: 0.2255235809
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2299705857 - test_loss: 0.2191495301
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2274239124 - test_loss: 0.2144209316
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2258967606 - test_loss: 0.2110320117
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2249589112 - test_loss: 0.2085498815
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2242900622 - test_loss: 0.2068085776
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2240202189 - test_loss: 0.2055644271
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2236869481 - test_loss: 0.2046072345
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2234184964 - test_loss: 0.2039538633
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2230470198 - test_loss: 0.2031954070
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2223132840 - test_loss: 0.2018863277
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2205439874 - test_loss: 0.1994186906
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2191686584 - test_loss: 0.1976066593
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2183546135 - test_loss: 0.1964845917
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2177869492 - test_loss: 0.1960448663
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2173792282 - test_loss: 0.1956820998
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2169754190 - test_loss: 0.1952361325
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2166780211 - test_loss: 0.1947174253
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2162600505 - test_loss: 0.1942270221
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2157426711 - test_loss: 0.1938887271
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2150960667 - test_loss: 0.1924497098
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2144223600 - test_loss: 0.1917705216
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2138779911 - test_loss: 0.1911207452
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2134149349 - test_loss: 0.1901821678
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2129328831 - test_loss: 0.1899489166
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2126061103 - test_loss: 0.1895583516
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2124279955 - test_loss: 0.1895303597
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2120722616 - test_loss: 0.1888536537
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2117979692 - test_loss: 0.1884391912
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2116252402 - test_loss: 0.1878734822
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2112577058 - test_loss: 0.1876918645
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2110175064 - test_loss: 0.1871605022
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2107254018 - test_loss: 0.1871776778
Early Stop Left: 4
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2104247660 - test_loss: 0.1863166864
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2099865066 - test_loss: 0.1859370261
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2096028291 - test_loss: 0.1851036691
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2092416580 - test_loss: 0.1844602373
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2088087589 - test_loss: 0.1840547717
-------- Save Best Model! --------
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.2083907280 - test_loss: 0.1832771852
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2077025484 - test_loss: 0.1824229116
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2067971370 - test_loss: 0.1811708192
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2057089367 - test_loss: 0.1794664194
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2046777160 - test_loss: 0.1788804071
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2036973821 - test_loss: 0.1772800743
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2026253304 - test_loss: 0.1761983676
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2014500696 - test_loss: 0.1747144165
-------- Save Best Model! --------
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2000603945 - test_loss: 0.1724327599
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.1982304401 - test_loss: 0.1693467857
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.1960539305 - test_loss: 0.1669616543
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.1939926772 - test_loss: 0.1653763306
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.1921881543 - test_loss: 0.1610304336
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.1904959509 - test_loss: 0.1590634507
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.1889284146 - test_loss: 0.1573287225
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.1876405709 - test_loss: 0.1560572396
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.1865075132 - test_loss: 0.1541838164
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.1853967854 - test_loss: 0.1530886943
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.1844740553 - test_loss: 0.1523503974
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.1835705764 - test_loss: 0.1503950007
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.1828073031 - test_loss: 0.1497264234
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.1821790333 - test_loss: 0.1486628379
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.1815018997 - test_loss: 0.1477813475
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.1809156994 - test_loss: 0.1475268465
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.1804103396 - test_loss: 0.1467908716
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.1798288201 - test_loss: 0.1456394345
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.1793117852 - test_loss: 0.1459473497
Early Stop Left: 4
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.1788329090 - test_loss: 0.1440275620
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.1783887658 - test_loss: 0.1441583869
Early Stop Left: 4
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.1780309021 - test_loss: 0.1430993031
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.1775895046 - test_loss: 0.1435229615
Early Stop Left: 4
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.1771113997 - test_loss: 0.1416093125
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.1767621506 - test_loss: 0.1413456976
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.1762740298 - test_loss: 0.1410551777
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.1759170985 - test_loss: 0.1403427115
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1754900183 - test_loss: 0.1393319460
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1750946985 - test_loss: 0.1391404627
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1746244243 - test_loss: 0.1385567713
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1741234572 - test_loss: 0.1374775935
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1735843495 - test_loss: 0.1368191340
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1731558812 - test_loss: 0.1350993123
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1726205803 - test_loss: 0.1360982241
Early Stop Left: 4
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1721352860 - test_loss: 0.1345015995
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1717300552 - test_loss: 0.1352670618
Early Stop Left: 4
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.1712820944 - test_loss: 0.1341248532
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.1707942353 - test_loss: 0.1331784519
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.1704012679 - test_loss: 0.1334093717
Early Stop Left: 4
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.1700244433 - test_loss: 0.1321263671
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.1695881177 - test_loss: 0.1315137249
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.1691816388 - test_loss: 0.1315184944
Early Stop Left: 4
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.1688982720 - test_loss: 0.1309559274
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.1684724259 - test_loss: 0.1290555143
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.1681464266 - test_loss: 0.1296685767
Early Stop Left: 4
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.1678485882 - test_loss: 0.1298758882
Early Stop Left: 3
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.1676423864 - test_loss: 0.1278567870
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.1673047932 - test_loss: 0.1278714793
Early Stop Left: 4
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.1671020800 - test_loss: 0.1286270471
Early Stop Left: 3
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.1668124465 - test_loss: 0.1272362449
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.1664169682 - test_loss: 0.1263043406
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.1663290708 - test_loss: 0.1271905773
Early Stop Left: 4
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.1660701244 - test_loss: 0.1266654077
Early Stop Left: 3
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.1658168617 - test_loss: 0.1271146339
Early Stop Left: 2
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.1656158692 - test_loss: 0.1254728371
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1653339694 - test_loss: 0.1255183908
Early Stop Left: 4
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.1651386679 - test_loss: 0.1255758971
Early Stop Left: 3
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.1649717239 - test_loss: 0.1252435223
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 114 - loss: 0.1647197105 - test_loss: 0.1250163155
-------- Save Best Model! --------
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.1645790358 - test_loss: 0.1250322136
Early Stop Left: 4
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.1643759917 - test_loss: 0.1247033812
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.1641605990 - test_loss: 0.1248582912
Early Stop Left: 4
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.1640112705 - test_loss: 0.1240837140
-------- Save Best Model! --------
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.1638571366 - test_loss: 0.1229376338
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.1637431866 - test_loss: 0.1242708028
Early Stop Left: 4
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.1635064976 - test_loss: 0.1230140448
Early Stop Left: 3
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.1633479631 - test_loss: 0.1232932943
Early Stop Left: 2
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.1631476288 - test_loss: 0.1239412268
Early Stop Left: 1
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.1629654480 - test_loss: 0.1223191147
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.1628003099 - test_loss: 0.1217285085
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.1625607011 - test_loss: 0.1221394020
Early Stop Left: 4
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.1625294095 - test_loss: 0.1230110315
Early Stop Left: 3
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.1623071703 - test_loss: 0.1226987626
Early Stop Left: 2
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.1621386323 - test_loss: 0.1209993154
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.1619906952 - test_loss: 0.1217885624
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.1618187387 - test_loss: 0.1212615240
Early Stop Left: 3
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.1617128176 - test_loss: 0.1218256940
Early Stop Left: 2
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.1616048314 - test_loss: 0.1204447390
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.1614280449 - test_loss: 0.1199717770
-------- Save Best Model! --------
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.1613105478 - test_loss: 0.1196756883
-------- Save Best Model! --------
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.1611646652 - test_loss: 0.1202596622
Early Stop Left: 4
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.1609717557 - test_loss: 0.1204452425
Early Stop Left: 3
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.1608916547 - test_loss: 0.1201404754
Early Stop Left: 2
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.1606791626 - test_loss: 0.1188036046
-------- Save Best Model! --------
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.1606500195 - test_loss: 0.1202946398
Early Stop Left: 4
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.1604037411 - test_loss: 0.1196203350
Early Stop Left: 3
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.1602431265 - test_loss: 0.1198192324
Early Stop Left: 2
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.1601399784 - test_loss: 0.1187656099
-------- Save Best Model! --------
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.1599770040 - test_loss: 0.1184748275
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.1598154947 - test_loss: 0.1183010434
-------- Save Best Model! --------
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.1597121816 - test_loss: 0.1178886044
-------- Save Best Model! --------
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.1596113323 - test_loss: 0.1184746650
Early Stop Left: 4
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.1594270504 - test_loss: 0.1172901405
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.1592765071 - test_loss: 0.1180548086
Early Stop Left: 4
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.1591881496 - test_loss: 0.1170880192
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.1590618816 - test_loss: 0.1189021072
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.1588871533 - test_loss: 0.1179769251
Early Stop Left: 3
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.1587739760 - test_loss: 0.1170212751
-------- Save Best Model! --------
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.1586435922 - test_loss: 0.1174243764
Early Stop Left: 4
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.1585351261 - test_loss: 0.1180776939
Early Stop Left: 3
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.1583965556 - test_loss: 0.1161642704
-------- Save Best Model! --------
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.1582307766 - test_loss: 0.1173903638
Early Stop Left: 4
------- START EPOCH 158 -------
Epoch: 158 - loss: 0.1581411871 - test_loss: 0.1169197651
Early Stop Left: 3
------- START EPOCH 159 -------
Epoch: 159 - loss: 0.1579868605 - test_loss: 0.1150935923
-------- Save Best Model! --------
------- START EPOCH 160 -------
Epoch: 160 - loss: 0.1578515104 - test_loss: 0.1153094935
Early Stop Left: 4
------- START EPOCH 161 -------
Epoch: 161 - loss: 0.1577396341 - test_loss: 0.1148575327
-------- Save Best Model! --------
------- START EPOCH 162 -------
Epoch: 162 - loss: 0.1575363875 - test_loss: 0.1157394828
Early Stop Left: 4
------- START EPOCH 163 -------
Epoch: 163 - loss: 0.1574701462 - test_loss: 0.1155534049
Early Stop Left: 3
------- START EPOCH 164 -------
Epoch: 164 - loss: 0.1573534802 - test_loss: 0.1149943816
Early Stop Left: 2
------- START EPOCH 165 -------
Epoch: 165 - loss: 0.1572228871 - test_loss: 0.1154084685
Early Stop Left: 1
------- START EPOCH 166 -------
Epoch: 166 - loss: 0.1570765787 - test_loss: 0.1136238095
-------- Save Best Model! --------
------- START EPOCH 167 -------
Epoch: 167 - loss: 0.1569702156 - test_loss: 0.1146873167
Early Stop Left: 4
------- START EPOCH 168 -------
Epoch: 168 - loss: 0.1567933283 - test_loss: 0.1138105532
Early Stop Left: 3
------- START EPOCH 169 -------
Epoch: 169 - loss: 0.1566646643 - test_loss: 0.1143592664
Early Stop Left: 2
------- START EPOCH 170 -------
Epoch: 170 - loss: 0.1566417679 - test_loss: 0.1135451373
-------- Save Best Model! --------
------- START EPOCH 171 -------
Epoch: 171 - loss: 0.1564645423 - test_loss: 0.1141337866
Early Stop Left: 4
------- START EPOCH 172 -------
Epoch: 172 - loss: 0.1563525609 - test_loss: 0.1146914724
Early Stop Left: 3
------- START EPOCH 173 -------
Epoch: 173 - loss: 0.1561517314 - test_loss: 0.1134554995
-------- Save Best Model! --------
------- START EPOCH 174 -------
Epoch: 174 - loss: 0.1561173340 - test_loss: 0.1137343644
Early Stop Left: 4
------- START EPOCH 175 -------
Epoch: 175 - loss: 0.1559498833 - test_loss: 0.1139133520
Early Stop Left: 3
------- START EPOCH 176 -------
Epoch: 176 - loss: 0.1558591720 - test_loss: 0.1136379555
Early Stop Left: 2
------- START EPOCH 177 -------
Epoch: 177 - loss: 0.1556949165 - test_loss: 0.1120314412
-------- Save Best Model! --------
------- START EPOCH 178 -------
Epoch: 178 - loss: 0.1556058564 - test_loss: 0.1131015927
Early Stop Left: 4
------- START EPOCH 179 -------
Epoch: 179 - loss: 0.1554990539 - test_loss: 0.1127543492
Early Stop Left: 3
------- START EPOCH 180 -------
Epoch: 180 - loss: 0.1553866858 - test_loss: 0.1115741372
-------- Save Best Model! --------
------- START EPOCH 181 -------
Epoch: 181 - loss: 0.1552945125 - test_loss: 0.1125356337
Early Stop Left: 4
------- START EPOCH 182 -------
Epoch: 182 - loss: 0.1551109281 - test_loss: 0.1113082246
-------- Save Best Model! --------
------- START EPOCH 183 -------
Epoch: 183 - loss: 0.1551056997 - test_loss: 0.1114846437
Early Stop Left: 4
------- START EPOCH 184 -------
Epoch: 184 - loss: 0.1549830229 - test_loss: 0.1121896024
Early Stop Left: 3
------- START EPOCH 185 -------
Epoch: 185 - loss: 0.1548158017 - test_loss: 0.1115036127
Early Stop Left: 2
------- START EPOCH 186 -------
Epoch: 186 - loss: 0.1547833078 - test_loss: 0.1111331300
-------- Save Best Model! --------
------- START EPOCH 187 -------
Epoch: 187 - loss: 0.1546033083 - test_loss: 0.1113988526
Early Stop Left: 4
------- START EPOCH 188 -------
Epoch: 188 - loss: 0.1545180695 - test_loss: 0.1118137322
Early Stop Left: 3
------- START EPOCH 189 -------
Epoch: 189 - loss: 0.1544682939 - test_loss: 0.1108093374
-------- Save Best Model! --------
------- START EPOCH 190 -------
Epoch: 190 - loss: 0.1543890961 - test_loss: 0.1113573831
Early Stop Left: 4
------- START EPOCH 191 -------
Epoch: 191 - loss: 0.1542173131 - test_loss: 0.1103948361
-------- Save Best Model! --------
------- START EPOCH 192 -------
Epoch: 192 - loss: 0.1541049183 - test_loss: 0.1097425933
-------- Save Best Model! --------
------- START EPOCH 193 -------
Epoch: 193 - loss: 0.1540733874 - test_loss: 0.1099738447
Early Stop Left: 4
------- START EPOCH 194 -------
Epoch: 194 - loss: 0.1539494415 - test_loss: 0.1110296333
Early Stop Left: 3
------- START EPOCH 195 -------
Epoch: 195 - loss: 0.1538514579 - test_loss: 0.1104278281
Early Stop Left: 2
------- START EPOCH 196 -------
Epoch: 196 - loss: 0.1537992499 - test_loss: 0.1110494888
Early Stop Left: 1
------- START EPOCH 197 -------
Epoch: 197 - loss: 0.1536296083 - test_loss: 0.1108099018
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 13%|█▎        | 16/121 [00:00<00:00, 155.81it/s] 26%|██▋       | 32/121 [00:00<00:00, 146.81it/s] 39%|███▉      | 47/121 [00:00<00:00, 140.97it/s] 52%|█████▏    | 63/121 [00:00<00:00, 146.12it/s] 65%|██████▌   | 79/121 [00:00<00:00, 149.66it/s] 79%|███████▊  | 95/121 [00:00<00:00, 151.52it/s] 92%|█████████▏| 111/121 [00:00<00:00, 149.31it/s]100%|██████████| 121/121 [00:00<00:00, 148.27it/s]
Best micro threshold=0.334549, fscore=0.771
p,r,f1: 0.7203391771116066 0.828810105002131 0.7707770915458956
throttleing by fixed threshold: 0.5
p,r,f1: 0.824837214206897 0.6788996086636445 0.7447867917037536
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.33454906940460205,
                 'p': 0.7203391771116066,
                 'r': 0.828810105002131,
                 'f1': 0.7707770915458956},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.824837214206897,
                 'r': 0.6788996086636445,
                 'f1': 0.7447867917037536}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6735729092 - test_loss: 0.7132715282
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.6187177014 - test_loss: 0.6509739870
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.5606570100 - test_loss: 0.5845011719
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.5036356670 - test_loss: 0.5254729671
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.4579686199 - test_loss: 0.4811972981
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.4238100916 - test_loss: 0.4467580796
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3964235280 - test_loss: 0.4177736271
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.3730196387 - test_loss: 0.3923739232
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.3525523939 - test_loss: 0.3697303228
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.3343924152 - test_loss: 0.3494184576
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.3182698789 - test_loss: 0.3311684284
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.3039557240 - test_loss: 0.3147918028
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2913876580 - test_loss: 0.3001197798
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2803198496 - test_loss: 0.2869967057
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2705307504 - test_loss: 0.2752862124
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2621182745 - test_loss: 0.2648526112
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2546922882 - test_loss: 0.2555927239
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2483147740 - test_loss: 0.2474098480
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2429002646 - test_loss: 0.2401937985
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2383029903 - test_loss: 0.2338531201
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2343548018 - test_loss: 0.2282973690
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2311409787 - test_loss: 0.2234686233
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2284729428 - test_loss: 0.2192527917
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2262805221 - test_loss: 0.2156402817
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2245278780 - test_loss: 0.2125554364
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2230421404 - test_loss: 0.2098990150
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2219807209 - test_loss: 0.2076786952
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2210894112 - test_loss: 0.2058498431
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2204606788 - test_loss: 0.2042803892
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2199283334 - test_loss: 0.2030289357
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2195293318 - test_loss: 0.2020249109
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2192702305 - test_loss: 0.2011909054
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2190246763 - test_loss: 0.2005282216
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2187376919 - test_loss: 0.2000126416
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2185371724 - test_loss: 0.1994618117
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2184678461 - test_loss: 0.1990590656
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2181412515 - test_loss: 0.1986820268
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2178913778 - test_loss: 0.1981879922
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2175796469 - test_loss: 0.1977620221
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2171821573 - test_loss: 0.1971910118
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2167620671 - test_loss: 0.1965951376
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2161486938 - test_loss: 0.1957520484
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2153642793 - test_loss: 0.1948245687
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2146818152 - test_loss: 0.1941190857
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2142292373 - test_loss: 0.1932342761
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2138430475 - test_loss: 0.1927803757
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2134772493 - test_loss: 0.1923515177
-------- Save Best Model! --------
------- START EPOCH 48 -------
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6553038920 - test_loss: 0.7132935588
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.6020534226 - test_loss: 0.6510561557
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.5457979482 - test_loss: 0.5846654714
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.4906120326 - test_loss: 0.5256478185
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.4465191953 - test_loss: 0.4814289929
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.4136580096 - test_loss: 0.4470787671
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3874115451 - test_loss: 0.4181945203
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.3650627010 - test_loss: 0.3929101332
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.3455883559 - test_loss: 0.3703795519
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.3283725110 - test_loss: 0.3501834709
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.3131455081 - test_loss: 0.3320407390
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2996792562 - test_loss: 0.3157585512
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2879075939 - test_loss: 0.3011741931
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2775917646 - test_loss: 0.2881362266
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2685180494 - test_loss: 0.2765138093
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2607796439 - test_loss: 0.2661714390
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2539999918 - test_loss: 0.2570051636
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2482344993 - test_loss: 0.2489283175
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2433951818 - test_loss: 0.2418274650
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2393390517 - test_loss: 0.2356120780
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2359005807 - test_loss: 0.2301911835
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2331552019 - test_loss: 0.2255169552
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2309163893 - test_loss: 0.2214605163
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2291126928 - test_loss: 0.2180245115
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2277052069 - test_loss: 0.2151258545
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2265259592 - test_loss: 0.2126508250
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2257230530 - test_loss: 0.2106232419
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2250528042 - test_loss: 0.2090013062
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2246031982 - test_loss: 0.2076125385
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2242181733 - test_loss: 0.2065482215
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2239336873 - test_loss: 0.2057287939
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2237602530 - test_loss: 0.2050527715
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2235795633 - test_loss: 0.2045322839
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2233449989 - test_loss: 0.2041397233
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2231806191 - test_loss: 0.2036592617
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2231316996 - test_loss: 0.2033381313
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2228370428 - test_loss: 0.2030175184
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2226133095 - test_loss: 0.2025624358
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2223340614 - test_loss: 0.2021726745
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2219662300 - test_loss: 0.2016113232
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2215535009 - test_loss: 0.2010240811
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2209510138 - test_loss: 0.2002353384
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2202360375 - test_loss: 0.1993273208
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2196324208 - test_loss: 0.1986672643
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2192167690 - test_loss: 0.1977725027
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2188519399 - test_loss: 0.1973441441
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2185033307 - test_loss: 0.1969345035
-------- Save Best Model! --------
------- START EPOCH 48 -------
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.6030325649 - test_loss: 0.7133688538
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.5543609194 - test_loss: 0.6513307804
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.5032417041 - test_loss: 0.5851900238
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.4533357215 - test_loss: 0.5263267219
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.4137678957 - test_loss: 0.4823144960
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3845866266 - test_loss: 0.4482453763
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3615578136 - test_loss: 0.4197043038
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.3421757638 - test_loss: 0.3947991569
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.3254822323 - test_loss: 0.3726600212
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.3108997968 - test_loss: 0.3528628081
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2981589532 - test_loss: 0.3351139113
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2870334996 - test_loss: 0.3192122320
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2774449353 - test_loss: 0.3049965205
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2691739426 - test_loss: 0.2923177907
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2620287818 - test_loss: 0.2810741308
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2560843897 - test_loss: 0.2711358129
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2509993592 - test_loss: 0.2623987636
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2468087862 - test_loss: 0.2548071432
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2434184038 - test_loss: 0.2482249390
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2406890282 - test_loss: 0.2425711481
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2384622920 - test_loss: 0.2377384073
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2367877875 - test_loss: 0.2337096735
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2354907372 - test_loss: 0.2302767182
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2345026057 - test_loss: 0.2275027564
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2337839847 - test_loss: 0.2252773393
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2331861189 - test_loss: 0.2234258891
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2328394988 - test_loss: 0.2220201794
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2325370889 - test_loss: 0.2210204011
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2323624958 - test_loss: 0.2201229198
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2321921412 - test_loss: 0.2195250441
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2320629610 - test_loss: 0.2191278444
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2319956152 - test_loss: 0.2187668613
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2318938605 - test_loss: 0.2185056620
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2317291275 - test_loss: 0.2183045800
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2316112361 - test_loss: 0.2179070970
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2315824707 - test_loss: 0.2177042523
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2313451642 - test_loss: 0.2174359029
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2311648017 - test_loss: 0.2170507620
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2309314518 - test_loss: 0.2167063403
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2305861391 - test_loss: 0.2161091129
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2301539445 - test_loss: 0.2154806573
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2295957458 - test_loss: 0.2147885192
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2290455222 - test_loss: 0.2138267691
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2285888215 - test_loss: 0.2132787813
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2282535502 - test_loss: 0.2123503025
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2279539920 - test_loss: 0.2120048889
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2276683400 - test_loss: 0.2116898046
-------- Save Best Model! --------
------- START EPOCH 48 -------
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5677566247 - test_loss: 0.7134428640
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.5221622734 - test_loss: 0.6515675079
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.4744817516 - test_loss: 0.5855979279
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.4281395088 - test_loss: 0.5269387975
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3916250784 - test_loss: 0.4831065058
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3649038157 - test_loss: 0.4492813639
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3440101287 - test_loss: 0.4210292832
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.3265819264 - test_loss: 0.3964510065
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.3117052696 - test_loss: 0.3746557041
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2988305009 - test_loss: 0.3552279620
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2876908818 - test_loss: 0.3378523603
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2780620823 - test_loss: 0.3223212191
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2698558332 - test_loss: 0.3084831233
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2628629699 - test_loss: 0.2961849430
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2569025720 - test_loss: 0.2853417532
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2520348057 - test_loss: 0.2758227134
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2479413459 - test_loss: 0.2675343966
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2446451660 - test_loss: 0.2604240238
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2420498540 - test_loss: 0.2543396951
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2400206406 - test_loss: 0.2492083124
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2384073305 - test_loss: 0.2448909184
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2372470011 - test_loss: 0.2413983578
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2363773394 - test_loss: 0.2384679239
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2357368627 - test_loss: 0.2362037065
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2352920118 - test_loss: 0.2344687043
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2349116624 - test_loss: 0.2330362541
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2347198275 - test_loss: 0.2320167681
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2345360107 - test_loss: 0.2313701895
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2344420093 - test_loss: 0.2307153694
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2343336873 - test_loss: 0.2303206247
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2342478555 - test_loss: 0.2300986373
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2342083688 - test_loss: 0.2298548983
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2341306101 - test_loss: 0.2296794606
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2339933727 - test_loss: 0.2295323146
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2338947309 - test_loss: 0.2291566284
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2338734564 - test_loss: 0.2290031116
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2336665779 - test_loss: 0.2287494703
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2335059296 - test_loss: 0.2284064957
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2332889734 - test_loss: 0.2280735961
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2329557129 - test_loss: 0.2274563639
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2325388361 - test_loss: 0.2267860934
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2320297861 - test_loss: 0.2261184006
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2315499611 - test_loss: 0.2251431958
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2311564332 - test_loss: 0.2246528572
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2308715076 - test_loss: 0.2237214574
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2306227517 - test_loss: 0.2234119284
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2303890393 - test_loss: 0.2231794576
-------- Save Best Model! --------
------- START EPOCH 48 -------
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Loading data for model
Data loaded successfully for stu
------- START EPOCH 1 -------
Epoch: 1 - loss: 0.5317698579 - test_loss: 0.7135314848
-------- Save Best Model! --------
------- START EPOCH 2 -------
Epoch: 2 - loss: 0.4893081302 - test_loss: 0.6518567372
-------- Save Best Model! --------
------- START EPOCH 3 -------
Epoch: 3 - loss: 0.4451183787 - test_loss: 0.5861272438
-------- Save Best Model! --------
------- START EPOCH 4 -------
Epoch: 4 - loss: 0.4024008936 - test_loss: 0.5277385446
-------- Save Best Model! --------
------- START EPOCH 5 -------
Epoch: 5 - loss: 0.3689875675 - test_loss: 0.4841545655
-------- Save Best Model! --------
------- START EPOCH 6 -------
Epoch: 6 - loss: 0.3447503323 - test_loss: 0.4506444197
-------- Save Best Model! --------
------- START EPOCH 7 -------
Epoch: 7 - loss: 0.3259955893 - test_loss: 0.4227598076
-------- Save Best Model! --------
------- START EPOCH 8 -------
Epoch: 8 - loss: 0.3105077188 - test_loss: 0.3985916844
-------- Save Best Model! --------
------- START EPOCH 9 -------
Epoch: 9 - loss: 0.2974188755 - test_loss: 0.3772279731
-------- Save Best Model! --------
------- START EPOCH 10 -------
Epoch: 10 - loss: 0.2862089712 - test_loss: 0.3582622951
-------- Save Best Model! --------
------- START EPOCH 11 -------
Epoch: 11 - loss: 0.2766178820 - test_loss: 0.3413793179
-------- Save Best Model! --------
------- START EPOCH 12 -------
Epoch: 12 - loss: 0.2684283204 - test_loss: 0.3263674046
-------- Save Best Model! --------
------- START EPOCH 13 -------
Epoch: 13 - loss: 0.2615445017 - test_loss: 0.3130919189
-------- Save Best Model! --------
------- START EPOCH 14 -------
Epoch: 14 - loss: 0.2557636536 - test_loss: 0.3013686651
-------- Save Best Model! --------
------- START EPOCH 15 -------
Epoch: 15 - loss: 0.2509095453 - test_loss: 0.2911165805
-------- Save Best Model! --------
------- START EPOCH 16 -------
Epoch: 16 - loss: 0.2470225347 - test_loss: 0.2821905320
-------- Save Best Model! --------
------- START EPOCH 17 -------
Epoch: 17 - loss: 0.2438078246 - test_loss: 0.2744832366
-------- Save Best Model! --------
------- START EPOCH 18 -------
Epoch: 18 - loss: 0.2412788614 - test_loss: 0.2679631289
-------- Save Best Model! --------
------- START EPOCH 19 -------
Epoch: 19 - loss: 0.2393424946 - test_loss: 0.2624669218
-------- Save Best Model! --------
------- START EPOCH 20 -------
Epoch: 20 - loss: 0.2378723359 - test_loss: 0.2579173377
-------- Save Best Model! --------
------- START EPOCH 21 -------
Epoch: 21 - loss: 0.2367307419 - test_loss: 0.2541573772
-------- Save Best Model! --------
------- START EPOCH 22 -------
Epoch: 22 - loss: 0.2359469531 - test_loss: 0.2512379496
-------- Save Best Model! --------
------- START EPOCH 23 -------
Epoch: 23 - loss: 0.2353762935 - test_loss: 0.2488199783
-------- Save Best Model! --------
------- START EPOCH 24 -------
Epoch: 24 - loss: 0.2349684674 - test_loss: 0.2470427373
-------- Save Best Model! --------
------- START EPOCH 25 -------
Epoch: 25 - loss: 0.2346989638 - test_loss: 0.2457569158
-------- Save Best Model! --------
------- START EPOCH 26 -------
Epoch: 26 - loss: 0.2344548233 - test_loss: 0.2446871124
-------- Save Best Model! --------
------- START EPOCH 27 -------
Epoch: 27 - loss: 0.2343534977 - test_loss: 0.2439747817
-------- Save Best Model! --------
------- START EPOCH 28 -------
Epoch: 28 - loss: 0.2342398709 - test_loss: 0.2435993631
-------- Save Best Model! --------
------- START EPOCH 29 -------
Epoch: 29 - loss: 0.2341922497 - test_loss: 0.2431148436
-------- Save Best Model! --------
------- START EPOCH 30 -------
Epoch: 30 - loss: 0.2341227977 - test_loss: 0.2428534601
-------- Save Best Model! --------
------- START EPOCH 31 -------
Epoch: 31 - loss: 0.2340668918 - test_loss: 0.2427579456
-------- Save Best Model! --------
------- START EPOCH 32 -------
Epoch: 32 - loss: 0.2340492501 - test_loss: 0.2426032157
-------- Save Best Model! --------
------- START EPOCH 33 -------
Epoch: 33 - loss: 0.2339956662 - test_loss: 0.2424934679
-------- Save Best Model! --------
------- START EPOCH 34 -------
Epoch: 34 - loss: 0.2338921805 - test_loss: 0.2424072200
-------- Save Best Model! --------
------- START EPOCH 35 -------
Epoch: 35 - loss: 0.2338244488 - test_loss: 0.2420844803
-------- Save Best Model! --------
------- START EPOCH 36 -------
Epoch: 36 - loss: 0.2338297838 - test_loss: 0.2420077778
-------- Save Best Model! --------
------- START EPOCH 37 -------
Epoch: 37 - loss: 0.2336781090 - test_loss: 0.2418236148
-------- Save Best Model! --------
------- START EPOCH 38 -------
Epoch: 38 - loss: 0.2335747028 - test_loss: 0.2415663253
-------- Save Best Model! --------
------- START EPOCH 39 -------
Epoch: 39 - loss: 0.2334344643 - test_loss: 0.2413491960
-------- Save Best Model! --------
------- START EPOCH 40 -------
Epoch: 40 - loss: 0.2332187338 - test_loss: 0.2409255022
-------- Save Best Model! --------
------- START EPOCH 41 -------
Epoch: 41 - loss: 0.2329600617 - test_loss: 0.2405018180
-------- Save Best Model! --------
------- START EPOCH 42 -------
Epoch: 42 - loss: 0.2326024962 - test_loss: 0.2399312877
-------- Save Best Model! --------
------- START EPOCH 43 -------
Epoch: 43 - loss: 0.2321659694 - test_loss: 0.2390316783
-------- Save Best Model! --------
------- START EPOCH 44 -------
Epoch: 44 - loss: 0.2317459419 - test_loss: 0.2384298619
-------- Save Best Model! --------
------- START EPOCH 45 -------
Epoch: 45 - loss: 0.2314377460 - test_loss: 0.2373114717
-------- Save Best Model! --------
------- START EPOCH 46 -------
Epoch: 46 - loss: 0.2311727844 - test_loss: 0.2369493762
-------- Save Best Model! --------
------- START EPOCH 47 -------
Epoch: 47 - loss: 0.2309321916 - test_loss: 0.2366535442
-------- Save Best Model! --------
------- START EPOCH 48 -------
Epoch: 48 - loss: 0.2131769537 - test_loss: 0.1919478017
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2128288631 - test_loss: 0.1916943740
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2125374208 - test_loss: 0.1914099534
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2122445906 - test_loss: 0.1909527435
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2120196816 - test_loss: 0.1907385393
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2117942008 - test_loss: 0.1904416167
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2115303611 - test_loss: 0.1900274292
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2113122127 - test_loss: 0.1899540461
-------- Save Best Model! --------
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2110797478 - test_loss: 0.1897363032
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2107749149 - test_loss: 0.1892871162
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2102939173 - test_loss: 0.1886336260
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2097498395 - test_loss: 0.1881676409
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2090360678 - test_loss: 0.1871856185
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2083481357 - test_loss: 0.1865298210
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2077713680 - test_loss: 0.1858506546
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2072345309 - test_loss: 0.1850920029
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2068087830 - test_loss: 0.1846224184
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.2062292360 - test_loss: 0.1842435888
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.2057649592 - test_loss: 0.1833933780
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.2052496978 - test_loss: 0.1826832005
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.2048455618 - test_loss: 0.1821314992
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.2044401201 - test_loss: 0.1816131277
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.2039584447 - test_loss: 0.1811646769
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.2035252745 - test_loss: 0.1804299697
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.2030929178 - test_loss: 0.1801387038
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.2025352948 - test_loss: 0.1790668059
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.2019378437 - test_loss: 0.1780594729
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.2012640916 - test_loss: 0.1773779194
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.2004722579 - test_loss: 0.1762009853
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.1996483371 - test_loss: 0.1752121181
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.1985719275 - test_loss: 0.1738367291
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.1974512255 - test_loss: 0.1724681085
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.1963913845 - test_loss: 0.1710171624
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.1951398848 - test_loss: 0.1695982261
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.1939733929 - test_loss: 0.1679639992
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1927996183 - test_loss: 0.1663077312
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1916192325 - test_loss: 0.1648633938
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1904678095 - test_loss: 0.1634003356
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1893159236 - test_loss: 0.1622687151
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1881256619 - test_loss: 0.1606383617
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1870059564 - test_loss: 0.1592807176
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1858188608 - test_loss: 0.1577645369
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1845989172 - test_loss: 0.1562383044
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1834374224 - test_loss: 0.1548804955
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.1822173440 - test_loss: 0.1531686787
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.1810545922 - test_loss: 0.1517227766
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.1800760840 - test_loss: 0.1505480954
-------- Save Best Model! --------
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.1791998778 - test_loss: 0.1493906238
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.1782291186 - test_loss: 0.1483037449
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.1774425044 - test_loss: 0.1472387216
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.1766854717 - test_loss: 0.1463490750
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.1759102291 - test_loss: 0.1452607055
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.1752970223 - test_loss: 0.1442017818
-------- Save Best Model! --------
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.1746282915 - test_loss: 0.1437374286
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.1741303378 - test_loss: 0.1431590803
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.1734666893 - test_loss: 0.1420585535
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.1728971707 - test_loss: 0.1415901866
-------- Save Best Model! --------
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.1723810924 - test_loss: 0.1407342483
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.1717347150 - test_loss: 0.1397274923
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.1713304856 - test_loss: 0.1394011948
-------- Save Best Model! --------
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.1708431469 - test_loss: 0.1388078626
-------- Save Best Model! --------
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.1702623272 - test_loss: 0.1380000235
-------- Save Best Model! --------
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.1698183903 - test_loss: 0.1373841618
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1693598562 - test_loss: 0.1367638389
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.1689204173 - test_loss: 0.1362700932
-------- Save Best Model! --------
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.1685563134 - test_loss: 0.1356960863
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 48 - loss: 0.2274359948 - test_loss: 0.2112372764
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2271681831 - test_loss: 0.2110847992
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2269529929 - test_loss: 0.2108151657
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2267444151 - test_loss: 0.2103586342
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2265953375 - test_loss: 0.2101838277
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2264504649 - test_loss: 0.2099429671
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2262845386 - test_loss: 0.2095942111
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2261659601 - test_loss: 0.2097242685
Early Stop Left: 4
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2260522898 - test_loss: 0.2096097939
Early Stop Left: 3
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2259193537 - test_loss: 0.2093594849
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2257314777 - test_loss: 0.2089528854
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2256098884 - test_loss: 0.2090008714
Early Stop Left: 4
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2254408407 - test_loss: 0.2085081488
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2252448467 - test_loss: 0.2084124662
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2250378734 - test_loss: 0.2080604190
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2248229343 - test_loss: 0.2077409912
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2246461400 - test_loss: 0.2074833727
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.2243221777 - test_loss: 0.2072304650
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.2240457987 - test_loss: 0.2067801472
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.2236814009 - test_loss: 0.2060965277
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.2233796849 - test_loss: 0.2058882239
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.2229888816 - test_loss: 0.2050517390
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.2225590509 - test_loss: 0.2045039437
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.2221408490 - test_loss: 0.2036489827
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.2217105388 - test_loss: 0.2030546936
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.2212028658 - test_loss: 0.2020426229
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.2206883705 - test_loss: 0.2009117108
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.2201679836 - test_loss: 0.2001215642
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.2196128026 - test_loss: 0.1994549370
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.2191060126 - test_loss: 0.1987600020
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.2184699127 - test_loss: 0.1977044245
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.2178553153 - test_loss: 0.1969548535
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.2173288082 - test_loss: 0.1958802414
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.2166869346 - test_loss: 0.1953924598
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.2161471032 - test_loss: 0.1943629797
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.2156213731 - test_loss: 0.1930981775
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.2151156661 - test_loss: 0.1927015406
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.2146217107 - test_loss: 0.1922477793
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.2141041951 - test_loss: 0.1916314168
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.2135357072 - test_loss: 0.1906566440
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.2129716180 - test_loss: 0.1900118586
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.2124071142 - test_loss: 0.1889043780
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.2117181505 - test_loss: 0.1882524971
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.2110647388 - test_loss: 0.1873048867
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.2102880404 - test_loss: 0.1860148055
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.2094593321 - test_loss: 0.1845526110
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.2087038705 - test_loss: 0.1834915221
-------- Save Best Model! --------
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.2079252868 - test_loss: 0.1824810877
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.2070602634 - test_loss: 0.1814838161
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.2062979210 - test_loss: 0.1802004469
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.2056046051 - test_loss: 0.1790930621
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.2048771369 - test_loss: 0.1781439982
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.2043082248 - test_loss: 0.1772654032
-------- Save Best Model! --------
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.2037435444 - test_loss: 0.1764407931
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.2032840849 - test_loss: 0.1755845500
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.2027738655 - test_loss: 0.1746628617
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.2023447976 - test_loss: 0.1739964970
-------- Save Best Model! --------
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.2019551503 - test_loss: 0.1736637322
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.2014797526 - test_loss: 0.1728495038
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.2012138993 - test_loss: 0.1724565427
-------- Save Best Model! --------
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.2009255027 - test_loss: 0.1716469862
-------- Save Best Model! --------
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.2004703745 - test_loss: 0.1710493267
-------- Save Best Model! --------
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.2002180878 - test_loss: 0.1707437026
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1998661725 - test_loss: 0.1704540888
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.1995461849 - test_loss: 0.1698419771
-------- Save Best Model! --------
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.1993041390 - test_loss: 0.1694822394
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 114 - loss: 0.1990093556 - test_loss: 0.1687288199
-------- Save Best Model! --------
Epoch: 48 - loss: 0.2307452617 - test_loss: 0.2361704141
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2305333339 - test_loss: 0.2360729496
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2303684402 - test_loss: 0.2358053352
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2302090535 - test_loss: 0.2353446422
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2300968577 - test_loss: 0.2351503513
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2299867188 - test_loss: 0.2349308313
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2298651720 - test_loss: 0.2346529165
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2297831884 - test_loss: 0.2348371526
Early Stop Left: 4
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2297062791 - test_loss: 0.2347396814
Early Stop Left: 3
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2296205082 - test_loss: 0.2345450796
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2295015972 - test_loss: 0.2341457440
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2294320632 - test_loss: 0.2342637106
Early Stop Left: 4
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2293347005 - test_loss: 0.2338280672
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2292288979 - test_loss: 0.2337794803
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2291189032 - test_loss: 0.2335812943
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2290142800 - test_loss: 0.2333420737
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2289460233 - test_loss: 0.2332382737
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.2287799717 - test_loss: 0.2331418114
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.2286576769 - test_loss: 0.2328804609
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.2284706119 - test_loss: 0.2324375243
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.2283459038 - test_loss: 0.2324124395
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.2281448079 - test_loss: 0.2319360843
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.2279190625 - test_loss: 0.2316702846
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.2276987630 - test_loss: 0.2311680505
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.2274584664 - test_loss: 0.2309376840
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.2271444956 - test_loss: 0.2300241106
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.2268203020 - test_loss: 0.2290434900
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.2264704564 - test_loss: 0.2283376603
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.2260939322 - test_loss: 0.2277413549
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.2257333990 - test_loss: 0.2268676478
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.2252620080 - test_loss: 0.2259813206
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.2247843177 - test_loss: 0.2253068163
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.2243805542 - test_loss: 0.2242140132
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.2238759107 - test_loss: 0.2237118100
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.2234425602 - test_loss: 0.2227563756
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.2230092616 - test_loss: 0.2215774185
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.2225770125 - test_loss: 0.2211657878
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.2221638004 - test_loss: 0.2204887166
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.2217555823 - test_loss: 0.2198149972
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.2213306942 - test_loss: 0.2190669647
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.2209491403 - test_loss: 0.2187895504
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.2206064972 - test_loss: 0.2175581264
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.2202138318 - test_loss: 0.2173806157
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.2198744595 - test_loss: 0.2169513588
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.2194682884 - test_loss: 0.2160963878
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.2190295835 - test_loss: 0.2151032860
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.2186544657 - test_loss: 0.2144338012
-------- Save Best Model! --------
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.2182228382 - test_loss: 0.2141653850
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.2176926609 - test_loss: 0.2134303165
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.2171790286 - test_loss: 0.2122339249
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.2166538837 - test_loss: 0.2111137121
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.2160438553 - test_loss: 0.2102198426
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.2155076422 - test_loss: 0.2094479150
-------- Save Best Model! --------
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.2149483424 - test_loss: 0.2082649170
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.2144462934 - test_loss: 0.2071731949
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.2138937792 - test_loss: 0.2059965466
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.2134114378 - test_loss: 0.2051935427
-------- Save Best Model! --------
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.2129814497 - test_loss: 0.2044218281
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.2124841749 - test_loss: 0.2038269375
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.2121544061 - test_loss: 0.2032123584
-------- Save Best Model! --------
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.2118302396 - test_loss: 0.2020739736
-------- Save Best Model! --------
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.2113833258 - test_loss: 0.2014947547
-------- Save Best Model! --------
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.2110993623 - test_loss: 0.2010595641
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.2107460271 - test_loss: 0.2004764229
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.2104383007 - test_loss: 0.2000401899
-------- Save Best Model! --------
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.2101924734 - test_loss: 0.1994106990
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 114 - loss: 0.2099240076 - test_loss: 0.1986969701
-------- Save Best Model! --------
Epoch: 48 - loss: 0.2182153375 - test_loss: 0.1965235179
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2178807328 - test_loss: 0.1962820461
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2176010263 - test_loss: 0.1959927693
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2173230458 - test_loss: 0.1955293168
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2171113181 - test_loss: 0.1953244730
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2169015454 - test_loss: 0.1950287559
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2166597415 - test_loss: 0.1946220690
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2164667537 - test_loss: 0.1945930223
-------- Save Best Model! --------
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2162696194 - test_loss: 0.1944172875
-------- Save Best Model! --------
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2160281080 - test_loss: 0.1940389038
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2156733370 - test_loss: 0.1935141834
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2153202277 - test_loss: 0.1932332325
-------- Save Best Model! --------
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2147597838 - test_loss: 0.1923286794
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2140546738 - test_loss: 0.1916355882
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2134078433 - test_loss: 0.1908657141
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2128503725 - test_loss: 0.1900591791
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2124259430 - test_loss: 0.1895699516
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.2118646682 - test_loss: 0.1892162962
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.2114116452 - test_loss: 0.1883247678
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.2109094742 - test_loss: 0.1875704752
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.2105152357 - test_loss: 0.1870028074
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.2101208626 - test_loss: 0.1864957839
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.2096615782 - test_loss: 0.1860657259
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.2092493114 - test_loss: 0.1853111905
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.2088442124 - test_loss: 0.1850607596
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.2083252654 - test_loss: 0.1839833241
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.2077773008 - test_loss: 0.1829768203
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.2071656018 - test_loss: 0.1823592119
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.2064560948 - test_loss: 0.1812181488
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.2057288331 - test_loss: 0.1803395108
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.2047744476 - test_loss: 0.1790560957
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.2037726840 - test_loss: 0.1777842962
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.2028106741 - test_loss: 0.1764418728
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.2016559949 - test_loss: 0.1750781711
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.2005804332 - test_loss: 0.1735225480
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.1995021415 - test_loss: 0.1718850258
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.1984199736 - test_loss: 0.1705859560
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.1973515773 - test_loss: 0.1691274491
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.1962709852 - test_loss: 0.1679890391
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.1951602825 - test_loss: 0.1663959778
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.1941263008 - test_loss: 0.1651209317
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.1930400079 - test_loss: 0.1636430471
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.1919303773 - test_loss: 0.1621795797
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.1908692231 - test_loss: 0.1609488888
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.1897456825 - test_loss: 0.1592923270
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.1886569184 - test_loss: 0.1577973719
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.1877168644 - test_loss: 0.1566003990
-------- Save Best Model! --------
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.1868636841 - test_loss: 0.1554479423
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.1859225997 - test_loss: 0.1542536074
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.1851616103 - test_loss: 0.1531964095
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.1844409321 - test_loss: 0.1523651124
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.1837059147 - test_loss: 0.1512099555
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.1831331209 - test_loss: 0.1501703642
-------- Save Best Model! --------
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.1825061953 - test_loss: 0.1497410209
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.1820430752 - test_loss: 0.1491517609
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.1814271890 - test_loss: 0.1481553944
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.1808979938 - test_loss: 0.1476109458
-------- Save Best Model! --------
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.1804189689 - test_loss: 0.1467660421
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.1798162303 - test_loss: 0.1458249066
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.1794345255 - test_loss: 0.1454762134
-------- Save Best Model! --------
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.1789831372 - test_loss: 0.1449061165
-------- Save Best Model! --------
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.1784328439 - test_loss: 0.1441091526
-------- Save Best Model! --------
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.1780155002 - test_loss: 0.1435283150
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.1775813747 - test_loss: 0.1429104500
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.1771611094 - test_loss: 0.1424057699
-------- Save Best Model! --------
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.1768158567 - test_loss: 0.1417947247
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 48 - loss: 0.2302041502 - test_loss: 0.2227404736
-------- Save Best Model! --------
------- START EPOCH 49 -------
Epoch: 49 - loss: 0.2299875392 - test_loss: 0.2226583168
-------- Save Best Model! --------
------- START EPOCH 50 -------
Epoch: 50 - loss: 0.2298175770 - test_loss: 0.2224113009
-------- Save Best Model! --------
------- START EPOCH 51 -------
Epoch: 51 - loss: 0.2296496901 - test_loss: 0.2219826771
-------- Save Best Model! --------
------- START EPOCH 52 -------
Epoch: 52 - loss: 0.2295329093 - test_loss: 0.2218213313
-------- Save Best Model! --------
------- START EPOCH 53 -------
Epoch: 53 - loss: 0.2294182805 - test_loss: 0.2215949382
-------- Save Best Model! --------
------- START EPOCH 54 -------
Epoch: 54 - loss: 0.2292856426 - test_loss: 0.2212898677
-------- Save Best Model! --------
------- START EPOCH 55 -------
Epoch: 55 - loss: 0.2291957043 - test_loss: 0.2214823645
Early Stop Left: 4
------- START EPOCH 56 -------
Epoch: 56 - loss: 0.2291098185 - test_loss: 0.2213868974
Early Stop Left: 3
------- START EPOCH 57 -------
Epoch: 57 - loss: 0.2290092039 - test_loss: 0.2211872062
-------- Save Best Model! --------
------- START EPOCH 58 -------
Epoch: 58 - loss: 0.2288639967 - test_loss: 0.2207841004
-------- Save Best Model! --------
------- START EPOCH 59 -------
Epoch: 59 - loss: 0.2287751458 - test_loss: 0.2208678954
Early Stop Left: 4
------- START EPOCH 60 -------
Epoch: 60 - loss: 0.2286486252 - test_loss: 0.2204085292
-------- Save Best Model! --------
------- START EPOCH 61 -------
Epoch: 61 - loss: 0.2285043208 - test_loss: 0.2203522236
-------- Save Best Model! --------
------- START EPOCH 62 -------
Epoch: 62 - loss: 0.2283515493 - test_loss: 0.2200702612
-------- Save Best Model! --------
------- START EPOCH 63 -------
Epoch: 63 - loss: 0.2281973962 - test_loss: 0.2198111000
-------- Save Best Model! --------
------- START EPOCH 64 -------
Epoch: 64 - loss: 0.2280792732 - test_loss: 0.2196290628
-------- Save Best Model! --------
------- START EPOCH 65 -------
Epoch: 65 - loss: 0.2278386920 - test_loss: 0.2194381646
-------- Save Best Model! --------
------- START EPOCH 66 -------
Epoch: 66 - loss: 0.2276440352 - test_loss: 0.2191029995
-------- Save Best Model! --------
------- START EPOCH 67 -------
Epoch: 67 - loss: 0.2273712546 - test_loss: 0.2185306926
-------- Save Best Model! --------
------- START EPOCH 68 -------
Epoch: 68 - loss: 0.2271644790 - test_loss: 0.2184423107
-------- Save Best Model! --------
------- START EPOCH 69 -------
Epoch: 69 - loss: 0.2268735332 - test_loss: 0.2177446728
-------- Save Best Model! --------
------- START EPOCH 70 -------
Epoch: 70 - loss: 0.2265528891 - test_loss: 0.2173313496
-------- Save Best Model! --------
------- START EPOCH 71 -------
Epoch: 71 - loss: 0.2262412305 - test_loss: 0.2166301763
-------- Save Best Model! --------
------- START EPOCH 72 -------
Epoch: 72 - loss: 0.2259100020 - test_loss: 0.2161883798
-------- Save Best Model! --------
------- START EPOCH 73 -------
Epoch: 73 - loss: 0.2255027908 - test_loss: 0.2152320001
-------- Save Best Model! --------
------- START EPOCH 74 -------
Epoch: 74 - loss: 0.2250868172 - test_loss: 0.2141464918
-------- Save Best Model! --------
------- START EPOCH 75 -------
Epoch: 75 - loss: 0.2246577667 - test_loss: 0.2133724760
-------- Save Best Model! --------
------- START EPOCH 76 -------
Epoch: 76 - loss: 0.2242048811 - test_loss: 0.2128409567
-------- Save Best Model! --------
------- START EPOCH 77 -------
Epoch: 77 - loss: 0.2237930308 - test_loss: 0.2121156788
-------- Save Best Model! --------
------- START EPOCH 78 -------
Epoch: 78 - loss: 0.2232656513 - test_loss: 0.2111947220
-------- Save Best Model! --------
------- START EPOCH 79 -------
Epoch: 79 - loss: 0.2227515025 - test_loss: 0.2105308306
-------- Save Best Model! --------
------- START EPOCH 80 -------
Epoch: 80 - loss: 0.2223150472 - test_loss: 0.2094858038
-------- Save Best Model! --------
------- START EPOCH 81 -------
Epoch: 81 - loss: 0.2217622361 - test_loss: 0.2089627406
-------- Save Best Model! --------
------- START EPOCH 82 -------
Epoch: 82 - loss: 0.2212784183 - test_loss: 0.2080023024
-------- Save Best Model! --------
------- START EPOCH 83 -------
Epoch: 83 - loss: 0.2207912250 - test_loss: 0.2066724124
-------- Save Best Model! --------
------- START EPOCH 84 -------
Epoch: 84 - loss: 0.2203117475 - test_loss: 0.2062989802
-------- Save Best Model! --------
------- START EPOCH 85 -------
Epoch: 85 - loss: 0.2198557622 - test_loss: 0.2056962289
-------- Save Best Model! --------
------- START EPOCH 86 -------
Epoch: 86 - loss: 0.2194094918 - test_loss: 0.2051123341
-------- Save Best Model! --------
------- START EPOCH 87 -------
Epoch: 87 - loss: 0.2189484044 - test_loss: 0.2042614550
-------- Save Best Model! --------
------- START EPOCH 88 -------
Epoch: 88 - loss: 0.2185212898 - test_loss: 0.2038848219
-------- Save Best Model! --------
------- START EPOCH 89 -------
Epoch: 89 - loss: 0.2181238526 - test_loss: 0.2028405718
-------- Save Best Model! --------
------- START EPOCH 90 -------
Epoch: 90 - loss: 0.2176405010 - test_loss: 0.2025300145
-------- Save Best Model! --------
------- START EPOCH 91 -------
Epoch: 91 - loss: 0.2172089787 - test_loss: 0.2017904465
-------- Save Best Model! --------
------- START EPOCH 92 -------
Epoch: 92 - loss: 0.2166845158 - test_loss: 0.2008187454
-------- Save Best Model! --------
------- START EPOCH 93 -------
Epoch: 93 - loss: 0.2161021593 - test_loss: 0.1996781074
-------- Save Best Model! --------
------- START EPOCH 94 -------
Epoch: 94 - loss: 0.2155670399 - test_loss: 0.1989260461
-------- Save Best Model! --------
------- START EPOCH 95 -------
Epoch: 95 - loss: 0.2149584466 - test_loss: 0.1981956714
-------- Save Best Model! --------
------- START EPOCH 96 -------
Epoch: 96 - loss: 0.2142143406 - test_loss: 0.1972517714
-------- Save Best Model! --------
------- START EPOCH 97 -------
Epoch: 97 - loss: 0.2134877966 - test_loss: 0.1955950536
-------- Save Best Model! --------
------- START EPOCH 98 -------
Epoch: 98 - loss: 0.2127727452 - test_loss: 0.1943829555
-------- Save Best Model! --------
------- START EPOCH 99 -------
Epoch: 99 - loss: 0.2120115224 - test_loss: 0.1934746024
-------- Save Best Model! --------
------- START EPOCH 100 -------
Epoch: 100 - loss: 0.2113849780 - test_loss: 0.1922733896
-------- Save Best Model! --------
------- START EPOCH 101 -------
Epoch: 101 - loss: 0.2107708080 - test_loss: 0.1913631589
-------- Save Best Model! --------
------- START EPOCH 102 -------
Epoch: 102 - loss: 0.2102518930 - test_loss: 0.1903695761
-------- Save Best Model! --------
------- START EPOCH 103 -------
Epoch: 103 - loss: 0.2096981353 - test_loss: 0.1893410608
-------- Save Best Model! --------
------- START EPOCH 104 -------
Epoch: 104 - loss: 0.2092384491 - test_loss: 0.1885387670
-------- Save Best Model! --------
------- START EPOCH 105 -------
Epoch: 105 - loss: 0.2088243133 - test_loss: 0.1882175792
-------- Save Best Model! --------
------- START EPOCH 106 -------
Epoch: 106 - loss: 0.2083436589 - test_loss: 0.1872835992
-------- Save Best Model! --------
------- START EPOCH 107 -------
Epoch: 107 - loss: 0.2080564267 - test_loss: 0.1868623820
-------- Save Best Model! --------
------- START EPOCH 108 -------
Epoch: 108 - loss: 0.2077600408 - test_loss: 0.1859519560
-------- Save Best Model! --------
------- START EPOCH 109 -------
Epoch: 109 - loss: 0.2073290692 - test_loss: 0.1855042408
-------- Save Best Model! --------
------- START EPOCH 110 -------
Epoch: 110 - loss: 0.2070804617 - test_loss: 0.1850710573
-------- Save Best Model! --------
------- START EPOCH 111 -------
Epoch: 111 - loss: 0.2067518012 - test_loss: 0.1845954589
-------- Save Best Model! --------
------- START EPOCH 112 -------
Epoch: 112 - loss: 0.2064622516 - test_loss: 0.1839575691
-------- Save Best Model! --------
------- START EPOCH 113 -------
Epoch: 113 - loss: 0.2062450281 - test_loss: 0.1836390306
-------- Save Best Model! --------
------- START EPOCH 114 -------
Epoch: 114 - loss: 0.2059868381 - test_loss: 0.1831549184
-------- Save Best Model! --------
Epoch: 114 - loss: 0.1681341424 - test_loss: 0.1353155303
-------- Save Best Model! --------
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.1677837446 - test_loss: 0.1345318249
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.1674484278 - test_loss: 0.1344338704
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.1670938559 - test_loss: 0.1335909470
-------- Save Best Model! --------
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.1667872063 - test_loss: 0.1334630630
-------- Save Best Model! --------
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.1665067658 - test_loss: 0.1331435076
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.1662384571 - test_loss: 0.1329028924
-------- Save Best Model! --------
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.1658836584 - test_loss: 0.1322366588
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.1656072795 - test_loss: 0.1317464901
-------- Save Best Model! --------
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.1653298352 - test_loss: 0.1316331490
-------- Save Best Model! --------
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.1650413973 - test_loss: 0.1314198239
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.1648428898 - test_loss: 0.1306107193
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.1645063515 - test_loss: 0.1302018517
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.1643785220 - test_loss: 0.1302365274
Early Stop Left: 4
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.1640984228 - test_loss: 0.1301293595
-------- Save Best Model! --------
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.1638757358 - test_loss: 0.1294859694
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.1637434643 - test_loss: 0.1300665932
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.1634236355 - test_loss: 0.1289008438
-------- Save Best Model! --------
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.1633343961 - test_loss: 0.1291668005
Early Stop Left: 4
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.1630995017 - test_loss: 0.1284981065
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.1629421984 - test_loss: 0.1280379862
-------- Save Best Model! --------
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.1627684643 - test_loss: 0.1284845298
Early Stop Left: 4
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.1625794890 - test_loss: 0.1279920245
-------- Save Best Model! --------
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.1623994857 - test_loss: 0.1281252345
Early Stop Left: 4
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.1622973744 - test_loss: 0.1276153820
-------- Save Best Model! --------
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.1620189697 - test_loss: 0.1270902890
-------- Save Best Model! --------
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.1619137218 - test_loss: 0.1271219040
Early Stop Left: 4
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.1617697678 - test_loss: 0.1267244747
-------- Save Best Model! --------
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.1615398945 - test_loss: 0.1273713058
Early Stop Left: 4
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.1614242670 - test_loss: 0.1263262330
-------- Save Best Model! --------
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.1612187774 - test_loss: 0.1259098855
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.1610787089 - test_loss: 0.1259411071
Early Stop Left: 4
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.1609107590 - test_loss: 0.1260647325
Early Stop Left: 3
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.1608228507 - test_loss: 0.1253525531
-------- Save Best Model! --------
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.1606648596 - test_loss: 0.1253069937
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.1604941083 - test_loss: 0.1257361137
Early Stop Left: 4
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.1603383321 - test_loss: 0.1249772691
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.1602406777 - test_loss: 0.1252584520
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.1600364794 - test_loss: 0.1242060228
-------- Save Best Model! --------
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.1599091502 - test_loss: 0.1245522969
Early Stop Left: 4
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.1597983543 - test_loss: 0.1246400885
Early Stop Left: 3
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.1597153464 - test_loss: 0.1243240440
Early Stop Left: 2
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.1595257459 - test_loss: 0.1241944398
-------- Save Best Model! --------
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.1594317934 - test_loss: 0.1242254924
Early Stop Left: 4
------- START EPOCH 158 -------
Epoch: 158 - loss: 0.1592922347 - test_loss: 0.1237021803
-------- Save Best Model! --------
------- START EPOCH 159 -------
Epoch: 159 - loss: 0.1591682022 - test_loss: 0.1231708855
-------- Save Best Model! --------
------- START EPOCH 160 -------
Epoch: 160 - loss: 0.1590403518 - test_loss: 0.1233121751
Early Stop Left: 4
------- START EPOCH 161 -------
Epoch: 161 - loss: 0.1588592426 - test_loss: 0.1224337178
-------- Save Best Model! --------
------- START EPOCH 162 -------
Epoch: 162 - loss: 0.1587209309 - test_loss: 0.1227813028
Early Stop Left: 4
------- START EPOCH 163 -------
Epoch: 163 - loss: 0.1587280480 - test_loss: 0.1226573782
Early Stop Left: 3
------- START EPOCH 164 -------
Epoch: 164 - loss: 0.1585051406 - test_loss: 0.1230030747
Early Stop Left: 2
------- START EPOCH 165 -------
Epoch: 165 - loss: 0.1583822835 - test_loss: 0.1225273557
Early Stop Left: 1
------- START EPOCH 166 -------
Epoch: 166 - loss: 0.1582417583 - test_loss: 0.1222585827
-------- Save Best Model! --------
------- START EPOCH 167 -------
Epoch: 167 - loss: 0.1581017420 - test_loss: 0.1218151626
-------- Save Best Model! --------
------- START EPOCH 168 -------
Epoch: 168 - loss: 0.1579572228 - test_loss: 0.1221710810
Early Stop Left: 4
------- START EPOCH 169 -------
Epoch: 169 - loss: 0.1577727968 - test_loss: 0.1228843278
Early Stop Left: 3
------- START EPOCH 170 -------
Epoch: 170 - loss: 0.1576968428 - test_loss: 0.1215739973
-------- Save Best Model! --------
------- START EPOCH 171 -------
Epoch: 171 - loss: 0.1575405293 - test_loss: 0.1214638223
-------- Save Best Model! --------
------- START EPOCH 172 -------
Epoch: 172 - loss: 0.1573742719 - test_loss: 0.1213552029
-------- Save Best Model! --------
------- START EPOCH 173 -------
Epoch: 173 - loss: 0.1571733290 - test_loss: 0.1212762036
-------- Save Best Model! --------
------- START EPOCH 174 -------
Epoch: 174 - loss: 0.1571479763 - test_loss: 0.1214765272
Early Stop Left: 4
------- START EPOCH 175 -------
Epoch: 175 - loss: 0.1569295197 - test_loss: 0.1207428660
-------- Save Best Model! --------
------- START EPOCH 176 -------
Epoch: 176 - loss: 0.1567900822 - test_loss: 0.1202737153
-------- Save Best Model! --------
------- START EPOCH 177 -------
Epoch: 177 - loss: 0.1565958371 - test_loss: 0.1202598813
-------- Save Best Model! --------
------- START EPOCH 178 -------
Epoch: 178 - loss: 0.1564302307 - test_loss: 0.1199582794
-------- Save Best Model! --------
------- START EPOCH 179 -------
Epoch: 179 - loss: 0.1563016985 - test_loss: 0.1198660461
-------- Save Best Model! --------
------- START EPOCH 180 -------
Epoch: 180 - loss: 0.1561385848 - test_loss: 0.1196226042
-------- Save Best Model! --------
------- START EPOCH 181 -------
Epoch: 181 - loss: 0.1559373170 - test_loss: 0.1198312169
Early Stop Left: 4
------- START EPOCH 182 -------
Epoch: 182 - loss: 0.1557272049 - test_loss: 0.1186522978
-------- Save Best Model! --------
------- START EPOCH 183 -------
Epoch: 183 - loss: 0.1555928956 - test_loss: 0.1189514268
Early Stop Left: 4
------- START EPOCH 184 -------
Epoch: 184 - loss: 0.1553360056 - test_loss: 0.1184271479
-------- Save Best Model! --------
------- START EPOCH 185 -------
Epoch: 185 - loss: 0.1551790822 - test_loss: 0.1181815266
-------- Save Best Model! --------
------- START EPOCH 186 -------
Epoch: 186 - loss: 0.1550184943 - test_loss: 0.1178389472
-------- Save Best Model! --------
------- START EPOCH 187 -------
Epoch: 187 - loss: 0.1547597858 - test_loss: 0.1181082747
Early Stop Left: 4
------- START EPOCH 188 -------
Epoch: 188 - loss: 0.1545439277 - test_loss: 0.1171661790
-------- Save Best Model! --------
------- START EPOCH 189 -------
Epoch: 189 - loss: 0.1543886004 - test_loss: 0.1177996299
Early Stop Left: 4
------- START EPOCH 190 -------
Epoch: 190 - loss: 0.1541875046 - test_loss: 0.1170184852
-------- Save Best Model! --------
------- START EPOCH 191 -------
Epoch: 191 - loss: 0.1539423682 - test_loss: 0.1164852711
-------- Save Best Model! --------
------- START EPOCH 192 -------
Epoch: 192 - loss: 0.1537398792 - test_loss: 0.1163876025
-------- Save Best Model! --------
------- START EPOCH 193 -------
Epoch: 193 - loss: 0.1535408350 - test_loss: 0.1166845389
Early Stop Left: 4
------- START EPOCH 194 -------
Epoch: 194 - loss: 0.1534018132 - test_loss: 0.1155615720
-------- Save Best Model! --------
------- START EPOCH 195 -------
Epoch: 195 - loss: 0.1531910997 - test_loss: 0.1157443870
Early Stop Left: 4
------- START EPOCH 196 -------
Epoch: 196 - loss: 0.1530106838 - test_loss: 0.1161425019
Early Stop Left: 3
------- START EPOCH 197 -------
Epoch: 197 - loss: 0.1528121231 - test_loss: 0.1153917882
-------- Save Best Model! --------
------- START EPOCH 198 -------
Epoch: 198 - loss: 0.1526318210 - test_loss: 0.1153228902
-------- Save Best Model! --------
------- START EPOCH 199 -------
Epoch: 199 - loss: 0.1524467063 - test_loss: 0.1143621816
-------- Save Best Model! --------
------- START EPOCH 200 -------
Epoch: 200 - loss: 0.1522202455 - test_loss: 0.1145361819
Early Stop Left: 4
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 17%|█▋        | 20/121 [00:00<00:00, 194.15it/s] 33%|███▎      | 40/121 [00:00<00:00, 194.21it/s] 50%|████▉     | 60/121 [00:00<00:00, 194.41it/s] 66%|██████▌   | 80/121 [00:00<00:00, 194.71it/s] 83%|████████▎ | 100/121 [00:00<00:00, 189.96it/s] 99%|█████████▉| 120/121 [00:00<00:00, 189.38it/s]100%|██████████| 121/121 [00:00<00:00, 192.20it/s]
Best micro threshold=0.349917, fscore=0.738
p,r,f1: 0.6944158154176296 0.7883993955596885 0.7384291786182949
throttleing by fixed threshold: 0.5
p,r,f1: 0.7918142912431126 0.6563741330543609 0.7177607695723355
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3499171733856201,
                 'p': 0.6944158154176296,
                 'r': 0.7883993955596885,
                 'f1': 0.7384291786182949},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.7918142912431126,
                 'r': 0.6563741330543609,
                 'f1': 0.7177607695723355}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
Epoch: 114 - loss: 0.1764174368 - test_loss: 0.1413882669
-------- Save Best Model! --------
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.1760794003 - test_loss: 0.1406105475
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.1757563083 - test_loss: 0.1405162676
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.1754144940 - test_loss: 0.1396034458
-------- Save Best Model! --------
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.1751270952 - test_loss: 0.1395704878
-------- Save Best Model! --------
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.1748533951 - test_loss: 0.1392028425
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.1745939819 - test_loss: 0.1389779727
-------- Save Best Model! --------
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.1742597180 - test_loss: 0.1383290164
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.1739961320 - test_loss: 0.1377738486
-------- Save Best Model! --------
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.1737326372 - test_loss: 0.1376788414
-------- Save Best Model! --------
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.1734568150 - test_loss: 0.1374515866
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.1732665502 - test_loss: 0.1366423340
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.1729543892 - test_loss: 0.1362121090
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.1728307294 - test_loss: 0.1362475555
Early Stop Left: 4
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.1725643961 - test_loss: 0.1361312127
-------- Save Best Model! --------
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.1723530852 - test_loss: 0.1354959724
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.1722292365 - test_loss: 0.1360616734
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.1719267260 - test_loss: 0.1349365855
-------- Save Best Model! --------
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.1718461810 - test_loss: 0.1351302458
Early Stop Left: 4
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.1716223648 - test_loss: 0.1345661435
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.1714725536 - test_loss: 0.1340989832
-------- Save Best Model! --------
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.1713154567 - test_loss: 0.1345073999
Early Stop Left: 4
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.1711401664 - test_loss: 0.1339436136
-------- Save Best Model! --------
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.1709691917 - test_loss: 0.1342355849
Early Stop Left: 4
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.1708731811 - test_loss: 0.1337080372
-------- Save Best Model! --------
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.1706182559 - test_loss: 0.1331269442
-------- Save Best Model! --------
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.1705203291 - test_loss: 0.1331795812
Early Stop Left: 4
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.1703846405 - test_loss: 0.1328005907
-------- Save Best Model! --------
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.1701716985 - test_loss: 0.1335005600
Early Stop Left: 4
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.1700638694 - test_loss: 0.1324815464
-------- Save Best Model! --------
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.1698765464 - test_loss: 0.1320945023
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.1697440871 - test_loss: 0.1320934625
-------- Save Best Model! --------
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.1695850594 - test_loss: 0.1321316004
Early Stop Left: 4
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.1695064272 - test_loss: 0.1315000102
-------- Save Best Model! --------
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.1693633255 - test_loss: 0.1314441794
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.1692006662 - test_loss: 0.1320112685
Early Stop Left: 4
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.1690585426 - test_loss: 0.1310878346
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.1689669769 - test_loss: 0.1314109826
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.1687759659 - test_loss: 0.1303394776
-------- Save Best Model! --------
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.1686577931 - test_loss: 0.1307213111
Early Stop Left: 4
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.1685523057 - test_loss: 0.1309068519
Early Stop Left: 3
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.1684765307 - test_loss: 0.1305131684
Early Stop Left: 2
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.1682997875 - test_loss: 0.1304219018
Early Stop Left: 1
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.1682071846 - test_loss: 0.1304326827
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 16%|█▌        | 19/121 [00:00<00:00, 188.39it/s] 31%|███▏      | 38/121 [00:00<00:00, 184.54it/s] 47%|████▋     | 57/121 [00:00<00:00, 185.19it/s] 63%|██████▎   | 76/121 [00:00<00:00, 181.55it/s] 79%|███████▊  | 95/121 [00:00<00:00, 180.34it/s] 94%|█████████▍| 114/121 [00:00<00:00, 174.86it/s]100%|██████████| 121/121 [00:00<00:00, 178.84it/s]------- START EPOCH 115 -------
Epoch: 115 - loss: 0.1987391742 - test_loss: 0.1682957732
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.1984845444 - test_loss: 0.1679433377
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.1981987135 - test_loss: 0.1671842585
-------- Save Best Model! --------
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.1979307071 - test_loss: 0.1673175585
Early Stop Left: 4
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.1977008621 - test_loss: 0.1667052419
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.1974321094 - test_loss: 0.1662345248
-------- Save Best Model! --------
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.1970761298 - test_loss: 0.1655831284
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.1967757350 - test_loss: 0.1653921172
-------- Save Best Model! --------
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.1964663440 - test_loss: 0.1645543950
-------- Save Best Model! --------
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.1961494767 - test_loss: 0.1640813136
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.1958841882 - test_loss: 0.1639318774
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.1954981427 - test_loss: 0.1633736316
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.1952607258 - test_loss: 0.1630395757
-------- Save Best Model! --------
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.1949204269 - test_loss: 0.1627708916
-------- Save Best Model! --------
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.1946261123 - test_loss: 0.1618964192
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.1944080957 - test_loss: 0.1622766395
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.1940510482 - test_loss: 0.1613667361
-------- Save Best Model! --------
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.1938411766 - test_loss: 0.1610304302
-------- Save Best Model! --------
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.1935686459 - test_loss: 0.1602248126
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.1933424916 - test_loss: 0.1599971690
-------- Save Best Model! --------
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.1931075583 - test_loss: 0.1596843986
-------- Save Best Model! --------
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.1928302836 - test_loss: 0.1592400371
-------- Save Best Model! --------
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.1925896827 - test_loss: 0.1590589008
-------- Save Best Model! --------
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.1924182225 - test_loss: 0.1585702431
-------- Save Best Model! --------
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.1921243289 - test_loss: 0.1580517493
-------- Save Best Model! --------
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.1919558161 - test_loss: 0.1577379646
-------- Save Best Model! --------
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.1917290390 - test_loss: 0.1574361188
-------- Save Best Model! --------
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.1914641836 - test_loss: 0.1569477089
-------- Save Best Model! --------
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.1912805356 - test_loss: 0.1569363082
-------- Save Best Model! --------
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.1910889526 - test_loss: 0.1562135622
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.1908593357 - test_loss: 0.1558591938
-------- Save Best Model! --------
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.1906773969 - test_loss: 0.1561773264
Early Stop Left: 4
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.1905223994 - test_loss: 0.1555856167
-------- Save Best Model! --------
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.1903509892 - test_loss: 0.1546735777
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.1901400184 - test_loss: 0.1546853962
Early Stop Left: 4
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.1899723627 - test_loss: 0.1545129759
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.1898210597 - test_loss: 0.1546756911
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.1896029326 - test_loss: 0.1537474893
-------- Save Best Model! --------
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.1894618840 - test_loss: 0.1537087621
-------- Save Best Model! --------
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.1893088942 - test_loss: 0.1538401930
Early Stop Left: 4
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.1891846231 - test_loss: 0.1534946310
-------- Save Best Model! --------
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.1889851514 - test_loss: 0.1525511005
-------- Save Best Model! --------
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.1888604891 - test_loss: 0.1535542133
Early Stop Left: 4
------- START EPOCH 158 -------
Epoch: 158 - loss: 0.1887113999 - test_loss: 0.1524910661
-------- Save Best Model! --------
------- START EPOCH 159 -------
Epoch: 159 - loss: 0.1885755164 - test_loss: 0.1521786808
-------- Save Best Model! --------
------- START EPOCH 160 -------
Epoch: 160 - loss: 0.1884365064 - test_loss: 0.1523791486
Early Stop Left: 4
------- START EPOCH 161 -------
Epoch: 161 - loss: 0.1882645388 - test_loss: 0.1510614695
-------- Save Best Model! --------
------- START EPOCH 162 -------
Epoch: 162 - loss: 0.1881226029 - test_loss: 0.1515938523
Early Stop Left: 4
------- START EPOCH 163 -------
Epoch: 163 - loss: 0.1880832316 - test_loss: 0.1514831097
Early Stop Left: 3
------- START EPOCH 164 -------
Epoch: 164 - loss: 0.1878803968 - test_loss: 0.1517569383
Early Stop Left: 2
------- START EPOCH 165 -------
Epoch: 165 - loss: 0.1877764746 - test_loss: 0.1510664904
Early Stop Left: 1
------- START EPOCH 166 -------
Epoch: 166 - loss: 0.1876223887 - test_loss: 0.1506906987
-------- Save Best Model! --------
------- START EPOCH 167 -------
Epoch: 167 - loss: 0.1875203118 - test_loss: 0.1503038456
-------- Save Best Model! --------
------- START EPOCH 168 -------
Epoch: 168 - loss: 0.1873408976 - test_loss: 0.1507192449
Early Stop Left: 4
------- START EPOCH 169 -------
Epoch: 169 - loss: 0.1871999938 - test_loss: 0.1505489474
Early Stop Left: 3
------- START EPOCH 170 -------
Epoch: 170 - loss: 0.1871137569 - test_loss: 0.1503259194
Early Stop Left: 2
------- START EPOCH 171 -------
Epoch: 171 - loss: 0.1869835283 - test_loss: 0.1498495037
-------- Save Best Model! --------
------- START EPOCH 172 -------
Epoch: 172 - loss: 0.1868672240 - test_loss: 0.1498461154
-------- Save Best Model! --------
------- START EPOCH 173 -------
Epoch: 173 - loss: 0.1866906618 - test_loss: 0.1496136333
-------- Save Best Model! --------
------- START EPOCH 174 -------
Epoch: 174 - loss: 0.1866694545 - test_loss: 0.1495219414
-------- Save Best Model! --------
------- START EPOCH 175 -------
Epoch: 175 - loss: 0.1864901847 - test_loss: 0.1493426558
-------- Save Best Model! --------
------- START EPOCH 176 -------
Epoch: 176 - loss: 0.1863942647 - test_loss: 0.1487362228
-------- Save Best Model! --------
------- START EPOCH 177 -------
Epoch: 177 - loss: 0.1862616990 - test_loss: 0.1492027294
Early Stop Left: 4
------- START EPOCH 178 -------
Epoch: 178 - loss: 0.1861358998 - test_loss: 0.1484687960
-------- Save Best Model! --------
------- START EPOCH 179 -------
Epoch: 179 - loss: 0.1860556216 - test_loss: 0.1482861243
-------- Save Best Model! --------
------- START EPOCH 180 -------
Epoch: 180 - loss: 0.1859667632 - test_loss: 0.1482506673
-------- Save Best Model! --------
------- START EPOCH 181 -------
Epoch: 181 - loss: 0.1858657635 - test_loss: 0.1484052862
Early Stop Left: 4
------- START EPOCH 182 -------
Epoch: 182 - loss: 0.1857325055 - test_loss: 0.1478455290
Best micro threshold=0.336526, fscore=0.715
p,r,f1: 0.6628878139603769 0.7769274284164439 0.715391405050908
throttleing by fixed threshold: 0.5
p,r,f1: 0.7778493010730463 0.6124096245495757 0.6852858696274252
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3365262448787689,
                 'p': 0.6628878139603769,
                 'r': 0.7769274284164439,
                 'f1': 0.715391405050908},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.7778493010730463,
                 'r': 0.6124096245495757,
                 'f1': 0.6852858696274252}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.2096746957 - test_loss: 0.1982832943
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.2094483237 - test_loss: 0.1974969216
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.2092129549 - test_loss: 0.1969428719
-------- Save Best Model! --------
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.2090005273 - test_loss: 0.1970443318
Early Stop Left: 4
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.2088306100 - test_loss: 0.1964939658
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.2086318053 - test_loss: 0.1960565242
-------- Save Best Model! --------
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.2083862458 - test_loss: 0.1953635016
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.2081856685 - test_loss: 0.1952932876
-------- Save Best Model! --------
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.2079941626 - test_loss: 0.1946566500
-------- Save Best Model! --------
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.2077907945 - test_loss: 0.1941753344
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.2076386310 - test_loss: 0.1943879118
Early Stop Left: 4
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.2073910769 - test_loss: 0.1938477646
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.2072508895 - test_loss: 0.1935140787
-------- Save Best Model! --------
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.2070380694 - test_loss: 0.1930797849
-------- Save Best Model! --------
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.2068593592 - test_loss: 0.1928217045
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.2067323668 - test_loss: 0.1930476968
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.2064821783 - test_loss: 0.1924853382
-------- Save Best Model! --------
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.2063475763 - test_loss: 0.1921025336
-------- Save Best Model! --------
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.2061610344 - test_loss: 0.1914275010
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.2060111303 - test_loss: 0.1914423624
Early Stop Left: 4
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.2058528962 - test_loss: 0.1910969945
-------- Save Best Model! --------
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.2056518997 - test_loss: 0.1907128954
-------- Save Best Model! --------
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.2054805384 - test_loss: 0.1903390641
-------- Save Best Model! --------
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.2053573768 - test_loss: 0.1896800407
-------- Save Best Model! --------
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.2051574261 - test_loss: 0.1897368346
Early Stop Left: 4
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.2050307158 - test_loss: 0.1893085467
-------- Save Best Model! --------
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.2048727604 - test_loss: 0.1894422923
Early Stop Left: 4
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.2046924080 - test_loss: 0.1889386680
-------- Save Best Model! --------
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.2045546635 - test_loss: 0.1889452028
Early Stop Left: 4
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.2044281510 - test_loss: 0.1885678586
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.2042520413 - test_loss: 0.1878653395
-------- Save Best Model! --------
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.2041391633 - test_loss: 0.1878928816
Early Stop Left: 4
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.2040418500 - test_loss: 0.1880076368
Early Stop Left: 3
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.2039250226 - test_loss: 0.1867912963
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.2037796808 - test_loss: 0.1869387250
Early Stop Left: 4
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.2036757101 - test_loss: 0.1866719295
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.2035916872 - test_loss: 0.1869482929
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.2034367180 - test_loss: 0.1861426302
-------- Save Best Model! --------
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.2033653095 - test_loss: 0.1861707037
Early Stop Left: 4
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.2032593823 - test_loss: 0.1863566721
Early Stop Left: 3
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.2031869703 - test_loss: 0.1860082494
-------- Save Best Model! --------
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.2030501084 - test_loss: 0.1853142224
-------- Save Best Model! --------
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.2029686938 - test_loss: 0.1862935908
Early Stop Left: 4
------- START EPOCH 158 -------
Epoch: 158 - loss: 0.2028914253 - test_loss: 0.1857874607
Early Stop Left: 3
------- START EPOCH 159 -------
Epoch: 159 - loss: 0.2028089293 - test_loss: 0.1854459121
Early Stop Left: 2
------- START EPOCH 160 -------
Epoch: 160 - loss: 0.2027125908 - test_loss: 0.1854190102
Early Stop Left: 1
------- START EPOCH 161 -------
Epoch: 161 - loss: 0.2026006003 - test_loss: 0.1840112443
-------- Save Best Model! --------
------- START EPOCH 162 -------
Epoch: 162 - loss: 0.2025221648 - test_loss: 0.1850839847
Early Stop Left: 4
------- START EPOCH 163 -------
Epoch: 163 - loss: 0.2025026178 - test_loss: 0.1843085985
Early Stop Left: 3
------- START EPOCH 164 -------
Epoch: 164 - loss: 0.2023800557 - test_loss: 0.1848147274
Early Stop Left: 2
------- START EPOCH 165 -------
Epoch: 165 - loss: 0.2023001403 - test_loss: 0.1846690583
Early Stop Left: 1
------- START EPOCH 166 -------
Epoch: 166 - loss: 0.2022062417 - test_loss: 0.1839330976
-------- Save Best Model! --------
------- START EPOCH 167 -------
Epoch: 167 - loss: 0.2021257133 - test_loss: 0.1837027430
-------- Save Best Model! --------
------- START EPOCH 168 -------
Epoch: 168 - loss: 0.2020249151 - test_loss: 0.1842510869
Early Stop Left: 4
------- START EPOCH 169 -------
Epoch: 169 - loss: 0.2019266053 - test_loss: 0.1836899250
-------- Save Best Model! --------
------- START EPOCH 170 -------
Epoch: 170 - loss: 0.2018705287 - test_loss: 0.1839745615
Early Stop Left: 4
------- START EPOCH 171 -------
Epoch: 171 - loss: 0.2017818767 - test_loss: 0.1833240277
-------- Save Best Model! --------
------- START EPOCH 172 -------
Epoch: 172 - loss: 0.2017163381 - test_loss: 0.1831790197
-------- Save Best Model! --------
------- START EPOCH 173 -------
Epoch: 173 - loss: 0.2015794853 - test_loss: 0.1828545719
-------- Save Best Model! --------
------- START EPOCH 174 -------
Epoch: 174 - loss: 0.2015594713 - test_loss: 0.1824643792
-------- Save Best Model! --------
------- START EPOCH 175 -------
Epoch: 175 - loss: 0.2014370427 - test_loss: 0.1822074421
-------- Save Best Model! --------
------- START EPOCH 176 -------
Epoch: 176 - loss: 0.2013630893 - test_loss: 0.1822505316
Early Stop Left: 4
------- START EPOCH 177 -------
Epoch: 177 - loss: 0.2012576419 - test_loss: 0.1826503643
Early Stop Left: 3
------- START EPOCH 178 -------
Epoch: 178 - loss: 0.2011720698 - test_loss: 0.1822402390
Early Stop Left: 2
------- START EPOCH 179 -------
Epoch: 179 - loss: 0.2011151557 - test_loss: 0.1816807881
-------- Save Best Model! --------
------- START EPOCH 180 -------
Epoch: 180 - loss: 0.2010354969 - test_loss: 0.1815544586
-------- Save Best Model! --------
------- START EPOCH 181 -------
Epoch: 181 - loss: 0.2009632027 - test_loss: 0.1815886473
Early Stop Left: 4
------- START EPOCH 182 -------
Epoch: 182 - loss: 0.2008538376 - test_loss: 0.1816835951
Early Stop Left: 3
------- START EPOCH 183 -------
Epoch: 183 - loss: 0.2007870607 - test_loss: 0.1816018798
Early Stop Left: 2
------- START EPOCH 184 -------
-------- Save Best Model! --------
------- START EPOCH 183 -------
Epoch: 183 - loss: 0.1856512866 - test_loss: 0.1481119627
Early Stop Left: 4
------- START EPOCH 184 -------
Epoch: 184 - loss: 0.1855255342 - test_loss: 0.1481651994
Early Stop Left: 3
------- START EPOCH 185 -------
Epoch: 185 - loss: 0.1854816264 - test_loss: 0.1477071048
-------- Save Best Model! --------
------- START EPOCH 186 -------
Epoch: 186 - loss: 0.1853801845 - test_loss: 0.1470893533
-------- Save Best Model! --------
------- START EPOCH 187 -------
Epoch: 187 - loss: 0.1852523735 - test_loss: 0.1474432296
Early Stop Left: 4
------- START EPOCH 188 -------
Epoch: 188 - loss: 0.1851480259 - test_loss: 0.1470425275
-------- Save Best Model! --------
------- START EPOCH 189 -------
Epoch: 189 - loss: 0.1850984812 - test_loss: 0.1470701453
Early Stop Left: 4
------- START EPOCH 190 -------
Epoch: 190 - loss: 0.1849821361 - test_loss: 0.1468304526
-------- Save Best Model! --------
------- START EPOCH 191 -------
Epoch: 191 - loss: 0.1848716468 - test_loss: 0.1465991027
-------- Save Best Model! --------
------- START EPOCH 192 -------
Epoch: 192 - loss: 0.1848213370 - test_loss: 0.1463214359
-------- Save Best Model! --------
------- START EPOCH 193 -------
Epoch: 193 - loss: 0.1846883435 - test_loss: 0.1472030432
Early Stop Left: 4
------- START EPOCH 194 -------
Epoch: 194 - loss: 0.1846253938 - test_loss: 0.1464637144
Early Stop Left: 3
------- START EPOCH 195 -------
Epoch: 195 - loss: 0.1845393694 - test_loss: 0.1464519232
Early Stop Left: 2
------- START EPOCH 196 -------
Epoch: 196 - loss: 0.1844899098 - test_loss: 0.1463926609
Early Stop Left: 1
------- START EPOCH 197 -------
Epoch: 197 - loss: 0.1843869855 - test_loss: 0.1460819789
-------- Save Best Model! --------
------- START EPOCH 198 -------
Epoch: 198 - loss: 0.1843124488 - test_loss: 0.1460994972
Early Stop Left: 4
------- START EPOCH 199 -------
Epoch: 199 - loss: 0.1842265687 - test_loss: 0.1456358800
-------- Save Best Model! --------
------- START EPOCH 200 -------
Epoch: 200 - loss: 0.1841020817 - test_loss: 0.1452849155
-------- Save Best Model! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 15%|█▍        | 18/121 [00:00<00:00, 172.12it/s] 30%|██▉       | 36/121 [00:00<00:00, 173.79it/s] 45%|████▍     | 54/121 [00:00<00:00, 176.08it/s] 60%|█████▉    | 72/121 [00:00<00:00, 173.25it/s] 74%|███████▍  | 90/121 [00:00<00:00, 173.21it/s] 89%|████████▉ | 108/121 [00:00<00:00, 172.25it/s]100%|██████████| 121/121 [00:00<00:00, 173.80it/s]
Epoch: 184 - loss: 0.2006877819 - test_loss: 0.1812551031
-------- Save Best Model! --------
------- START EPOCH 185 -------
Epoch: 185 - loss: 0.2006472682 - test_loss: 0.1815057196
Early Stop Left: 4
------- START EPOCH 186 -------
Epoch: 186 - loss: 0.2005620147 - test_loss: 0.1807502875
-------- Save Best Model! --------
------- START EPOCH 187 -------
Epoch: 187 - loss: 0.2004705886 - test_loss: 0.1808883718
Early Stop Left: 4
------- START EPOCH 188 -------
Epoch: 188 - loss: 0.2003593610 - test_loss: 0.1807567607
Early Stop Left: 3
------- START EPOCH 189 -------
Epoch: 189 - loss: 0.2003479083 - test_loss: 0.1802434197
-------- Save Best Model! --------
------- START EPOCH 190 -------
Epoch: 190 - loss: 0.2002305357 - test_loss: 0.1805177655
Early Stop Left: 4
------- START EPOCH 191 -------
Epoch: 191 - loss: 0.2001495634 - test_loss: 0.1799928531
-------- Save Best Model! --------
------- START EPOCH 192 -------
Epoch: 192 - loss: 0.2000871331 - test_loss: 0.1795547825
-------- Save Best Model! --------
------- START EPOCH 193 -------
Epoch: 193 - loss: 0.1999854732 - test_loss: 0.1804306273
Early Stop Left: 4
------- START EPOCH 194 -------
Epoch: 194 - loss: 0.1999280148 - test_loss: 0.1801343984
Early Stop Left: 3
------- START EPOCH 195 -------
Epoch: 195 - loss: 0.1998579886 - test_loss: 0.1800150784
Early Stop Left: 2
------- START EPOCH 196 -------
Epoch: 196 - loss: 0.1998018366 - test_loss: 0.1801895276
Early Stop Left: 1
------- START EPOCH 197 -------
Epoch: 197 - loss: 0.1997235162 - test_loss: 0.1793843758
-------- Save Best Model! --------
------- START EPOCH 198 -------
Epoch: 198 - loss: 0.1996384302 - test_loss: 0.1790416057
-------- Save Best Model! --------
------- START EPOCH 199 -------
Epoch: 199 - loss: 0.1995937431 - test_loss: 0.1789999295
-------- Save Best Model! --------
------- START EPOCH 200 -------
Epoch: 200 - loss: 0.1994543215 - test_loss: 0.1788245581
-------- Save Best Model! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 17%|█▋        | 20/121 [00:00<00:00, 195.75it/s] 33%|███▎      | 40/121 [00:00<00:00, 195.37it/s] 50%|████▉     | 60/121 [00:00<00:00, 195.62it/s] 66%|██████▌   | 80/121 [00:00<00:00, 195.54it/s] 83%|████████▎ | 100/121 [00:00<00:00, 195.43it/s] 99%|█████████▉| 120/121 [00:00<00:00, 195.05it/s]100%|██████████| 121/121 [00:00<00:00, 196.18it/s]
Best micro threshold=0.364787, fscore=0.725
p,r,f1: 0.6732072926031523 0.785694912627378 0.725114463526864
throttleing by fixed threshold: 0.5
p,r,f1: 0.7777909262687763 0.6315750319655934 0.6970983317011002
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3647867441177368,
                 'p': 0.6732072926031523,
                 'r': 0.785694912627378,
                 'f1': 0.725114463526864},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.7777909262687763,
                 'r': 0.6315750319655934,
                 'f1': 0.6970983317011002}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm

Best micro threshold=0.373910, fscore=0.710
p,r,f1: 0.652840813035619 0.7780464179162307 0.7099657402267721
throttleing by fixed threshold: 0.5
p,r,f1: 0.7691682742028223 0.6074656127707388 0.678819955594196
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3739103376865387,
                 'p': 0.652840813035619,
                 'r': 0.7780464179162307,
                 'f1': 0.7099657402267721},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.7691682742028223,
                 'r': 0.6074656127707388,
                 'f1': 0.678819955594196}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
------- START EPOCH 115 -------
Epoch: 115 - loss: 0.2057534385 - test_loss: 0.1824841050
-------- Save Best Model! --------
------- START EPOCH 116 -------
Epoch: 116 - loss: 0.2055354664 - test_loss: 0.1821636111
-------- Save Best Model! --------
------- START EPOCH 117 -------
Epoch: 117 - loss: 0.2052993432 - test_loss: 0.1814994606
-------- Save Best Model! --------
------- START EPOCH 118 -------
Epoch: 118 - loss: 0.2050828818 - test_loss: 0.1815249969
Early Stop Left: 4
------- START EPOCH 119 -------
Epoch: 119 - loss: 0.2049175625 - test_loss: 0.1809804231
-------- Save Best Model! --------
------- START EPOCH 120 -------
Epoch: 120 - loss: 0.2047087840 - test_loss: 0.1807458849
-------- Save Best Model! --------
------- START EPOCH 121 -------
Epoch: 121 - loss: 0.2044408738 - test_loss: 0.1801109832
-------- Save Best Model! --------
------- START EPOCH 122 -------
Epoch: 122 - loss: 0.2042231042 - test_loss: 0.1799627432
-------- Save Best Model! --------
------- START EPOCH 123 -------
Epoch: 123 - loss: 0.2040086700 - test_loss: 0.1793055566
-------- Save Best Model! --------
------- START EPOCH 124 -------
Epoch: 124 - loss: 0.2037948103 - test_loss: 0.1790273581
-------- Save Best Model! --------
------- START EPOCH 125 -------
Epoch: 125 - loss: 0.2036281615 - test_loss: 0.1790061572
-------- Save Best Model! --------
------- START EPOCH 126 -------
Epoch: 126 - loss: 0.2033407292 - test_loss: 0.1785651193
-------- Save Best Model! --------
------- START EPOCH 127 -------
Epoch: 127 - loss: 0.2031867233 - test_loss: 0.1785417444
-------- Save Best Model! --------
------- START EPOCH 128 -------
Epoch: 128 - loss: 0.2029372769 - test_loss: 0.1776991792
-------- Save Best Model! --------
------- START EPOCH 129 -------
Epoch: 129 - loss: 0.2027348245 - test_loss: 0.1775064510
-------- Save Best Model! --------
------- START EPOCH 130 -------
Epoch: 130 - loss: 0.2025892658 - test_loss: 0.1779202228
Early Stop Left: 4
------- START EPOCH 131 -------
Epoch: 131 - loss: 0.2022989956 - test_loss: 0.1768982805
-------- Save Best Model! --------
------- START EPOCH 132 -------
Epoch: 132 - loss: 0.2021469973 - test_loss: 0.1772847548
Early Stop Left: 4
------- START EPOCH 133 -------
Epoch: 133 - loss: 0.2019394090 - test_loss: 0.1762932613
-------- Save Best Model! --------
------- START EPOCH 134 -------
Epoch: 134 - loss: 0.2017561879 - test_loss: 0.1761887066
-------- Save Best Model! --------
------- START EPOCH 135 -------
Epoch: 135 - loss: 0.2015744743 - test_loss: 0.1758130013
-------- Save Best Model! --------
------- START EPOCH 136 -------
Epoch: 136 - loss: 0.2013413556 - test_loss: 0.1754161727
-------- Save Best Model! --------
------- START EPOCH 137 -------
Epoch: 137 - loss: 0.2011406596 - test_loss: 0.1751786824
-------- Save Best Model! --------
------- START EPOCH 138 -------
Epoch: 138 - loss: 0.2009927103 - test_loss: 0.1744443923
-------- Save Best Model! --------
------- START EPOCH 139 -------
Epoch: 139 - loss: 0.2007538989 - test_loss: 0.1742784950
-------- Save Best Model! --------
------- START EPOCH 140 -------
Epoch: 140 - loss: 0.2005997826 - test_loss: 0.1740474226
-------- Save Best Model! --------
------- START EPOCH 141 -------
Epoch: 141 - loss: 0.2004058891 - test_loss: 0.1735445422
-------- Save Best Model! --------
------- START EPOCH 142 -------
Epoch: 142 - loss: 0.2001975255 - test_loss: 0.1738194131
Early Stop Left: 4
------- START EPOCH 143 -------
Epoch: 143 - loss: 0.2000298946 - test_loss: 0.1731842173
-------- Save Best Model! --------
------- START EPOCH 144 -------
Epoch: 144 - loss: 0.1998653313 - test_loss: 0.1729295047
-------- Save Best Model! --------
------- START EPOCH 145 -------
Epoch: 145 - loss: 0.1996663995 - test_loss: 0.1724185452
-------- Save Best Model! --------
------- START EPOCH 146 -------
Epoch: 146 - loss: 0.1995146663 - test_loss: 0.1725604649
Early Stop Left: 4
------- START EPOCH 147 -------
Epoch: 147 - loss: 0.1993834155 - test_loss: 0.1720688491
-------- Save Best Model! --------
------- START EPOCH 148 -------
Epoch: 148 - loss: 0.1992421910 - test_loss: 0.1719079215
-------- Save Best Model! --------
------- START EPOCH 149 -------
Epoch: 149 - loss: 0.1990652233 - test_loss: 0.1715393600
-------- Save Best Model! --------
------- START EPOCH 150 -------
Epoch: 150 - loss: 0.1989288595 - test_loss: 0.1709807364
-------- Save Best Model! --------
------- START EPOCH 151 -------
Epoch: 151 - loss: 0.1988132765 - test_loss: 0.1710841242
Early Stop Left: 4
------- START EPOCH 152 -------
Epoch: 152 - loss: 0.1986299260 - test_loss: 0.1706061485
-------- Save Best Model! --------
------- START EPOCH 153 -------
Epoch: 153 - loss: 0.1985331126 - test_loss: 0.1703972648
-------- Save Best Model! --------
------- START EPOCH 154 -------
Epoch: 154 - loss: 0.1983977489 - test_loss: 0.1706203486
Early Stop Left: 4
------- START EPOCH 155 -------
Epoch: 155 - loss: 0.1983042236 - test_loss: 0.1703937805
-------- Save Best Model! --------
------- START EPOCH 156 -------
Epoch: 156 - loss: 0.1981464265 - test_loss: 0.1699876844
-------- Save Best Model! --------
------- START EPOCH 157 -------
Epoch: 157 - loss: 0.1980393261 - test_loss: 0.1705689004
Early Stop Left: 4
------- START EPOCH 158 -------
Epoch: 158 - loss: 0.1979266381 - test_loss: 0.1702123012
Early Stop Left: 3
------- START EPOCH 159 -------
Epoch: 159 - loss: 0.1978229922 - test_loss: 0.1697845431
-------- Save Best Model! --------
------- START EPOCH 160 -------
Epoch: 160 - loss: 0.1977243330 - test_loss: 0.1698556137
Early Stop Left: 4
------- START EPOCH 161 -------
Epoch: 161 - loss: 0.1975695877 - test_loss: 0.1682892012
-------- Save Best Model! --------
------- START EPOCH 162 -------
Epoch: 162 - loss: 0.1974700776 - test_loss: 0.1689667805
Early Stop Left: 4
------- START EPOCH 163 -------
Epoch: 163 - loss: 0.1974453342 - test_loss: 0.1685856754
Early Stop Left: 3
------- START EPOCH 164 -------
Epoch: 164 - loss: 0.1972863568 - test_loss: 0.1686700251
Early Stop Left: 2
------- START EPOCH 165 -------
Epoch: 165 - loss: 0.1972015459 - test_loss: 0.1684204969
Early Stop Left: 1
------- START EPOCH 166 -------
Epoch: 166 - loss: 0.1970808731 - test_loss: 0.1677410359
-------- Save Best Model! --------
------- START EPOCH 167 -------
Epoch: 167 - loss: 0.1969843082 - test_loss: 0.1677626453
Early Stop Left: 4
------- START EPOCH 168 -------
Epoch: 168 - loss: 0.1968588972 - test_loss: 0.1679720872
Early Stop Left: 3
------- START EPOCH 169 -------
Epoch: 169 - loss: 0.1967434911 - test_loss: 0.1677731023
Early Stop Left: 2
------- START EPOCH 170 -------
Epoch: 170 - loss: 0.1966744854 - test_loss: 0.1676341975
-------- Save Best Model! --------
------- START EPOCH 171 -------
Epoch: 171 - loss: 0.1965675613 - test_loss: 0.1672518220
-------- Save Best Model! --------
------- START EPOCH 172 -------
Epoch: 172 - loss: 0.1964954926 - test_loss: 0.1676997902
Early Stop Left: 4
------- START EPOCH 173 -------
Epoch: 173 - loss: 0.1963325707 - test_loss: 0.1668484949
-------- Save Best Model! --------
------- START EPOCH 174 -------
Epoch: 174 - loss: 0.1963201545 - test_loss: 0.1670333739
Early Stop Left: 4
------- START EPOCH 175 -------
Epoch: 175 - loss: 0.1961754714 - test_loss: 0.1665727697
-------- Save Best Model! --------
------- START EPOCH 176 -------
Epoch: 176 - loss: 0.1960940635 - test_loss: 0.1665548596
-------- Save Best Model! --------
------- START EPOCH 177 -------
Epoch: 177 - loss: 0.1959735524 - test_loss: 0.1664831758
-------- Save Best Model! --------
------- START EPOCH 178 -------
Epoch: 178 - loss: 0.1958852087 - test_loss: 0.1658232158
-------- Save Best Model! --------
------- START EPOCH 179 -------
Epoch: 179 - loss: 0.1958189054 - test_loss: 0.1662357575
Early Stop Left: 4
------- START EPOCH 180 -------
Epoch: 180 - loss: 0.1957293876 - test_loss: 0.1646750849
-------- Save Best Model! --------
------- START EPOCH 181 -------
Epoch: 181 - loss: 0.1956530682 - test_loss: 0.1656332560
Early Stop Left: 4
------- START EPOCH 182 -------
Epoch: 182 - loss: 0.1955256461 - test_loss: 0.1650292088
Early Stop Left: 3
------- START EPOCH 183 -------
Epoch: 183 - loss: 0.1954553792 - test_loss: 0.1656967171
Early Stop Left: 2
------- START EPOCH 184 -------
Epoch: 184 - loss: 0.1953438686 - test_loss: 0.1655504106
Early Stop Left: 1
------- START EPOCH 185 -------
Epoch: 185 - loss: 0.1953069181 - test_loss: 0.1651311554
Early Stop Left: 0
-------- Early Stop! --------
Validation start
  0%|          | 0/121 [00:00<?, ?it/s] 16%|█▌        | 19/121 [00:00<00:00, 186.21it/s] 31%|███▏      | 38/121 [00:00<00:00, 186.72it/s] 47%|████▋     | 57/121 [00:00<00:00, 187.35it/s] 63%|██████▎   | 76/121 [00:00<00:00, 186.59it/s] 79%|███████▊  | 95/121 [00:00<00:00, 185.31it/s] 94%|█████████▍| 114/121 [00:00<00:00, 185.25it/s]100%|██████████| 121/121 [00:00<00:00, 186.59it/s]
Best micro threshold=0.354876, fscore=0.708
p,r,f1: 0.6496155794946358 0.7769320779573017 0.7075924584975997
throttleing by fixed threshold: 0.5
p,r,f1: 0.777434778004936 0.5917191677321865 0.6719814981206829
{'model': 'vit',
 'app': '433.milc-s0.txt.xz',
 'validation': [{'method': 'micro precision f1',
                 'threshold': 0.3548758327960968,
                 'p': 0.6496155794946358,
                 'r': 0.7769320779573017,
                 'f1': 0.7075924584975997},
                {'method': 'fixed threshold 0.5',
                 'threshold': 0.5,
                 'p': 0.777434778004936,
                 'r': 0.5917191677321865,
                 'f1': 0.6719814981206829}]}
saving tensor pickle data
tensor data saved
saving test dataframe
done data saving for amm
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/122 [00:00<?, ?it/s]  1%|          | 1/122 [00:00<01:11,  1.70it/s] 27%|██▋       | 33/122 [00:00<00:01, 63.63it/s] 54%|█████▍    | 66/122 [00:00<00:00, 121.10it/s] 81%|████████  | 99/122 [00:00<00:00, 169.30it/s]100%|██████████| 122/122 [00:00<00:00, 126.45it/s]
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
           app  mean  max  min  median
0  433.milc-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/433.milc-s0.vit.stu.90.0.pkl.degree_stats.csv
Generation start
preprocessing_gen with context
b4 model prediction col0
 Index(['id', 'cycle', 'addr', 'ip', 'hit', 'raw', 'block_address',
       'page_address', 'page_offset', 'block_index', 'block_addr_delta',
       'patch', 'past', 'past_ip', 'past_page'],
      dtype='object')
predicting
  0%|          | 0/122 [00:00<?, ?it/s]  1%|          | 1/122 [00:00<01:18,  1.54it/s] 13%|█▎        | 16/122 [00:00<00:03, 28.09it/s] 25%|██▌       | 31/122 [00:00<00:01, 52.79it/s] 39%|███▊      | 47/122 [00:00<00:00, 75.92it/s] 52%|█████▏    | 63/122 [00:01<00:00, 94.83it/s] 65%|██████▍   | 79/122 [00:01<00:00, 109.65it/s] 77%|███████▋  | 94/122 [00:01<00:00, 120.05it/s] 90%|█████████ | 110/122 [00:01<00:00, 129.03it/s]100%|██████████| 122/122 [00:01<00:00, 83.76it/s] 
after model prediction col1
 Index(['id', 'cycle', 'addr', 'ip', 'block_address', 'y_score'], dtype='object')
post_processing, opt_threshold<0.9
after delta filter
 Index(['id', 'pred_hex'], dtype='object')
           app  mean  max  min  median
0  433.milc-s0   1.0  1.0  1.0     1.0
Done: results saved at: res/433.milc-s0.vitt.pkl.degree_stats.csv
Traceback (most recent call last):
  File "src/3_vit.py", line 5, in <module>
    import vq_amm
  File "/data/neelesh/DART_by_app/433/src/vq_amm.py", line 5, in <module>
    import vquantizers as vq
  File "/data/neelesh/DART_by_app/433/src/vquantizers.py", line 11, in <module>
    from utils import kmeans
ImportError: cannot import name 'kmeans' from 'utils' (/data/neelesh/DART_by_app/433/src/utils.py)
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/433/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/433/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.31, 0.446
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0431, 0.0241
--- total mse / var(X): 0.235
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0139, 0.0142
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0122, 0.0119
--- total mse / var(X): 0.013
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.182, 0.193
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.173, 0.163
--- total mse / var(X): 0.178
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.146, 0.15
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.173, 0.168
--- total mse / var(X): 0.159
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0307, 0.0202
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0168, 0.0226
--- total mse / var(X): 0.0214
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.228, 0.188
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.208, 0.244
--- total mse / var(X): 0.216
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00229, 0.00207
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0401, 0.044
--- total mse / var(X): 0.023
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0688, 0.0652
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.1, 0.106
--- total mse / var(X): 0.0854
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00162, 0.00124
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00244, 0.00301
--- total mse / var(X): 0.00212
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 1.01, 1.15
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 1.42, 1.22
--- total mse / var(X): 1.19
start table evaluation...
Elapsed time: 63.49085879325867 seconds
Cosine similarity between AMM and exact (Train): 0.6371986
Cosine similarity between AMM and exact (Test): 0.63790816
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.2660928873010718 0.26665581773799835 0.2663740551085101
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16],
               'cossim_layer_train': [0.9878972768783569,
                                      0.9797797203063965,
                                      0.9774407744407654,
                                      0.6371985673904419],
               'cossim_layer_test': [0.9871790409088135,
                                     0.9796370267868042,
                                     0.9771984219551086,
                                     0.6379081606864929],
               'cossim_amm_train': [0.9784223437309265,
                                    0.9939465522766113,
                                    0.9337385296821594,
                                    0.9030436277389526,
                                    0.9539899826049805,
                                    0.8732619285583496,
                                    0.9692774415016174,
                                    0.9013750553131104],
               'cossim_amm_test': [0.9774486422538757,
                                   0.9948012828826904,
                                   0.9340847730636597,
                                   0.9049980640411377,
                                   0.9537076950073242,
                                   0.8707717657089233,
                                   0.9700609445571899,
                                   0.9007870554924011],
               'f1': [0.2660928873010718,
                      0.26665581773799835,
                      0.2663740551085101],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 16),
                              (192, 2, 16),
                              (16, 16, 2),
                              (16, 16, 2),
                              (32, 2, 16),
                              (32, 2, 16),
                              (32, 2, 16),
                              (256, 2, 16)],
               'lut_total_size': 19456}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000004
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.216, 0.312
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0143, 0.00802
--- total mse / var(X): 0.16
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0101, 0.0103
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0101, 0.00983
--- total mse / var(X): 0.0101
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0485, 0.0512
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0354, 0.0334
--- total mse / var(X): 0.0423
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00554, 0.00567
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00486, 0.00475
--- total mse / var(X): 0.00521
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0067, 0.00643
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.004, 0.00416
--- total mse / var(X): 0.0053
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0951, 0.0787
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.104, 0.121
--- total mse / var(X): 0.1
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.01, 0.00928
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00136, 0.00147
--- total mse / var(X): 0.00537
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0118, 0.0112
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00964, 0.0102
--- total mse / var(X): 0.0107
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00194, 0.00147
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00633, 0.00787
--- total mse / var(X): 0.00467
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 1.93e-05, 1.79e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 4.77e-06, 5.12e-06
--- total mse / var(X): 1.15e-05
start table evaluation...
Elapsed time: 141.05197954177856 seconds
Cosine similarity between AMM and exact (Train): 0.7314537
Cosine similarity between AMM and exact (Test): 0.7337199
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.31480518759712867 0.5274392653725445 0.39428129516615357
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32],
               'cossim_layer_train': [0.9908063411712646,
                                      0.9923540353775024,
                                      0.9916070103645325,
                                      0.7314536571502686],
               'cossim_layer_test': [0.9904956817626953,
                                     0.9922200441360474,
                                     0.991584300994873,
                                     0.7337198257446289],
               'cossim_amm_train': [0.9836227893829346,
                                    0.9958662986755371,
                                    0.9853373169898987,
                                    0.9648828506469727,
                                    0.9854074716567993,
                                    0.9310585856437683,
                                    0.9819021821022034,
                                    0.884823203086853],
               'cossim_amm_test': [0.9832166433334351,
                                   0.9965816140174866,
                                   0.9857707619667053,
                                   0.9663742184638977,
                                   0.9852882027626038,
                                   0.9310212731361389,
                                   0.9828363656997681,
                                   0.8857997059822083],
               'f1': [0.31480518759712867,
                      0.5274392653725445,
                      0.39428129516615357],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 32),
                              (192, 2, 32),
                              (32, 32, 2),
                              (32, 32, 2),
                              (32, 2, 32),
                              (32, 2, 32),
                              (32, 2, 32),
                              (256, 2, 32)],
               'lut_total_size': 40960}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (8). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999999
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.153, 0.22
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0049, 0.00274
--- total mse / var(X): 0.111
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00789, 0.00807
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.008, 0.00781
--- total mse / var(X): 0.00794
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00192, 0.00203
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00312, 0.00294
--- total mse / var(X): 0.00248
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00363, 0.00371
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00343, 0.00334
--- total mse / var(X): 0.00353
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00523, 0.00506
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00889, 0.00918
--- total mse / var(X): 0.00712
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0269, 0.0222
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.0512, 0.06
--- total mse / var(X): 0.0411
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00104, 0.00102
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00241, 0.00246
--- total mse / var(X): 0.00174
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00932, 0.00884
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.009, 0.00946
--- total mse / var(X): 0.00915
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00379, 0.00284
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.00351, 0.00439
--- total mse / var(X): 0.00362
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 4.58e-05, 4.54e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 64, 8
mse / {var(X_subs), var(X)}: 0.000139, 0.00014
--- total mse / var(X): 9.29e-05
start table evaluation...
Elapsed time: 107.69911909103394 seconds
Cosine similarity between AMM and exact (Train): 0.72727835
Cosine similarity between AMM and exact (Test): 0.72964305
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.32214314332935057 0.5582626215661204 0.4085399775544311
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64,
                             64],
               'cossim_layer_train': [0.9935547113418579,
                                      0.9956998229026794,
                                      0.9947658777236938,
                                      0.7272783517837524],
               'cossim_layer_test': [0.9928322434425354,
                                     0.995557427406311,
                                     0.9946909546852112,
                                     0.7296430468559265],
               'cossim_amm_train': [0.9885321259498596,
                                    0.9968128800392151,
                                    0.9935378432273865,
                                    0.9831244945526123,
                                    0.9911244511604309,
                                    0.9351315498352051,
                                    0.987337052822113,
                                    0.8820642232894897],
               'cossim_amm_test': [0.987364649772644,
                                   0.9971989393234253,
                                   0.9939655661582947,
                                   0.9846240282058716,
                                   0.9911443591117859,
                                   0.933971107006073,
                                   0.9875293374061584,
                                   0.882313072681427],
               'f1': [0.32214314332935057,
                      0.5582626215661204,
                      0.4085399775544311],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 64),
                              (192, 2, 64),
                              (64, 64, 2),
                              (64, 64, 2),
                              (32, 2, 64),
                              (32, 2, 64),
                              (32, 2, 64),
                              (256, 2, 64)],
               'lut_total_size': 90112}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (12). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000001
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0997, 0.144
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.000837, 0.000467
--- total mse / var(X): 0.0721
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0064, 0.00655
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00655, 0.0064
--- total mse / var(X): 0.00648
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00187, 0.00197
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00225, 0.00212
--- total mse / var(X): 0.00205
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00285, 0.00292
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00257, 0.00251
--- total mse / var(X): 0.00271
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00309, 0.00296
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00525, 0.00548
--- total mse / var(X): 0.00422
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0128, 0.0106
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0127, 0.015
--- total mse / var(X): 0.0128
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0041, 0.00389
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00298, 0.00313
--- total mse / var(X): 0.00351
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0113, 0.0109
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0099, 0.0102
--- total mse / var(X): 0.0106
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00526, 0.00398
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00561, 0.00698
--- total mse / var(X): 0.00548
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00294, 0.00238
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00242, 0.00288
--- total mse / var(X): 0.00263
start table evaluation...
Elapsed time: 162.8422019481659 seconds
Cosine similarity between AMM and exact (Train): 0.7735973
Cosine similarity between AMM and exact (Test): 0.7693518
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.37072755199776136 0.5584904490681545 0.445638798989388
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9954763650894165,
                                      0.9973763227462769,
                                      0.996517539024353,
                                      0.7735974788665771],
               'cossim_layer_test': [0.9941223859786987,
                                     0.9971451163291931,
                                     0.9963867664337158,
                                     0.7693517804145813],
               'cossim_amm_train': [0.9919555187225342,
                                    0.9974570870399475,
                                    0.9952235817909241,
                                    0.9919753074645996,
                                    0.9948382377624512,
                                    0.9685657620429993,
                                    0.9916895031929016,
                                    0.9032127857208252],
               'cossim_amm_test': [0.9896330237388611,
                                   0.9976732730865479,
                                   0.995641827583313,
                                   0.9929438233375549,
                                   0.9949477910995483,
                                   0.9678125381469727,
                                   0.9918568730354309,
                                   0.9008933305740356],
               'f1': [0.37072755199776136,
                      0.5584904490681545,
                      0.445638798989388],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 128),
                              (192, 2, 128),
                              (128, 128, 2),
                              (128, 128, 2),
                              (32, 2, 128),
                              (32, 2, 128),
                              (32, 2, 128),
                              (256, 2, 128)],
               'lut_total_size': 212992}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (16). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999964
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.063, 0.0903
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 8.81e-05, 4.99e-05
--- total mse / var(X): 0.0452
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00489, 0.00501
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00463, 0.00452
--- total mse / var(X): 0.00477
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00182, 0.00193
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00234, 0.0022
--- total mse / var(X): 0.00207
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00248, 0.00254
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00259, 0.00253
--- total mse / var(X): 0.00253
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00267, 0.00254
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00385, 0.00403
--- total mse / var(X): 0.00329
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.006, 0.00496
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00922, 0.0108
--- total mse / var(X): 0.00789
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00797, 0.00761
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00581, 0.00607
--- total mse / var(X): 0.00684
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0102, 0.00992
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00924, 0.00949
--- total mse / var(X): 0.0097
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.0033, 0.00249
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00262, 0.00326
--- total mse / var(X): 0.00288
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00578, 0.00492
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 256, 16
mse / {var(X_subs), var(X)}: 0.00347, 0.00399
--- total mse / var(X): 0.00445
start table evaluation...
Elapsed time: 174.0098967552185 seconds
Cosine similarity between AMM and exact (Train): 0.7965148
Cosine similarity between AMM and exact (Test): 0.7918368
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.395028844439099 0.590490139098764 0.4733762437807082
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256,
                             256],
               'cossim_layer_train': [0.9971052408218384,
                                      0.9981481432914734,
                                      0.9973316788673401,
                                      0.7965149879455566],
               'cossim_layer_test': [0.9956114888191223,
                                     0.9979177713394165,
                                     0.9971502423286438,
                                     0.7918367385864258],
               'cossim_amm_train': [0.9948557019233704,
                                    0.9980908632278442,
                                    0.9962274432182312,
                                    0.9944407343864441,
                                    0.9962545037269592,
                                    0.9758994579315186,
                                    0.992824137210846,
                                    0.9227927923202515],
               'cossim_amm_test': [0.9922624826431274,
                                   0.9980869889259338,
                                   0.996577262878418,
                                   0.99500972032547,
                                   0.9963438510894775,
                                   0.9750922322273254,
                                   0.9925522208213806,
                                   0.9201642274856567],
               'f1': [0.395028844439099, 0.590490139098764, 0.4733762437807082],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 256),
                              (192, 2, 256),
                              (256, 256, 2),
                              (256, 256, 2),
                              (32, 2, 256),
                              (32, 2, 256),
                              (32, 2, 256),
                              (256, 2, 256)],
               'lut_total_size': 557056}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (23). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000001
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0371, 0.0534
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.000113, 6.32e-05
--- total mse / var(X): 0.0267
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00371, 0.00379
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00321, 0.00313
--- total mse / var(X): 0.00346
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00156, 0.00165
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0019, 0.0018
--- total mse / var(X): 0.00172
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00206, 0.00211
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00224, 0.00218
--- total mse / var(X): 0.00215
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00192, 0.00182
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00263, 0.00276
--- total mse / var(X): 0.00229
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00414, 0.00342
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00692, 0.00812
--- total mse / var(X): 0.00577
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00859, 0.00814
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00694, 0.0073
--- total mse / var(X): 0.00772
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.0073, 0.00713
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00608, 0.00621
--- total mse / var(X): 0.00667
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00328, 0.0025
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00225, 0.00279
--- total mse / var(X): 0.00264
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00817, 0.00674
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 512, 23
mse / {var(X_subs), var(X)}: 0.00672, 0.00789
--- total mse / var(X): 0.00732
start table evaluation...
Elapsed time: 286.08894181251526 seconds
Cosine similarity between AMM and exact (Train): 0.8375823
Cosine similarity between AMM and exact (Test): 0.8350864
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.4344913779635725 0.6250083304273703 0.5126206804502437
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512,
                             512],
               'cossim_layer_train': [0.9982388615608215,
                                      0.9987006187438965,
                                      0.998073399066925,
                                      0.8375823497772217],
               'cossim_layer_test': [0.9967085123062134,
                                     0.9984531998634338,
                                     0.9978481531143188,
                                     0.835086464881897],
               'cossim_amm_train': [0.9968646168708801,
                                    0.9986317753791809,
                                    0.9971203207969666,
                                    0.9960930347442627,
                                    0.9972721934318542,
                                    0.9851861000061035,
                                    0.994856595993042,
                                    0.9427594542503357],
               'cossim_amm_test': [0.9942018985748291,
                                   0.9984524846076965,
                                   0.9970795512199402,
                                   0.9962807297706604,
                                   0.9972729086875916,
                                   0.9850061535835266,
                                   0.9947063326835632,
                                   0.9410176873207092],
               'f1': [0.4344913779635725,
                      0.6250083304273703,
                      0.5126206804502437],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 512),
                              (192, 2, 512),
                              (512, 512, 2),
                              (512, 512, 2),
                              (32, 2, 512),
                              (32, 2, 512),
                              (32, 2, 512),
                              (256, 2, 512)],
               'lut_total_size': 1638400}}
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.9999998
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.124, 0.124
--- total mse / var(X): 0.124
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00563, 0.00563
--- total mse / var(X): 0.00563
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00167, 0.00167
--- total mse / var(X): 0.00167
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00204, 0.00204
--- total mse / var(X): 0.00204
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00574, 0.00574
--- total mse / var(X): 0.00574
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0107, 0.0107
--- total mse / var(X): 0.0107
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.0036, 0.0036
--- total mse / var(X): 0.0036
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00704, 0.00704
--- total mse / var(X): 0.00704
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 0.00308, 0.00308
--- total mse / var(X): 0.00308
running kmeans in subspace 1/1... kmeans: clustering in subspaces first; k, sqrt(k) = 128, 12
mse / {var(X_subs), var(X)}: 7.18e-11, 7.18e-11
--- total mse / var(X): 7.18e-11
start table evaluation...
Elapsed time: 86.19292092323303 seconds
Cosine similarity between AMM and exact (Train): 0.771143
Cosine similarity between AMM and exact (Test): 0.7783934
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.40765827409186217 0.530937269944593 0.4612017870569633
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],
               'K_CLUSTER': [128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128,
                             128],
               'cossim_layer_train': [0.9913756251335144,
                                      0.9963303804397583,
                                      0.9954569339752197,
                                      0.7711430191993713],
               'cossim_layer_test': [0.9877694249153137,
                                     0.995760440826416,
                                     0.9949716925621033,
                                     0.7783933877944946],
               'cossim_amm_train': [0.9846142530441284,
                                    0.9970248341560364,
                                    0.9938597679138184,
                                    0.9915515184402466,
                                    0.9938444495201111,
                                    0.9541508555412292,
                                    0.9894399642944336,
                                    0.9213464260101318],
               'cossim_amm_test': [0.9783852696418762,
                                   0.9972457885742188,
                                   0.99436354637146,
                                   0.9924200177192688,
                                   0.9938374757766724,
                                   0.9532180428504944,
                                   0.9890625476837158,
                                   0.9246610403060913],
               'f1': [0.40765827409186217,
                      0.530937269944593,
                      0.4612017870569633],
               'lut_num': 8,
               'lut_shapes': [(32, 1, 128),
                              (192, 1, 128),
                              (128, 128, 1),
                              (128, 128, 1),
                              (32, 1, 128),
                              (32, 1, 128),
                              (32, 1, 128),
                              (256, 1, 128)],
               'lut_total_size': 106496}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (32). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0
Manual and Torch results cosine similarity (Test): 0.99999994
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0211, 0.0304
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.000182, 0.000102
--- total mse / var(X): 0.0153
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00269, 0.00275
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00226, 0.00221
--- total mse / var(X): 0.00248
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00115, 0.00121
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00147, 0.00138
--- total mse / var(X): 0.0013
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00153, 0.00156
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00162, 0.00158
--- total mse / var(X): 0.00157
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00155, 0.00147
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00201, 0.00211
--- total mse / var(X): 0.00179
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00279, 0.0023
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.005, 0.00587
--- total mse / var(X): 0.00409
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0086, 0.00815
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00696, 0.00732
--- total mse / var(X): 0.00774
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00604, 0.00591
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00513, 0.00524
--- total mse / var(X): 0.00557
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00282, 0.00216
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00201, 0.00248
--- total mse / var(X): 0.00232
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.0105, 0.00863
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 1024, 32
mse / {var(X_subs), var(X)}: 0.00863, 0.0102
--- total mse / var(X): 0.00941
start table evaluation...
Elapsed time: 460.83703446388245 seconds
Cosine similarity between AMM and exact (Train): 0.86860853
Cosine similarity between AMM and exact (Test): 0.8717929
p,r,f1: 0.6494858848247294 0.7771041109690419 0.7075868365848615
p,r,f1: 0.4676337016200095 0.6843132240691232 0.5555949131033581
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.6494858848247294, 0.7771041109690419, 0.7075868365848615],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024,
                             1024],
               'cossim_layer_train': [0.9989238977432251,
                                      0.9990423321723938,
                                      0.9985196590423584,
                                      0.8686084747314453],
               'cossim_layer_test': [0.9974369406700134,
                                     0.9988295435905457,
                                     0.9982988834381104,
                                     0.8717929720878601],
               'cossim_amm_train': [0.9980906248092651,
                                    0.9990271329879761,
                                    0.9978659749031067,
                                    0.9971277117729187,
                                    0.9979020357131958,
                                    0.9892740845680237,
                                    0.99603271484375,
                                    0.9536267518997192],
               'cossim_amm_test': [0.995484471321106,
                                   0.9987649321556091,
                                   0.9977666139602661,
                                   0.9971380233764648,
                                   0.9979224801063538,
                                   0.9890916347503662,
                                   0.9958789944648743,
                                   0.9537338614463806],
               'f1': [0.4676337016200095,
                      0.6843132240691232,
                      0.5555949131033581],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 1024),
                              (192, 2, 1024),
                              (1024, 1024, 2),
                              (1024, 1024, 2),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (32, 2, 1024),
                              (256, 2, 1024)],
               'lut_total_size': 5373952}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/433/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
/data/neelesh/DART_by_app/433/src/kmeans.py:46: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans1 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, :D//2])
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (4). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 0.99999964
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.31, 0.446
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0536, 0.0302
--- total mse / var(X): 0.238
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0148, 0.0152
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.012, 0.0117
--- total mse / var(X): 0.0134
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.217, 0.233
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.117, 0.108
--- total mse / var(X): 0.17
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.128, 0.127
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.146, 0.147
--- total mse / var(X): 0.137
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0311, 0.0178
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0157, 0.0224
--- total mse / var(X): 0.0201
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.169, 0.13
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.232, 0.285
--- total mse / var(X): 0.208
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 1.93e-05, 5.78e-06
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00047, 0.000799
--- total mse / var(X): 0.000402
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0643, 0.0699
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0623, 0.0568
--- total mse / var(X): 0.0634
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.00313, 0.00177
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.025, 0.0359
--- total mse / var(X): 0.0188
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 1.47, 1.41
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 16, 4
mse / {var(X_subs), var(X)}: 0.0869, 0.0904
--- total mse / var(X): 0.752
start table evaluation...
Elapsed time: 69.89440274238586 seconds
Cosine similarity between AMM and exact (Train): 0.5776095
Cosine similarity between AMM and exact (Test): 0.5788657
p,r,f1: 0.7386025342866525 0.8471060482777326 0.7891420667669624
p,r,f1: 0.4735574320666883 0.27117672129877174 0.34486870568293243
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.7386025342866525, 0.8471060482777326, 0.7891420667669624],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16,
                             16],
               'cossim_layer_train': [0.9875732660293579,
                                      0.9874938130378723,
                                      0.983875036239624,
                                      0.5776095390319824],
               'cossim_layer_test': [0.9863836765289307,
                                     0.9870771765708923,
                                     0.9834534525871277,
                                     0.578865647315979],
               'cossim_amm_train': [0.9775798320770264,
                                    0.9937397241592407,
                                    0.9332008957862854,
                                    0.9316028952598572,
                                    0.9813161492347717,
                                    0.8836132287979126,
                                    0.9485527873039246,
                                    0.8937797546386719],
               'cossim_amm_test': [0.975557804107666,
                                   0.9944851398468018,
                                   0.9335542917251587,
                                   0.9323338866233826,
                                   0.9813670516014099,
                                   0.8837419748306274,
                                   0.9485553503036499,
                                   0.8932503461837769],
               'f1': [0.4735574320666883,
                      0.27117672129877174,
                      0.34486870568293243],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 16),
                              (192, 2, 16),
                              (16, 16, 2),
                              (16, 16, 2),
                              (32, 2, 16),
                              (32, 2, 16),
                              (32, 2, 16),
                              (256, 2, 16)],
               'lut_total_size': 19456}}
/data/neelesh/DART_by_app/433/src/kmeans.py:47: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (6). Possibly due to duplicate points in X.
  kmeans2 = KMeans(n_clusters=sqrt_k, random_state=0).fit(X[:, D//2:])
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
TMAP                                               384
├─Sequential: 1-1                                  --
│    └─Rearrange: 2-1                              --
│    └─Linear: 2-2                                 352
├─Dropout: 1-2                                     --
├─Transformer: 1-3                                 --
│    └─ModuleList: 2-3                             --
│    │    └─ModuleList: 3-1                        10,464
├─Identity: 1-4                                    --
├─Sequential: 1-5                                  --
│    └─LayerNorm: 2-4                              64
│    └─Linear: 2-5                                 8,448
===========================================================================
Total params: 19,712
Trainable params: 19,712
Non-trainable params: 0
===========================================================================
Manual and Torch results cosine similarity (Train): 1.0000002
Manual and Torch results cosine similarity (Test): 1.0000006
start table training...
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.218, 0.314
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0139, 0.00776
--- total mse / var(X): 0.161
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0079, 0.0081
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00947, 0.00923
--- total mse / var(X): 0.00866
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0234, 0.0251
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0171, 0.0159
--- total mse / var(X): 0.0205
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.044, 0.0436
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0374, 0.0377
--- total mse / var(X): 0.0407
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0124, 0.00473
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00385, 0.00623
--- total mse / var(X): 0.00548
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.0841, 0.0645
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.128, 0.157
--- total mse / var(X): 0.111
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00259, 0.000852
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.000438, 0.000732
--- total mse / var(X): 0.000792
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00914, 0.00906
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00737, 0.00744
--- total mse / var(X): 0.00825
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00379, 0.00221
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 0.00139, 0.00196
--- total mse / var(X): 0.00209
running kmeans in subspace 1/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 4.14e-05, 5.01e-05
running kmeans in subspace 2/2... kmeans: clustering in subspaces first; k, sqrt(k) = 32, 6
mse / {var(X_subs), var(X)}: 2.06e-05, 1.63e-05
--- total mse / var(X): 3.32e-05
start table evaluation...
Elapsed time: 71.61960506439209 seconds
Cosine similarity between AMM and exact (Train): 0.6132514
Cosine similarity between AMM and exact (Test): 0.6130336
p,r,f1: 0.7386025342866525 0.8471060482777326 0.7891420667669624
p,r,f1: 0.3976484731201712 0.37834243868417994 0.38775529653949886
done
{'model': {'name': 'ViT',
           'layer': 4,
           'dim': 32,
           'f1': [0.7386025342866525, 0.8471060482777326, 0.7891420667669624],
           'num_param': 19712},
 'estimator': {'method': 'PQ_KMEANS',
               'N_SUBSPACE': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
               'K_CLUSTER': [32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32,
                             32],
               'cossim_layer_train': [0.9902910590171814,
                                      0.9932231903076172,
                                      0.9932984709739685,
                                      0.6132513284683228],
               'cossim_layer_test': [0.9897655844688416,
                                     0.9931018948554993,
                                     0.9931914806365967,
                                     0.6130335927009583],
               'cossim_amm_train': [0.9824998378753662,
                                    0.9965243935585022,
                                    0.9767887592315674,
                                    0.963599681854248,
                                    0.9913296699523926,
                                    0.9214041233062744,
                                    0.9792671203613281,
                                    0.8949563503265381],
               'cossim_amm_test': [0.9815345406532288,
                                   0.9971693158149719,
                                   0.9774357676506042,
                                   0.9646643400192261,
                                   0.9913536906242371,
                                   0.9204085469245911,
                                   0.979308545589447,
                                   0.8941923975944519],
               'f1': [0.3976484731201712,
                      0.37834243868417994,
                      0.38775529653949886],
               'lut_num': 8,
               'lut_shapes': [(32, 2, 32),
                              (192, 2, 32),
                              (32, 32, 2),
                              (32, 32, 2),
                              (32, 2, 32),
                              (32, 2, 32),
                              (32, 2, 32),
                              (256, 2, 32)],
               'lut_total_size': 40960}}
